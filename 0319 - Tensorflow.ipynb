{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "052f193f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0283f07a",
   "metadata": {},
   "source": [
    "## XOR 문제 해결 - 여러개의 층을 만들어서 해결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e6090c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m6\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m3\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> (36.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9\u001b[0m (36.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> (36.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9\u001b[0m (36.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# 입력과 출력 데이터 생성 - 같으면 0 다르면 1\n",
    "\n",
    "X = np.array([[0,0],[0, 1], [1, 0],[0, 0]])\n",
    "y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "# 2개의 완전 연결층을 가진 모델을 생성\n",
    "# units 는 뉴런의 개수이고 activation은 출력을 계산해주는 함수\n",
    "# input_shape 는 맨처음 입력 층에서 피처의 모양\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units = 2, activation = 'sigmoid', input_shape = (2, )),\n",
    "    tf.keras.layers.Dense(units = 1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "# lr 부분이 에러가 나면 learning_rate로 수정하면 됩니다.\n",
    "model.compile(optimizer = tf.keras.optimizers.SGD(learning_rate = 0.2), loss = 'mse')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87131722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2350  \n",
      "Epoch 2/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2580 \n",
      "Epoch 3/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2119 \n",
      "Epoch 4/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.2263  \n",
      "Epoch 5/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2727 \n",
      "Epoch 6/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.2763  \n",
      "Epoch 7/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.2377  \n",
      "Epoch 8/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2073 \n",
      "Epoch 9/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2283 \n",
      "Epoch 10/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.2507  \n",
      "Epoch 11/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - loss: 0.2265\n",
      "Epoch 12/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193us/step - loss: 0.2159\n",
      "Epoch 13/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2240 \n",
      "Epoch 14/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2459 \n",
      "Epoch 15/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.2128  \n",
      "Epoch 16/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2175 \n",
      "Epoch 17/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.2182  \n",
      "Epoch 18/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2396 \n",
      "Epoch 19/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2274 \n",
      "Epoch 20/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.2336  \n",
      "Epoch 21/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2156 \n",
      "Epoch 22/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2523 \n",
      "Epoch 23/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.2229  \n",
      "Epoch 24/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.2284  \n",
      "Epoch 25/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1997 \n",
      "Epoch 26/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.1946  \n",
      "Epoch 27/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2014 \n",
      "Epoch 28/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2431 \n",
      "Epoch 29/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2033 \n",
      "Epoch 30/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2254 \n",
      "Epoch 31/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2132 \n",
      "Epoch 32/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.1806  \n",
      "Epoch 33/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 0.1955\n",
      "Epoch 34/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2196 \n",
      "Epoch 35/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.1929  \n",
      "Epoch 36/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.2106  \n",
      "Epoch 37/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2206 \n",
      "Epoch 38/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.1814  \n",
      "Epoch 39/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 0.1768\n",
      "Epoch 40/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1830 \n",
      "Epoch 41/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.2145  \n",
      "Epoch 42/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1670 \n",
      "Epoch 43/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1655 \n",
      "Epoch 44/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1640 \n",
      "Epoch 45/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2109 \n",
      "Epoch 46/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1946 \n",
      "Epoch 47/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.1744  \n",
      "Epoch 48/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1836 \n",
      "Epoch 49/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1865 \n",
      "Epoch 50/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.1616  \n",
      "Epoch 51/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.1611  \n",
      "Epoch 52/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1672 \n",
      "Epoch 53/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1498 \n",
      "Epoch 54/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1626 \n",
      "Epoch 55/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.1502  \n",
      "Epoch 56/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1515 \n",
      "Epoch 57/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1808 \n",
      "Epoch 58/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1459 \n",
      "Epoch 59/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1689 \n",
      "Epoch 60/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1662 \n",
      "Epoch 61/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1719 \n",
      "Epoch 62/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1586 \n",
      "Epoch 63/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.1443  \n",
      "Epoch 64/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.1673  \n",
      "Epoch 65/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.1425  \n",
      "Epoch 66/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310us/step - loss: 0.1273\n",
      "Epoch 67/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.1564  \n",
      "Epoch 68/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1239 \n",
      "Epoch 69/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1438 \n",
      "Epoch 70/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.1295  \n",
      "Epoch 71/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.1396  \n",
      "Epoch 72/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.1224  \n",
      "Epoch 73/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1309 \n",
      "Epoch 74/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.1432  \n",
      "Epoch 75/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1308 \n",
      "Epoch 76/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1296 \n",
      "Epoch 77/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - loss: 0.1174\n",
      "Epoch 78/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1246 \n",
      "Epoch 79/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - loss: 0.1200\n",
      "Epoch 80/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step - loss: 0.1055\n",
      "Epoch 81/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1017 \n",
      "Epoch 82/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1161 \n",
      "Epoch 83/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - loss: 0.1052\n",
      "Epoch 84/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0969 \n",
      "Epoch 85/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0974 \n",
      "Epoch 86/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.1135  \n",
      "Epoch 87/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0959  \n",
      "Epoch 88/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.1103  \n",
      "Epoch 89/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0943 \n",
      "Epoch 90/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1016 \n",
      "Epoch 91/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0863  \n",
      "Epoch 92/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0848  \n",
      "Epoch 93/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - loss: 0.0933\n",
      "Epoch 94/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0934 \n",
      "Epoch 95/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0936  \n",
      "Epoch 96/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0855  \n",
      "Epoch 97/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0838  \n",
      "Epoch 98/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0871 \n",
      "Epoch 99/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0886  \n",
      "Epoch 100/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0839  \n",
      "Epoch 101/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0726  \n",
      "Epoch 102/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0806  \n",
      "Epoch 103/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0715  \n",
      "Epoch 104/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0711 \n",
      "Epoch 105/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0678 \n",
      "Epoch 106/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0748  \n",
      "Epoch 107/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0719  \n",
      "Epoch 108/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0711  \n",
      "Epoch 109/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - loss: 0.0723\n",
      "Epoch 110/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124us/step - loss: 0.0620\n",
      "Epoch 111/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0696  \n",
      "Epoch 112/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0643  \n",
      "Epoch 113/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0679  \n",
      "Epoch 114/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0618 \n",
      "Epoch 115/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0629  \n",
      "Epoch 116/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step - loss: 0.0567\n",
      "Epoch 117/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - loss: 0.0561\n",
      "Epoch 118/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0555 \n",
      "Epoch 119/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0548 \n",
      "Epoch 120/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0546  \n",
      "Epoch 121/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0516 \n",
      "Epoch 122/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0567 \n",
      "Epoch 123/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0558  \n",
      "Epoch 124/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0500  \n",
      "Epoch 125/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0534 \n",
      "Epoch 126/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0475  \n",
      "Epoch 127/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0531 \n",
      "Epoch 128/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0477 \n",
      "Epoch 129/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0512 \n",
      "Epoch 130/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0504  \n",
      "Epoch 131/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0484 \n",
      "Epoch 132/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0477 \n",
      "Epoch 133/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0425 \n",
      "Epoch 134/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0457 \n",
      "Epoch 135/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0441 \n",
      "Epoch 136/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0454  \n",
      "Epoch 137/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0428  \n",
      "Epoch 138/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0427 \n",
      "Epoch 139/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0406 \n",
      "Epoch 140/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0410 \n",
      "Epoch 141/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0408 \n",
      "Epoch 142/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - loss: 0.0389\n",
      "Epoch 143/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0379 \n",
      "Epoch 144/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0402  \n",
      "Epoch 145/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0388 \n",
      "Epoch 146/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0366 \n",
      "Epoch 147/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0344 \n",
      "Epoch 148/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0342 \n",
      "Epoch 149/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0359 \n",
      "Epoch 150/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0355 \n",
      "Epoch 151/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0336 \n",
      "Epoch 152/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0344  \n",
      "Epoch 153/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0322 \n",
      "Epoch 154/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0318 \n",
      "Epoch 155/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0324 \n",
      "Epoch 156/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0315 \n",
      "Epoch 157/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0302 \n",
      "Epoch 158/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0296 \n",
      "Epoch 159/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0303 \n",
      "Epoch 160/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0318 \n",
      "Epoch 161/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0311  \n",
      "Epoch 162/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0280 \n",
      "Epoch 163/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0286 \n",
      "Epoch 164/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0300 \n",
      "Epoch 165/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0288 \n",
      "Epoch 166/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0275 \n",
      "Epoch 167/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0280  \n",
      "Epoch 168/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0262 \n",
      "Epoch 169/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0275 \n",
      "Epoch 170/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0269 \n",
      "Epoch 171/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0263  \n",
      "Epoch 172/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0260 \n",
      "Epoch 173/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0257 \n",
      "Epoch 174/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - loss: 0.0241\n",
      "Epoch 175/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0240 \n",
      "Epoch 176/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0242 \n",
      "Epoch 177/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0241  \n",
      "Epoch 178/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0230  \n",
      "Epoch 179/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0241 \n",
      "Epoch 180/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0233  \n",
      "Epoch 181/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0237 \n",
      "Epoch 182/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0234  \n",
      "Epoch 183/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0223 \n",
      "Epoch 184/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0225 \n",
      "Epoch 185/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0228 \n",
      "Epoch 186/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0217 \n",
      "Epoch 187/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0209 \n",
      "Epoch 188/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0216  \n",
      "Epoch 189/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0212  \n",
      "Epoch 190/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337us/step - loss: 0.0213\n",
      "Epoch 191/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0213 \n",
      "Epoch 192/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0207  \n",
      "Epoch 193/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0205 \n",
      "Epoch 194/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0198 \n",
      "Epoch 195/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0205  \n",
      "Epoch 196/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0189  \n",
      "Epoch 197/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0199 \n",
      "Epoch 198/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0194  \n",
      "Epoch 199/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0190 \n",
      "Epoch 200/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0186  \n",
      "Epoch 201/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0192 \n",
      "Epoch 202/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0187 \n",
      "Epoch 203/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0179 \n",
      "Epoch 204/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0175  \n",
      "Epoch 205/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0181  \n",
      "Epoch 206/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0182 \n",
      "Epoch 207/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0172 \n",
      "Epoch 208/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0175 \n",
      "Epoch 209/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0173 \n",
      "Epoch 210/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0168  \n",
      "Epoch 211/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0166  \n",
      "Epoch 212/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0162  \n",
      "Epoch 213/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0160 \n",
      "Epoch 214/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0169 \n",
      "Epoch 215/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0167  \n",
      "Epoch 216/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0156 \n",
      "Epoch 217/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0164 \n",
      "Epoch 218/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0160  \n",
      "Epoch 219/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0158 \n",
      "Epoch 220/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0159  \n",
      "Epoch 221/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0149 \n",
      "Epoch 222/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0150  \n",
      "Epoch 223/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0147  \n",
      "Epoch 224/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0149  \n",
      "Epoch 225/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0149  \n",
      "Epoch 226/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59us/step - loss: 0.0145\n",
      "Epoch 227/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0146 \n",
      "Epoch 228/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0148 \n",
      "Epoch 229/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0141 \n",
      "Epoch 230/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0143  \n",
      "Epoch 231/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0144  \n",
      "Epoch 232/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0135 \n",
      "Epoch 233/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0135 \n",
      "Epoch 234/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0138  \n",
      "Epoch 235/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0134  \n",
      "Epoch 236/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0131 \n",
      "Epoch 237/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0130  \n",
      "Epoch 238/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0131 \n",
      "Epoch 239/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0128 \n",
      "Epoch 240/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0131  \n",
      "Epoch 241/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0129 \n",
      "Epoch 242/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0131  \n",
      "Epoch 243/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0128 \n",
      "Epoch 244/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0127  \n",
      "Epoch 245/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0128 \n",
      "Epoch 246/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0122  \n",
      "Epoch 247/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0122 \n",
      "Epoch 248/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0125 \n",
      "Epoch 249/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0120 \n",
      "Epoch 250/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0123  \n",
      "Epoch 251/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0117 \n",
      "Epoch 252/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0117  \n",
      "Epoch 253/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0115  \n",
      "Epoch 254/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0118 \n",
      "Epoch 255/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0114 \n",
      "Epoch 256/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0118 \n",
      "Epoch 257/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0113  \n",
      "Epoch 258/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0114  \n",
      "Epoch 259/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0111  \n",
      "Epoch 260/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0111 \n",
      "Epoch 261/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0113  \n",
      "Epoch 262/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0110  \n",
      "Epoch 263/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0110  \n",
      "Epoch 264/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0107 \n",
      "Epoch 265/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0110 \n",
      "Epoch 266/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0107  \n",
      "Epoch 267/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0104 \n",
      "Epoch 268/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - loss: 0.0106\n",
      "Epoch 269/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0105 \n",
      "Epoch 270/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0106 \n",
      "Epoch 271/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0102 \n",
      "Epoch 272/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0103  \n",
      "Epoch 273/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0101 \n",
      "Epoch 274/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0100  \n",
      "Epoch 275/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0100  \n",
      "Epoch 276/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0100  \n",
      "Epoch 277/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 \n",
      "Epoch 278/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0098 \n",
      "Epoch 279/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 \n",
      "Epoch 280/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0096  \n",
      "Epoch 281/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0094  \n",
      "Epoch 282/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0094  \n",
      "Epoch 283/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0095 \n",
      "Epoch 284/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0092  \n",
      "Epoch 285/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 \n",
      "Epoch 286/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0095 \n",
      "Epoch 287/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0091  \n",
      "Epoch 288/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0091  \n",
      "Epoch 289/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0091 \n",
      "Epoch 290/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0090 \n",
      "Epoch 291/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0091 \n",
      "Epoch 292/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0088 \n",
      "Epoch 293/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0088 \n",
      "Epoch 294/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0089  \n",
      "Epoch 295/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 \n",
      "Epoch 296/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - loss: 0.0089\n",
      "Epoch 297/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0085 \n",
      "Epoch 298/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0087 \n",
      "Epoch 299/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0087 \n",
      "Epoch 300/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0086  \n",
      "Epoch 301/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0083  \n",
      "Epoch 302/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0083 \n",
      "Epoch 303/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 \n",
      "Epoch 304/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0084 \n",
      "Epoch 305/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 \n",
      "Epoch 306/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 \n",
      "Epoch 307/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0080 \n",
      "Epoch 308/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0083  \n",
      "Epoch 309/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0082  \n",
      "Epoch 310/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0080 \n",
      "Epoch 311/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0079 \n",
      "Epoch 312/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 \n",
      "Epoch 313/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0078 \n",
      "Epoch 314/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0077 \n",
      "Epoch 315/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0078 \n",
      "Epoch 316/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0077 \n",
      "Epoch 317/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0077  \n",
      "Epoch 318/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0078  \n",
      "Epoch 319/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0078  \n",
      "Epoch 320/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - loss: 0.0078\n",
      "Epoch 321/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0076  \n",
      "Epoch 322/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0074 \n",
      "Epoch 323/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 \n",
      "Epoch 324/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0074  \n",
      "Epoch 325/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0073  \n",
      "Epoch 326/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0074 \n",
      "Epoch 327/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - loss: 0.0073\n",
      "Epoch 328/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0072 \n",
      "Epoch 329/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0074  \n",
      "Epoch 330/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0072 \n",
      "Epoch 331/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0071  \n",
      "Epoch 332/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0071 \n",
      "Epoch 333/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0072  \n",
      "Epoch 334/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0070 \n",
      "Epoch 335/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0069  \n",
      "Epoch 336/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0069  \n",
      "Epoch 337/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0069  \n",
      "Epoch 338/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0068  \n",
      "Epoch 339/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0069 \n",
      "Epoch 340/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - loss: 0.0069\n",
      "Epoch 341/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0068 \n",
      "Epoch 342/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0068  \n",
      "Epoch 343/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368us/step - loss: 0.0068\n",
      "Epoch 344/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0067  \n",
      "Epoch 345/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0067 \n",
      "Epoch 346/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0067  \n",
      "Epoch 347/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0067  \n",
      "Epoch 348/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0067 \n",
      "Epoch 349/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 \n",
      "Epoch 350/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0066  \n",
      "Epoch 351/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0066  \n",
      "Epoch 352/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0064 \n",
      "Epoch 353/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0065  \n",
      "Epoch 354/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0064  \n",
      "Epoch 355/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0063  \n",
      "Epoch 356/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0063  \n",
      "Epoch 357/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0062  \n",
      "Epoch 358/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0063  \n",
      "Epoch 359/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0063  \n",
      "Epoch 360/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0062  \n",
      "Epoch 361/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0061  \n",
      "Epoch 362/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0061  \n",
      "Epoch 363/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0062  \n",
      "Epoch 364/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0061  \n",
      "Epoch 365/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0060  \n",
      "Epoch 366/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0060 \n",
      "Epoch 367/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - loss: 0.0061\n",
      "Epoch 368/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0059 \n",
      "Epoch 369/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0060 \n",
      "Epoch 370/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0059  \n",
      "Epoch 371/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - loss: 0.0059\n",
      "Epoch 372/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0058 \n",
      "Epoch 373/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0058 \n",
      "Epoch 374/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0057  \n",
      "Epoch 375/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0059  \n",
      "Epoch 376/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0057 \n",
      "Epoch 377/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0058 \n",
      "Epoch 378/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0057  \n",
      "Epoch 379/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 \n",
      "Epoch 380/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0056 \n",
      "Epoch 381/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434us/step - loss: 0.0057\n",
      "Epoch 382/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0055  \n",
      "Epoch 383/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0056  \n",
      "Epoch 384/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0056  \n",
      "Epoch 385/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0056  \n",
      "Epoch 386/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 \n",
      "Epoch 387/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0055 \n",
      "Epoch 388/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0054 \n",
      "Epoch 389/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0055 \n",
      "Epoch 390/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0055  \n",
      "Epoch 391/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0054  \n",
      "Epoch 392/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - loss: 0.0054\n",
      "Epoch 393/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0053 \n",
      "Epoch 394/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0054 \n",
      "Epoch 395/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 \n",
      "Epoch 396/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0053  \n",
      "Epoch 397/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0053 \n",
      "Epoch 398/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 \n",
      "Epoch 399/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0053 \n",
      "Epoch 400/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0052 \n",
      "Epoch 401/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0051  \n",
      "Epoch 402/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0052  \n",
      "Epoch 403/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0051  \n",
      "Epoch 404/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0051  \n",
      "Epoch 405/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051 \n",
      "Epoch 406/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0051 \n",
      "Epoch 407/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0050 \n",
      "Epoch 408/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0050  \n",
      "Epoch 409/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0050 \n",
      "Epoch 410/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0050 \n",
      "Epoch 411/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0050  \n",
      "Epoch 412/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0050 \n",
      "Epoch 413/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0050  \n",
      "Epoch 414/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0049  \n",
      "Epoch 415/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0049  \n",
      "Epoch 416/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0049 \n",
      "Epoch 417/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0048 \n",
      "Epoch 418/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0049  \n",
      "Epoch 419/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0048 \n",
      "Epoch 420/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0048  \n",
      "Epoch 421/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0048 \n",
      "Epoch 422/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0048 \n",
      "Epoch 423/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0048 \n",
      "Epoch 424/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0048 \n",
      "Epoch 425/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0047 \n",
      "Epoch 426/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0047 \n",
      "Epoch 427/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0046 \n",
      "Epoch 428/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0046  \n",
      "Epoch 429/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - loss: 0.0046\n",
      "Epoch 430/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0046  \n",
      "Epoch 431/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 \n",
      "Epoch 432/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0046  \n",
      "Epoch 433/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0045  \n",
      "Epoch 434/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0046  \n",
      "Epoch 435/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0045 \n",
      "Epoch 436/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0045 \n",
      "Epoch 437/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0045  \n",
      "Epoch 438/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0045  \n",
      "Epoch 439/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0044 \n",
      "Epoch 440/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0044  \n",
      "Epoch 441/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 \n",
      "Epoch 442/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0045  \n",
      "Epoch 443/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 0.0045\n",
      "Epoch 444/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 \n",
      "Epoch 445/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0044 \n",
      "Epoch 446/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0044 \n",
      "Epoch 447/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0043  \n",
      "Epoch 448/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236us/step - loss: 0.0044\n",
      "Epoch 449/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0044 \n",
      "Epoch 450/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0043 \n",
      "Epoch 451/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0043  \n",
      "Epoch 452/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0043 \n",
      "Epoch 453/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0042 \n",
      "Epoch 454/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0043 \n",
      "Epoch 455/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0042  \n",
      "Epoch 456/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 \n",
      "Epoch 457/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0042  \n",
      "Epoch 458/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0042  \n",
      "Epoch 459/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0041 \n",
      "Epoch 460/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0042  \n",
      "Epoch 461/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0041  \n",
      "Epoch 462/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0042  \n",
      "Epoch 463/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - loss: 0.0041\n",
      "Epoch 464/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0041  \n",
      "Epoch 465/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0041 \n",
      "Epoch 466/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0041  \n",
      "Epoch 467/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0041 \n",
      "Epoch 468/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0040  \n",
      "Epoch 469/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - loss: 0.0041\n",
      "Epoch 470/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0041  \n",
      "Epoch 471/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0040 \n",
      "Epoch 472/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - loss: 0.0040\n",
      "Epoch 473/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 \n",
      "Epoch 474/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0039 \n",
      "Epoch 475/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0040 \n",
      "Epoch 476/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0039 \n",
      "Epoch 477/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0040 \n",
      "Epoch 478/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0039 \n",
      "Epoch 479/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0039  \n",
      "Epoch 480/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0039  \n",
      "Epoch 481/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0038  \n",
      "Epoch 482/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0038  \n",
      "Epoch 483/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0038  \n",
      "Epoch 484/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 \n",
      "Epoch 485/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0038  \n",
      "Epoch 486/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 \n",
      "Epoch 487/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0038 \n",
      "Epoch 488/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0038 \n",
      "Epoch 489/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0038  \n",
      "Epoch 490/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0038 \n",
      "Epoch 491/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0037 \n",
      "Epoch 492/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0037  \n",
      "Epoch 493/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - loss: 0.0037\n",
      "Epoch 494/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0037  \n",
      "Epoch 495/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0037  \n",
      "Epoch 496/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0037  \n",
      "Epoch 497/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0037 \n",
      "Epoch 498/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0037  \n",
      "Epoch 499/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0036  \n",
      "Epoch 500/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0036  \n",
      "Epoch 501/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0036  \n",
      "Epoch 502/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0036 \n",
      "Epoch 503/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0036  \n",
      "Epoch 504/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 \n",
      "Epoch 505/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0036 \n",
      "Epoch 506/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0036 \n",
      "Epoch 507/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0036 \n",
      "Epoch 508/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0035 \n",
      "Epoch 509/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0035  \n",
      "Epoch 510/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0035 \n",
      "Epoch 511/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0036 \n",
      "Epoch 512/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0035  \n",
      "Epoch 513/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0035 \n",
      "Epoch 514/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0035  \n",
      "Epoch 515/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0035  \n",
      "Epoch 516/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0035 \n",
      "Epoch 517/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0035 \n",
      "Epoch 518/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0034  \n",
      "Epoch 519/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0035 \n",
      "Epoch 520/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - loss: 0.0035\n",
      "Epoch 521/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0034  \n",
      "Epoch 522/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0035 \n",
      "Epoch 523/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0034  \n",
      "Epoch 524/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0034 \n",
      "Epoch 525/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0034 \n",
      "Epoch 526/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0034 \n",
      "Epoch 527/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 \n",
      "Epoch 528/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0033  \n",
      "Epoch 529/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0034 \n",
      "Epoch 530/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0034  \n",
      "Epoch 531/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0034  \n",
      "Epoch 532/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0033 \n",
      "Epoch 533/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0033 \n",
      "Epoch 534/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0033 \n",
      "Epoch 535/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0033  \n",
      "Epoch 536/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0033  \n",
      "Epoch 537/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0033 \n",
      "Epoch 538/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0033 \n",
      "Epoch 539/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0033 \n",
      "Epoch 540/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - loss: 0.0033\n",
      "Epoch 541/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0033  \n",
      "Epoch 542/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0032  \n",
      "Epoch 543/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0032 \n",
      "Epoch 544/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0032  \n",
      "Epoch 545/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0032 \n",
      "Epoch 546/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0032  \n",
      "Epoch 547/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 \n",
      "Epoch 548/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 \n",
      "Epoch 549/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 \n",
      "Epoch 550/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0031  \n",
      "Epoch 551/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0031  \n",
      "Epoch 552/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0031 \n",
      "Epoch 553/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0031 \n",
      "Epoch 554/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0031  \n",
      "Epoch 555/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 \n",
      "Epoch 556/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - loss: 0.0031\n",
      "Epoch 557/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0031  \n",
      "Epoch 558/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 \n",
      "Epoch 559/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0031 \n",
      "Epoch 560/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0031  \n",
      "Epoch 561/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 \n",
      "Epoch 562/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0031 \n",
      "Epoch 563/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0031  \n",
      "Epoch 564/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - loss: 0.0030\n",
      "Epoch 565/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0031  \n",
      "Epoch 566/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0030  \n",
      "Epoch 567/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0030 \n",
      "Epoch 568/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0030  \n",
      "Epoch 569/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0030  \n",
      "Epoch 570/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 \n",
      "Epoch 571/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0030 \n",
      "Epoch 572/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0030 \n",
      "Epoch 573/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0030  \n",
      "Epoch 574/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0030  \n",
      "Epoch 575/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0030  \n",
      "Epoch 576/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0030  \n",
      "Epoch 577/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0030  \n",
      "Epoch 578/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0029 \n",
      "Epoch 579/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0029  \n",
      "Epoch 580/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0029  \n",
      "Epoch 581/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0029  \n",
      "Epoch 582/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 \n",
      "Epoch 583/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0029  \n",
      "Epoch 584/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0029  \n",
      "Epoch 585/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0029  \n",
      "Epoch 586/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - loss: 0.0029\n",
      "Epoch 587/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0029  \n",
      "Epoch 588/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - loss: 0.0028\n",
      "Epoch 589/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0028 \n",
      "Epoch 590/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0028 \n",
      "Epoch 591/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0028 \n",
      "Epoch 592/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0028  \n",
      "Epoch 593/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0028 \n",
      "Epoch 594/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0028  \n",
      "Epoch 595/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0028 \n",
      "Epoch 596/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0028  \n",
      "Epoch 597/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0028  \n",
      "Epoch 598/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0028  \n",
      "Epoch 599/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0028  \n",
      "Epoch 600/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0028 \n",
      "Epoch 601/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 \n",
      "Epoch 602/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0028  \n",
      "Epoch 603/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48us/step - loss: 0.0027\n",
      "Epoch 604/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0028 \n",
      "Epoch 605/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 \n",
      "Epoch 606/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 \n",
      "Epoch 607/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 \n",
      "Epoch 608/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0027 \n",
      "Epoch 609/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - loss: 0.0027\n",
      "Epoch 610/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0027 \n",
      "Epoch 611/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0027  \n",
      "Epoch 612/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 \n",
      "Epoch 613/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 \n",
      "Epoch 614/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0027  \n",
      "Epoch 615/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 \n",
      "Epoch 616/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0027  \n",
      "Epoch 617/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 \n",
      "Epoch 618/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0026 \n",
      "Epoch 619/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0027  \n",
      "Epoch 620/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228us/step - loss: 0.0026\n",
      "Epoch 621/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0026  \n",
      "Epoch 622/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0026 \n",
      "Epoch 623/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - loss: 0.0026\n",
      "Epoch 624/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0026 \n",
      "Epoch 625/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0026  \n",
      "Epoch 626/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0026  \n",
      "Epoch 627/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0026  \n",
      "Epoch 628/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58us/step - loss: 0.0026\n",
      "Epoch 629/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0026  \n",
      "Epoch 630/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0026  \n",
      "Epoch 631/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0026 \n",
      "Epoch 632/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 \n",
      "Epoch 633/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 \n",
      "Epoch 634/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0026  \n",
      "Epoch 635/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 \n",
      "Epoch 636/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 \n",
      "Epoch 637/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0025  \n",
      "Epoch 638/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 \n",
      "Epoch 639/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0025  \n",
      "Epoch 640/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0025  \n",
      "Epoch 641/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0025 \n",
      "Epoch 642/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0025  \n",
      "Epoch 643/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - loss: 0.0025\n",
      "Epoch 644/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 \n",
      "Epoch 645/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 \n",
      "Epoch 646/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0025  \n",
      "Epoch 647/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0025 \n",
      "Epoch 648/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0025 \n",
      "Epoch 649/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0025 \n",
      "Epoch 650/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0025  \n",
      "Epoch 651/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 \n",
      "Epoch 652/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0024  \n",
      "Epoch 653/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0024  \n",
      "Epoch 654/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0025  \n",
      "Epoch 655/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0024  \n",
      "Epoch 656/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0024  \n",
      "Epoch 657/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0024 \n",
      "Epoch 658/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 \n",
      "Epoch 659/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0024  \n",
      "Epoch 660/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - loss: 0.0024\n",
      "Epoch 661/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0024 \n",
      "Epoch 662/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0024  \n",
      "Epoch 663/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0024  \n",
      "Epoch 664/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0024  \n",
      "Epoch 665/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0024  \n",
      "Epoch 666/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0024  \n",
      "Epoch 667/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0024  \n",
      "Epoch 668/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 \n",
      "Epoch 669/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0024  \n",
      "Epoch 670/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 \n",
      "Epoch 671/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0023  \n",
      "Epoch 672/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0024  \n",
      "Epoch 673/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0024 \n",
      "Epoch 674/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 \n",
      "Epoch 675/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - loss: 0.0023\n",
      "Epoch 676/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 \n",
      "Epoch 677/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0023  \n",
      "Epoch 678/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0023 \n",
      "Epoch 679/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 \n",
      "Epoch 680/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 \n",
      "Epoch 681/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 \n",
      "Epoch 682/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0023  \n",
      "Epoch 683/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0023 \n",
      "Epoch 684/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 \n",
      "Epoch 685/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0023  \n",
      "Epoch 686/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0023  \n",
      "Epoch 687/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0023  \n",
      "Epoch 688/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0023 \n",
      "Epoch 689/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0023  \n",
      "Epoch 690/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0023 \n",
      "Epoch 691/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 \n",
      "Epoch 692/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0023 \n",
      "Epoch 693/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0022 \n",
      "Epoch 694/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0022  \n",
      "Epoch 695/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - loss: 0.0022\n",
      "Epoch 696/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0022 \n",
      "Epoch 697/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0022 \n",
      "Epoch 698/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0022  \n",
      "Epoch 699/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0022 \n",
      "Epoch 700/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0022  \n",
      "Epoch 701/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 \n",
      "Epoch 702/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0022 \n",
      "Epoch 703/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0022  \n",
      "Epoch 704/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0022 \n",
      "Epoch 705/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 \n",
      "Epoch 706/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - loss: 0.0022\n",
      "Epoch 707/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 \n",
      "Epoch 708/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0022  \n",
      "Epoch 709/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 \n",
      "Epoch 710/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 \n",
      "Epoch 711/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0022 \n",
      "Epoch 712/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 \n",
      "Epoch 713/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 \n",
      "Epoch 714/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0021  \n",
      "Epoch 715/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 \n",
      "Epoch 716/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 \n",
      "Epoch 717/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0021 \n",
      "Epoch 718/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 \n",
      "Epoch 719/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0021  \n",
      "Epoch 720/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0021 \n",
      "Epoch 721/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0021  \n",
      "Epoch 722/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0021 \n",
      "Epoch 723/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0021 \n",
      "Epoch 724/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0021 \n",
      "Epoch 725/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0021  \n",
      "Epoch 726/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0021  \n",
      "Epoch 727/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0021  \n",
      "Epoch 728/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0021  \n",
      "Epoch 729/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0021  \n",
      "Epoch 730/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0021  \n",
      "Epoch 731/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - loss: 0.0021\n",
      "Epoch 732/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0021  \n",
      "Epoch 733/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0021  \n",
      "Epoch 734/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - loss: 0.0021\n",
      "Epoch 735/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0021 \n",
      "Epoch 736/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 0.0021\n",
      "Epoch 737/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0021  \n",
      "Epoch 738/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0020  \n",
      "Epoch 739/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0021 \n",
      "Epoch 740/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0021 \n",
      "Epoch 741/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0021 \n",
      "Epoch 742/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0020 \n",
      "Epoch 743/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - loss: 0.0021\n",
      "Epoch 744/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0020 \n",
      "Epoch 745/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0020  \n",
      "Epoch 746/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - loss: 0.0020\n",
      "Epoch 747/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0020 \n",
      "Epoch 748/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0020  \n",
      "Epoch 749/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0020  \n",
      "Epoch 750/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0020  \n",
      "Epoch 751/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0020  \n",
      "Epoch 752/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0020  \n",
      "Epoch 753/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 \n",
      "Epoch 754/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0020  \n",
      "Epoch 755/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0020  \n",
      "Epoch 756/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0020  \n",
      "Epoch 757/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0020  \n",
      "Epoch 758/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0020  \n",
      "Epoch 759/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - loss: 0.0020\n",
      "Epoch 760/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 \n",
      "Epoch 761/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0020  \n",
      "Epoch 762/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0020 \n",
      "Epoch 763/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 \n",
      "Epoch 764/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 \n",
      "Epoch 765/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0019  \n",
      "Epoch 766/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0019  \n",
      "Epoch 767/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019 \n",
      "Epoch 768/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0019  \n",
      "Epoch 769/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0019  \n",
      "Epoch 770/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0019 \n",
      "Epoch 771/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0019  \n",
      "Epoch 772/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 \n",
      "Epoch 773/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0019  \n",
      "Epoch 774/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 \n",
      "Epoch 775/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0019 \n",
      "Epoch 776/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0019 \n",
      "Epoch 777/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0019 \n",
      "Epoch 778/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0019  \n",
      "Epoch 779/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 \n",
      "Epoch 780/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 \n",
      "Epoch 781/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - loss: 0.0019\n",
      "Epoch 782/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0019  \n",
      "Epoch 783/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0019  \n",
      "Epoch 784/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0019 \n",
      "Epoch 785/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 \n",
      "Epoch 786/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 \n",
      "Epoch 787/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0019 \n",
      "Epoch 788/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0019  \n",
      "Epoch 789/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0019  \n",
      "Epoch 790/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0019  \n",
      "Epoch 791/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0019 \n",
      "Epoch 792/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 \n",
      "Epoch 793/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0019  \n",
      "Epoch 794/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0019  \n",
      "Epoch 795/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 \n",
      "Epoch 796/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 \n",
      "Epoch 797/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0019  \n",
      "Epoch 798/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0018  \n",
      "Epoch 799/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0018 \n",
      "Epoch 800/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0018  \n",
      "Epoch 801/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0018  \n",
      "Epoch 802/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018 \n",
      "Epoch 803/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0018  \n",
      "Epoch 804/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0018  \n",
      "Epoch 805/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 \n",
      "Epoch 806/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018 \n",
      "Epoch 807/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0018 \n",
      "Epoch 808/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 \n",
      "Epoch 809/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 \n",
      "Epoch 810/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0018  \n",
      "Epoch 811/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0018  \n",
      "Epoch 812/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 \n",
      "Epoch 813/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0018 \n",
      "Epoch 814/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0018  \n",
      "Epoch 815/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0018 \n",
      "Epoch 816/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018 \n",
      "Epoch 817/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 \n",
      "Epoch 818/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0018  \n",
      "Epoch 819/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0018 \n",
      "Epoch 820/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0018  \n",
      "Epoch 821/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 \n",
      "Epoch 822/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 \n",
      "Epoch 823/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0018 \n",
      "Epoch 824/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0018  \n",
      "Epoch 825/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0018  \n",
      "Epoch 826/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0018  \n",
      "Epoch 827/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 0.0018\n",
      "Epoch 828/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0018 \n",
      "Epoch 829/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0017  \n",
      "Epoch 830/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 \n",
      "Epoch 831/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 \n",
      "Epoch 832/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0018 \n",
      "Epoch 833/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0017  \n",
      "Epoch 834/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0017 \n",
      "Epoch 835/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 \n",
      "Epoch 836/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0017  \n",
      "Epoch 837/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 \n",
      "Epoch 838/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0017  \n",
      "Epoch 839/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0017 \n",
      "Epoch 840/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0017  \n",
      "Epoch 841/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 0.0017\n",
      "Epoch 842/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - loss: 0.0017\n",
      "Epoch 843/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - loss: 0.0017\n",
      "Epoch 844/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0017 \n",
      "Epoch 845/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0017  \n",
      "Epoch 846/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0017 \n",
      "Epoch 847/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 \n",
      "Epoch 848/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0017  \n",
      "Epoch 849/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0017 \n",
      "Epoch 850/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0017  \n",
      "Epoch 851/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0017 \n",
      "Epoch 852/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0017  \n",
      "Epoch 853/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0017 \n",
      "Epoch 854/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 \n",
      "Epoch 855/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0017  \n",
      "Epoch 856/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0017  \n",
      "Epoch 857/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0017  \n",
      "Epoch 858/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0017 \n",
      "Epoch 859/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0017  \n",
      "Epoch 860/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0017 \n",
      "Epoch 861/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0017 \n",
      "Epoch 862/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0017 \n",
      "Epoch 863/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0017  \n",
      "Epoch 864/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0017  \n",
      "Epoch 865/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0016  \n",
      "Epoch 866/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0017 \n",
      "Epoch 867/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 \n",
      "Epoch 868/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0016  \n",
      "Epoch 869/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - loss: 0.0016\n",
      "Epoch 870/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0016 \n",
      "Epoch 871/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0016  \n",
      "Epoch 872/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0016 \n",
      "Epoch 873/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0016  \n",
      "Epoch 874/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0016  \n",
      "Epoch 875/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0016 \n",
      "Epoch 876/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0016  \n",
      "Epoch 877/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0016 \n",
      "Epoch 878/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0016  \n",
      "Epoch 879/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0016  \n",
      "Epoch 880/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0016 \n",
      "Epoch 881/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016 \n",
      "Epoch 882/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0016  \n",
      "Epoch 883/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 \n",
      "Epoch 884/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0016 \n",
      "Epoch 885/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0016  \n",
      "Epoch 886/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 \n",
      "Epoch 887/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0016  \n",
      "Epoch 888/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0016 \n",
      "Epoch 889/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0016  \n",
      "Epoch 890/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0016 \n",
      "Epoch 891/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 \n",
      "Epoch 892/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0016 \n",
      "Epoch 893/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0016  \n",
      "Epoch 894/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0016  \n",
      "Epoch 895/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 \n",
      "Epoch 896/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0016  \n",
      "Epoch 897/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0016 \n",
      "Epoch 898/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0016  \n",
      "Epoch 899/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 0.0016\n",
      "Epoch 900/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0016  \n",
      "Epoch 901/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0016  \n",
      "Epoch 902/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79us/step - loss: 0.0016\n",
      "Epoch 903/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0016  \n",
      "Epoch 904/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0016 \n",
      "Epoch 905/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0016  \n",
      "Epoch 906/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47us/step - loss: 0.0016\n",
      "Epoch 907/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0015 \n",
      "Epoch 908/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0015 \n",
      "Epoch 909/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0015  \n",
      "Epoch 910/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - loss: 0.0015\n",
      "Epoch 911/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 \n",
      "Epoch 912/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - loss: 0.0015\n",
      "Epoch 913/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - loss: 0.0015\n",
      "Epoch 914/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0015  \n",
      "Epoch 915/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0015 \n",
      "Epoch 916/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0015 \n",
      "Epoch 917/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0015  \n",
      "Epoch 918/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0015 \n",
      "Epoch 919/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0015  \n",
      "Epoch 920/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0015 \n",
      "Epoch 921/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0015  \n",
      "Epoch 922/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0015  \n",
      "Epoch 923/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - loss: 0.0015\n",
      "Epoch 924/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0015 \n",
      "Epoch 925/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0015  \n",
      "Epoch 926/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0015  \n",
      "Epoch 927/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0015  \n",
      "Epoch 928/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0015 \n",
      "Epoch 929/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0015 \n",
      "Epoch 930/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0015  \n",
      "Epoch 931/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - loss: 0.0015\n",
      "Epoch 932/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0015  \n",
      "Epoch 933/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 \n",
      "Epoch 934/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - loss: 0.0015\n",
      "Epoch 935/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0015 \n",
      "Epoch 936/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0015  \n",
      "Epoch 937/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436us/step - loss: 0.0015\n",
      "Epoch 938/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0015 \n",
      "Epoch 939/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0015  \n",
      "Epoch 940/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0015  \n",
      "Epoch 941/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0015 \n",
      "Epoch 942/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0015  \n",
      "Epoch 943/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0015  \n",
      "Epoch 944/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0015  \n",
      "Epoch 945/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0015  \n",
      "Epoch 946/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0015  \n",
      "Epoch 947/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0015 \n",
      "Epoch 948/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 \n",
      "Epoch 949/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0015 \n",
      "Epoch 950/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 \n",
      "Epoch 951/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0015  \n",
      "Epoch 952/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0015 \n",
      "Epoch 953/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0014 \n",
      "Epoch 954/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0014  \n",
      "Epoch 955/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0015  \n",
      "Epoch 956/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0014 \n",
      "Epoch 957/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0014 \n",
      "Epoch 958/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - loss: 0.0014\n",
      "Epoch 959/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 \n",
      "Epoch 960/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0014  \n",
      "Epoch 961/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0014 \n",
      "Epoch 962/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0014 \n",
      "Epoch 963/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0014  \n",
      "Epoch 964/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0014 \n",
      "Epoch 965/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0014  \n",
      "Epoch 966/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - loss: 0.0014\n",
      "Epoch 967/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0014  \n",
      "Epoch 968/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0014  \n",
      "Epoch 969/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0014 \n",
      "Epoch 970/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0014  \n",
      "Epoch 971/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0014  \n",
      "Epoch 972/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0014  \n",
      "Epoch 973/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0014  \n",
      "Epoch 974/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0014  \n",
      "Epoch 975/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0014  \n",
      "Epoch 976/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0014  \n",
      "Epoch 977/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0014  \n",
      "Epoch 978/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0014  \n",
      "Epoch 979/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 \n",
      "Epoch 980/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0014  \n",
      "Epoch 981/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0014  \n",
      "Epoch 982/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0014 \n",
      "Epoch 983/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0014  \n",
      "Epoch 984/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0014 \n",
      "Epoch 985/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0014 \n",
      "Epoch 986/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 \n",
      "Epoch 987/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0014  \n",
      "Epoch 988/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0014 \n",
      "Epoch 989/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0014  \n",
      "Epoch 990/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0014  \n",
      "Epoch 991/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0014 \n",
      "Epoch 992/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0014  \n",
      "Epoch 993/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0014 \n",
      "Epoch 994/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0014  \n",
      "Epoch 995/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0014  \n",
      "Epoch 996/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 \n",
      "Epoch 997/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0014  \n",
      "Epoch 998/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0014 \n",
      "Epoch 999/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0014 \n",
      "Epoch 1000/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - loss: 0.0014  \n"
     ]
    }
   ],
   "source": [
    "# 훈련\n",
    "# batch_size 는 한 번에 연산되는 데이터의 크기 (Mini Batch)\n",
    "history = model.fit(X, y, epochs = 1000, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0f91143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "[[0.03672937]\n",
      " [0.96333104]\n",
      " [0.96284646]\n",
      " [0.03672937]]\n"
     ]
    }
   ],
   "source": [
    "# 결과 확인\n",
    "result = model.predict(X)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9b654c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x18be82eb910>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA5BklEQVR4nO3de3yU5Z3///c9M8lMEpLhEMgBQgwnCVA5BOUktrUaz6vdds22CvZbbZdd24L8um0pta3sutTutg+qK6itlp91xdivWt2WVmNrQUo8xcQTiApIIiSEAMnkQDLJzP39Y5KBMQlmkknuObyej8f9yOSe677zmSvYvHvd133dhmmapgAAAKKYzeoCAAAAPgmBBQAARD0CCwAAiHoEFgAAEPUILAAAIOoRWAAAQNQjsAAAgKhHYAEAAFHPYXUBkeL3+3XkyBGlp6fLMAyrywEAAANgmqaam5uVm5srm63/cZS4CSxHjhxRXl6e1WUAAIBBqKmp0aRJk/p9P24CS3p6uqTAB87IyLC4GgAAMBAej0d5eXnBv+P9iZvA0nMZKCMjg8ACAECM+aTpHEy6BQAAUY/AAgAAoh6BBQAARD0CCwAAiHoEFgAAEPUILAAAIOoRWAAAQNQjsAAAgKhHYAEAAFFvUIFl8+bNKigokMvlUlFRkV588cV+2z755JO69NJLNX78eGVkZGjJkiV69tlnQ9ps3bpVhmH02trb2wdTHgAAiDNhB5bS0lKtWbNG69evV2VlpZYvX64rrrhC1dXVfbbfuXOnLr30Um3fvl0VFRX67Gc/q2uuuUaVlZUh7TIyMlRbWxuyuVyuwX0qAAAQVwzTNM1wDli0aJEWLFigLVu2BPcVFhbquuuu08aNGwd0jtmzZ6ukpEQ//OEPJQVGWNasWaPGxsZwSgnh8XjkdrvV1NTEs4QAAIgRA/37HdYIi9frVUVFhYqLi0P2FxcXa/fu3QM6h9/vV3Nzs8aOHRuyv6WlRfn5+Zo0aZKuvvrqXiMwH9fR0SGPxxOyRZppmnr81Rr9029e08lWb8TPDwAABiaswNLQ0CCfz6esrKyQ/VlZWaqrqxvQOX72s5+ptbVV119/fXDfzJkztXXrVj3zzDPatm2bXC6Xli1bpvfff7/f82zcuFFutzu45eXlhfNRBsQwDD30t4N69p2jemFffcTPDwAABmZQk24//gho0zQ/8bHQkrRt2zb9+Mc/VmlpqSZMmBDcv3jxYt14442aO3euli9frscff1wzZszQPffc0++51q1bp6ampuBWU1MzmI/yiS4pDISzP+8lsAAAYJWwAktmZqbsdnuv0ZT6+vpeoy4fV1paqptvvlmPP/64LrnkkrMXZbPp/PPPP+sIi9PpVEZGRsg2HD5XGAhWO947Jm+Xf1h+BgAAOLuwAktycrKKiopUVlYWsr+srExLly7t97ht27bpK1/5ih599FFdddVVn/hzTNNUVVWVcnJywilvWMydNFqZo5xq6ejSKwdPWF0OAAAJKexLQmvXrtWvfvUrPfTQQ9q7d69uu+02VVdXa9WqVZICl2pWrlwZbL9t2zatXLlSP/vZz7R48WLV1dWprq5OTU1NwTZ33HGHnn32WR04cEBVVVW6+eabVVVVFTynlWw2QxfPHC9Jen7vUYurAQAgMYUdWEpKSrRp0yZt2LBB8+bN086dO7V9+3bl5+dLkmpra0PWZLn//vvV1dWlW2+9VTk5OcFt9erVwTaNjY36+te/rsLCQhUXF+vw4cPauXOnLrjgggh8xKH7XM88lnePKsy7wAEAQASEvQ5LtBrOdVjavF2at6FM3i6/nrvtIs3ISo/o+QEASFTDsg5LokpNdmjp1HGSuCwEAIAVCCwD9DlubwYAwDIElgH63MzA7c2vV5/U8ZYOi6sBACCxEFgGKHd0imblZMg0pRf2HbO6HAAAEgqBJQyXdC8i92fmsQAAMKIILGG4ZFZgHsvO946po8tncTUAACQOAksY5uS6NSHdqVavTy8dYNVbAABGCoElDDabEXy2EJeFAAAYOQSWMH1u5unbm+NkzT0AAKIegSVMy6Zlyumw6XDjKb1b12x1OQAAJAQCS5hSku26cFqmJC4LAQAwUggsg9Cz6u3zrHoLAMCIILAMQs/E2zc+alQDq94CADDsCCyDkJXh0szsdJmm9NqH3N4MAMBwI7AMUlH+GElSxaGTFlcCAED8I7AMEoEFAICRQ2AZpJ7A8vZhj9o7WaYfAIDhRGAZpMljU5Wd4ZLX59crB5nHAgDAcCKwDJJhGPr0jPGSpB3vHbO4GgAA4huBZQg+fW4gsPx1H+uxAAAwnAgsQ7BsWqbsNkP7j7Wq5kSb1eUAABC3CCxD4E5J0oLJoyVJf3mXURYAAIYLgWWILpudLUl6qvKwxZUAABC/CCxDdM3cXEmBZfob27wWVwMAQHwisAxRVoZL0yaMkmlKLx04bnU5AADEJQJLBCybOk6S9LcPCCwAAAwHAksELJmaKUl6lQchAgAwLAgsETAvb7Qk6f36FpbpBwBgGBBYIiArw6nMUcny+U29+VGT1eUAABB3CCwRYBiGLpwWuCz0p7frLK4GAID4Q2CJkEtnBdZjeeVDJt4CABBpBJYIOW+SW5K0r65Z3i6/xdUAABBfCCwRMmlMisamJavTZ+q1Q9wtBABAJBFYIsQwDF1amCVJeu6doxZXAwBAfCGwRNCF0wMTb1+vPmlxJQAAxBcCSwTN735y854jHtZjAQAggggsETRxdIrGpzvV5Tf19mHWYwEAIFIILBFkGEZw1duqmkZLawEAIJ4QWCKs57JQZXWjpXUAABBPCCwRNj9vjCSpkom3AABEDIElws6b5JbNkI40teuop93qcgAAiAsElghLczo0IytdEpeFAACIFALLMJg/ufuyUA2XhQAAiAQCyzBg4i0AAJFFYBkG87tvbX7royZ1+XgQIgAAQ0VgGQZTx49SutOhU50+7TvabHU5AADEPALLMLDZDM3jshAAABFDYBkmPZeFCCwAAAwdgWWY9IywVHGnEAAAQ0ZgGSbzule83X+sVU1tnRZXAwBAbCOwDJOxack6Z1yqJKnqo0ZriwEAIMYRWIZRcAE5nisEAMCQEFiG0bzuibdVNY2W1gEAQKwjsAyjM1e8NU3T2mIAAIhhBJZhNDM7Q06HTU2nOnWwodXqcgAAiFkElmGU7LBpzkS3JNZjAQBgKAYVWDZv3qyCggK5XC4VFRXpxRdf7Lftk08+qUsvvVTjx49XRkaGlixZomeffbZXuyeeeEKzZs2S0+nUrFmz9NRTTw2mtKjTM4/lTe4UAgBg0MIOLKWlpVqzZo3Wr1+vyspKLV++XFdccYWqq6v7bL9z505deuml2r59uyoqKvTZz35W11xzjSorK4NtysvLVVJSohUrVuiNN97QihUrdP311+vll18e/CeLEoU5GZKk9462WFwJAACxyzDDnA26aNEiLViwQFu2bAnuKyws1HXXXaeNGzcO6ByzZ89WSUmJfvjDH0qSSkpK5PF49Mc//jHY5vLLL9eYMWO0bdu2AZ3T4/HI7XarqalJGRkZYXyi4fXmR436u//+m8alJavi9kutLgcAgKgy0L/fYY2weL1eVVRUqLi4OGR/cXGxdu/ePaBz+P1+NTc3a+zYscF95eXlvc552WWXnfWcHR0d8ng8IVs0mj4hXQ6boeOtXlUfb7O6HAAAYlJYgaWhoUE+n09ZWVkh+7OyslRXVzegc/zsZz9Ta2urrr/++uC+urq6sM+5ceNGud3u4JaXlxfGJxk5Kcn24O3Nu/c3WFsMAAAxalCTbg3DCPneNM1e+/qybds2/fjHP1ZpaakmTJgwpHOuW7dOTU1Nwa2mpiaMTzCyivIDo0lvHW6yuBIAAGKTI5zGmZmZstvtvUY+6uvre42QfFxpaaluvvlm/fa3v9Ull1wS8l52dnbY53Q6nXI6neGUb5nCnHRJ0t7a6LxsBQBAtAtrhCU5OVlFRUUqKysL2V9WVqalS5f2e9y2bdv0la98RY8++qiuuuqqXu8vWbKk1zmfe+65s54zlszqvlPo3bpm+f2seAsAQLjCGmGRpLVr12rFihVauHChlixZogceeEDV1dVatWqVpMClmsOHD+vhhx+WFAgrK1eu1C9+8QstXrw4OJKSkpIitzuwqNrq1at10UUX6a677tK1116rp59+Ws8//7x27doVqc9pqYLMNCU7bGrz+lR9ok3nZKZZXRIAADEl7DksJSUl2rRpkzZs2KB58+Zp586d2r59u/Lz8yVJtbW1IWuy3H///erq6tKtt96qnJyc4LZ69epgm6VLl+qxxx7Tr3/9a5133nnaunWrSktLtWjRogh8ROs57Dadm8VlIQAABivsdViiVbSuw9LjO//3DT3+2kf61sXTtLb4XKvLAQAgKgzLOiwYvJ4Vb/fUNltcCQAAsYfAMkJ6AguXhAAACB+BZYQUZgcCy+HGU2o61WlxNQAAxBYCywhxpyZp4ugUSdK7jLIAABAWAssIYgE5AAAGh8Aygk7PY2HiLQAA4SCwjKBgYKljhAUAgHAQWEZQT2DZV9esLp/f4moAAIgdBJYRlD82VanJdnV0+fXh8VarywEAIGYQWEaQzWbo3OzAxFsWkAMAYOAILCOMBeQAAAgfgWWEEVgAAAgfgWWEzWItFgAAwkZgGWHndi/Rf9TToROtXourAQAgNhBYRtgop0OTx6ZKYpQFAICBIrBYgCX6AQAID4HFAj0Tb/cQWAAAGBACiwV4phAAAOEhsFhgVndg+aCeJfoBABgIAosFJo5OkSvJpk6fqZqTp6wuBwCAqEdgsYDNZmhK5ihJ0v76FourAQAg+hFYLDJ1QndgOUZgAQDgkxBYLDJtPIEFAICBIrBYZOqENEnS/mOtFlcCAED0I7BYZPqEwOJx++qa5fObFlcDAEB0I7BYZNqEUUpNtqulo0sHuCwEAMBZEVgsYrcZmp0bWI/lrcNNFlcDAEB0I7BYaEZW4LLQB9zaDADAWRFYLDS9+9bm9wksAACcFYHFQtMZYQEAYEAILBaa1j3Ccuh4qzq6fBZXAwBA9CKwWGhCulPpLof8pnSwgfVYAADoD4HFQoZhnJ7HcpTLQgAA9IfAYrFpTLwFAOATEVgs1rPiLU9tBgCgfwQWi03L6hlhaba4EgAAoheBxWI9T20+2NCqLp/f4moAAIhOBBaLTRydopQkuzp9pg6daLO6HAAAohKBxWI2m3F64i13CgEA0CcCSxToubX5A+axAADQJwJLFJgaDCyMsAAA0BcCSxTgIYgAAJwdgSUK9DwEcf+xFvn9psXVAAAQfQgsUSBvTIqS7Ta1d/p1uPGU1eUAABB1CCxRwGG3acr4NEksIAcAQF8ILFGCW5sBAOgfgSVK8BBEAAD6R2CJEj0PQeTWZgAAeiOwRInpWafXYjFN7hQCAOBMBJYocc64NNlthlo6ulTnabe6HAAAogqBJUokO2zKH5cqictCAAB8HIElikznTiEAAPpEYIkiPRNvuVMIAIBQBJYoMo2nNgMA0CcCSxSZOj4QWA42tFlcCQAA0YXAEkUmjw1Mum1o6dApr8/iagAAiB4ElijiTk1SusshSao5ySgLAAA9BhVYNm/erIKCArlcLhUVFenFF1/st21tba2+/OUv69xzz5XNZtOaNWt6tdm6dasMw+i1tbcn3nokPbc2f9jQanElAABEj7ADS2lpqdasWaP169ersrJSy5cv1xVXXKHq6uo+23d0dGj8+PFav3695s6d2+95MzIyVFtbG7K5XK5wy4t53CkEAEBvYQeWn//857r55pt1yy23qLCwUJs2bVJeXp62bNnSZ/tzzjlHv/jFL7Ry5Uq53e5+z2sYhrKzs0O2RDQjKxBY3q3jTiEAAHqEFVi8Xq8qKipUXFwcsr+4uFi7d+8eUiEtLS3Kz8/XpEmTdPXVV6uysvKs7Ts6OuTxeEK2eDAzOxBY9tXFx+cBACASwgosDQ0N8vl8ysrKCtmflZWlurq6QRcxc+ZMbd26Vc8884y2bdsml8ulZcuW6f333+/3mI0bN8rtdge3vLy8Qf/8aHJud2A5cKxV3i6/xdUAABAdBjXp1jCMkO9N0+y1LxyLFy/WjTfeqLlz52r58uV6/PHHNWPGDN1zzz39HrNu3To1NTUFt5qamkH//GiS43Yp3eVQl9/UgQbmsQAAIIUZWDIzM2W323uNptTX1/cadRlSUTabzj///LOOsDidTmVkZIRs8cAwjOCKt/vruVMIAAApzMCSnJysoqIilZWVhewvKyvT0qVLI1aUaZqqqqpSTk5OxM4ZS6aN71minxEWAAAkyRHuAWvXrtWKFSu0cOFCLVmyRA888ICqq6u1atUqSYFLNYcPH9bDDz8cPKaqqkpSYGLtsWPHVFVVpeTkZM2aNUuSdMcdd2jx4sWaPn26PB6P7r77blVVVenee++NwEeMPVN7RliOEVgAAJAGEVhKSkp0/PhxbdiwQbW1tZozZ462b9+u/Px8SYGF4j6+Jsv8+fODrysqKvToo48qPz9fH374oSSpsbFRX//611VXVye326358+dr586duuCCC4bw0WJXzzOFCCwAAAQYpmmaVhcRCR6PR263W01NTTE/n+XAsRZd/LMdSkmy6507LpPNNvgJzQAARLOB/v3mWUJRaPLYVCXZDZ3q9OlI0ymrywEAwHIElijksNt0zrg0SdL+Y9wpBAAAgSVKBeexcKcQAAAElmg1dULPCAuBBQAAAkuUmspaLAAABBFYolRwtVvmsAAAQGCJVlO6R1gaWjrU1NZpcTUAAFiLwBKlRjkdys5wSZL28xBEAECCI7BEsZ6Jt8xjAQAkOgJLFJvGEv0AAEgisES14EMQ65l4CwBIbASWKNZza/MBRlgAAAmOwBLFegLLoRNt8nb5La4GAADrEFiiWFaGU6OcDvn8pg4d57IQACBxEViimGEYmjqeJfoBACCwRDmW6AcAgMAS9aayRD8AAASWaDeVtVgAACCwRLtp3avd7q9vkWmaFlcDAIA1CCxRbvLYNNlthlq9PtV52q0uBwAASxBYolyyw6b8samSWPEWAJC4CCwxYArzWAAACY7AEgOmTSCwAAASG4ElBvQsHsdaLACAREVgiQFTGWEBACQ4AksM6FmL5ainQ83tnRZXAwDAyCOwxAB3SpLGpzslSQdY8RYAkIAILDGCeSwAgERGYIkRwYcgMo8FAJCACCwxYnr3xNv36potrgQAgJFHYIkRcya6JUlvH2myuBIAAEYegSVGFOZkyDACdwodb+mwuhwAAEYUgSVGpDkdmjQmRZL0PhNvAQAJhsASQ6ZPSJckvX+UeSwAgMRCYIkh07MCE28ZYQEAJBoCSwzpGWF5jxEWAECCIbDEkBk9IyxHGWEBACQWAksMmda9FsvxVi93CgEAEgqBJYakJjuUNzZwp9B7jLIAABIIgSXGzOi5U6ieeSwAgMRBYIkxM7KZeAsASDwElhjTM/GWS0IAgERCYIkxZ97abJqmxdUAADAyCCwxZtqEUbIZUmNbp45xpxAAIEEQWGKMK8mu/HFpkliPBQCQOAgsMWh693os++qYeAsASAwElhg0I4tbmwEAiYXAEoNO39rMJSEAQGIgsMSg4K3NddwpBABIDASWGFSQmSa7zVBzR5fqPO1WlwMAwLAjsMQgp8Ouc8alSuKyEAAgMRBYYtS53fNY3meJfgBAAiCwxKieFW+5tRkAkAgILDGq59bm9+q5JAQAiH8Elhh1bnbgTqEPjjbL7+dOIQBAfCOwxKj8cWlKshtq9fp0uPGU1eUAADCsCCwxKsluC14WeudIk8XVAAAwvAYVWDZv3qyCggK5XC4VFRXpxRdf7LdtbW2tvvzlL+vcc8+VzWbTmjVr+mz3xBNPaNasWXI6nZo1a5aeeuqpwZSWUObkuiVJbx/2WFwJAADDK+zAUlpaqjVr1mj9+vWqrKzU8uXLdcUVV6i6urrP9h0dHRo/frzWr1+vuXPn9tmmvLxcJSUlWrFihd544w2tWLFC119/vV5++eVwy0socyZmSJLeZoQFABDnDDPMtd0XLVqkBQsWaMuWLcF9hYWFuu6667Rx48azHvuZz3xG8+bN06ZNm0L2l5SUyOPx6I9//GNw3+WXX64xY8Zo27ZtA6rL4/HI7XarqalJGRkZA/9AMez16pP6+827lTkqWa+uv0SGYVhdEgAAYRno3++wRli8Xq8qKipUXFwcsr+4uFi7d+8eXKUKjLB8/JyXXXbZWc/Z0dEhj8cTsiWawuwM2QypocWr+uYOq8sBAGDYhBVYGhoa5PP5lJWVFbI/KytLdXV1gy6irq4u7HNu3LhRbrc7uOXl5Q3658eqlGS7powP3N68pzbxAhsAIHEMatLtxy89mKY55MsR4Z5z3bp1ampqCm41NTVD+vmxalZOYPhszxECCwAgfoUVWDIzM2W323uNfNTX1/caIQlHdnZ22Od0Op3KyMgI2RLRrNzuwMIICwAgjoUVWJKTk1VUVKSysrKQ/WVlZVq6dOmgi1iyZEmvcz733HNDOmeiYIQFAJAIHOEesHbtWq1YsUILFy7UkiVL9MADD6i6ulqrVq2SFLhUc/jwYT388MPBY6qqqiRJLS0tOnbsmKqqqpScnKxZs2ZJklavXq2LLrpId911l6699lo9/fTTev7557Vr164IfMT4Nrt7hOXD461q6ejSKGfYv1IAAKJe2H/dSkpKdPz4cW3YsEG1tbWaM2eOtm/frvz8fEmBheI+vibL/Pnzg68rKir06KOPKj8/Xx9++KEkaenSpXrsscf0gx/8QLfffrumTp2q0tJSLVq0aAgfLTGMG+VUjtul2qZ27a316PxzxlpdEgAAERf2OizRKhHXYelxy///qp7fW68fXTNL/2dZgdXlAAAwYMOyDgui02yW6AcAxDkCSxyYMzEQWHgIIgAgXhFY4kDPM4Xer29Re6fP4moAAIg8AkscyM5waWxasnx+U/vqmq0uBwCAiCOwxAHDMIK3N/PkZgBAPCKwxInT81iYeAsAiD8Eljgxp/tOoXcOM8ICAIg/BJY40XNJaG9dszp9fourAQAgsggscWLy2FSlOx3ydvm1/1iL1eUAABBRBJY4YbMZwSc3s4AcACDeEFjiSM/E27eZxwIAiDMEljhy3qRAYKmqabS2EAAAIozAEkfm542RFFiinxVvAQDxhMASR/LGpihzVLI6fSbPFQIAxBUCSxwxDEPzJwdGWV4/1GhtMQAARBCBJc4s6Aks1SctrgQAgMghsMSZ+ZNHSwoEFtM0rS0GAIAIIbDEmfMmuWW3GTrq6dCRpnarywEAICIILHEmNdmhwpx0SdLrh7gsBACIDwSWOFTUPY+lgsACAIgTBJY4tPCcsZKk1w6dsLgSAAAig8AShxaeExhh2XPEo5aOLourAQBg6AgscSjHnaKJo1PkN6Wq6karywEAYMgILHHq/O5Rllc/5LIQACD2EVjiVM88FibeAgDiAYElTvXMY3m9+qS6fH6LqwEAYGgILHFqxoR0pbscavP6tLe22epyAAAYEgJLnLLZDC3MZx4LACA+EFjiGPNYAADxgsASx87vDiyvfniCByECAGIagSWOnTfJrSS7ofrmDh063mZ1OQAADBqBJY65kuya3/1cob/tb7C4GgAABo/AEucunJYpSdr1PoEFABC7CCxx7sLpgcCye/9x+fzMYwEAxCYCS5w7b6Jb6S6Hmk516u3DTVaXAwDAoBBY4pzDbtOSKeMkSbs+4LIQACA2EVgSwPLpzGMBAMQ2AksCWNY98bbi0Em1ebssrgYAgPARWBJAQWaaJo1Jkdfn10sHjltdDgAAYSOwJADDMHTRjPGSpJ3vcVkIABB7CCwJ4tPdgWXHe8csrgQAgPARWBLE0qnj5LAZOtjQqmqW6QcAxBgCS4JIdyVpQX5gmf4d7zPKAgCILQSWBBK8LLSv3uJKAAAID4ElgVw8c4Ikaef7DWrp4PZmAEDsILAkkJnZ6SrITJO3y6+/vMsoCwAgdhBYEohhGLpiTrYkafubtRZXAwDAwBFYEsyVn8qRJL2wr16tXBYCAMQIAkuCmZ2bofxxqero8usFJt8CAGIEgSXBBC4LBUZZtr/FZSEAQGwgsCSgq3ouC717jIchAgBiAoElAc2ZmKFJY1J0qtOnv+5jETkAQPQjsCQgwzCCoyx/4LIQACAGEFgSVM/dQn/ZW69TXp/F1QAAcHYElgR13iS3Jo4OXBba8R53CwEAohuBJUEZhqErPxVYRO4Pb9VZXA0AAGc3qMCyefNmFRQUyOVyqaioSC+++OJZ2+/YsUNFRUVyuVyaMmWK7rvvvpD3t27dKsMwem3t7e2DKQ8D1HNZ6M97j6q9k8tCAIDoFXZgKS0t1Zo1a7R+/XpVVlZq+fLluuKKK1RdXd1n+4MHD+rKK6/U8uXLVVlZqe9///v61re+pSeeeCKkXUZGhmpra0M2l8s1uE+FAZmXN1q5bpfavD6V7TlqdTkAAPQr7MDy85//XDfffLNuueUWFRYWatOmTcrLy9OWLVv6bH/fffdp8uTJ2rRpkwoLC3XLLbfoq1/9qv7rv/4rpJ1hGMrOzg7ZMLwMw9AXiyZJkn7z0iGLqwEAoH9hBRav16uKigoVFxeH7C8uLtbu3bv7PKa8vLxX+8suu0yvvfaaOjs7g/taWlqUn5+vSZMm6eqrr1ZlZWU4pWGQvrRosuw2Q68cPKF9dc1WlwMAQJ/CCiwNDQ3y+XzKysoK2Z+VlaW6ur4nbtbV1fXZvqurSw0NDZKkmTNnauvWrXrmmWe0bds2uVwuLVu2TO+//36/tXR0dMjj8YRsCF+OO0WXFgZ+P48wygIAiFKDmnRrGEbI96Zp9tr3Se3P3L948WLdeOONmjt3rpYvX67HH39cM2bM0D333NPvOTdu3Ci32x3c8vLyBvNRIGnFknxJ0pOvf6QWnuAMAIhCYQWWzMxM2e32XqMp9fX1vUZRemRnZ/fZ3uFwaNy4cX0XZbPp/PPPP+sIy7p169TU1BTcampqwvkoOMPSqeM0ZXyaWr0+PVV52OpyAADoJazAkpycrKKiIpWVlYXsLysr09KlS/s8ZsmSJb3aP/fcc1q4cKGSkpL6PMY0TVVVVSknJ6ffWpxOpzIyMkI2DI5hGLpxUWCU5ZHyQ8ERMAAAokXYl4TWrl2rX/3qV3rooYe0d+9e3XbbbaqurtaqVaskBUY+Vq5cGWy/atUqHTp0SGvXrtXevXv10EMP6cEHH9S3v/3tYJs77rhDzz77rA4cOKCqqirdfPPNqqqqCp4Tw+8LRZPkSrJp39FmvfrhSavLAQAghCPcA0pKSnT8+HFt2LBBtbW1mjNnjrZv3678/MD/Q6+trQ1Zk6WgoEDbt2/XbbfdpnvvvVe5ubm6++679YUvfCHYprGxUV//+tdVV1cnt9ut+fPna+fOnbrgggsi8BExEO6UJF03b6Iee7VGv3npkC4oGGt1SQAABBlmnIz/ezweud1uNTU1cXlokN4+3KSr79mlJLuhv33vYk1IZ+E+AMDwGujfb54lhKA5E92aP3m0On2mHn+VScwAgOhBYEGIFYsDl/a27j6kU16eLwQAiA4EFoS4+rxcTRydooaWDv3PyywkBwCIDgQWhEh22PStz02TJN23Y7/avCwkBwCwHoEFvfz9gkmaPDZVDS1e/aacURYAgPUILOglyW7TNy8OjLLcv/OAWlmuHwBgMQIL+vT5+RN1zrhUnWj16mFGWQAAFiOwoE8Ou03fvHi6JOn+nfvV1NZpcUUAgERGYEG/rp2XqxlZo9TY1qlNf37P6nIAAAmMwIJ+Oew23X71LEnSb8oP6YP6FosrAgAkKgILzmr59PG6pHCCuvym7vzDHqvLAQAkKAILPtH3ryyUw2bohX3HVLbnqNXlAAASEIEFn2jK+FG6ZfkUSdLtv3tbze1MwAUAjCwCCwZkzSXTlT8uVXWedv30T/usLgcAkGAILBgQV5JdGz//KUnSIy8fUsWhExZXBABIJAQWDNjSaZn6h6JJMk3pO//3TZ4zBAAYMQQWhGX9VYWakO7U/mOtuuMZ7hoCAIwMAgvCMjo1WZv+cZ4MQyp9rUZPVx22uiQAQAIgsCBsS6dmBpftX//U2ywoBwAYdgQWDMq3Lp6mRQVj1dLRpa8//JqaTnGrMwBg+BBYMCgOu0333rBAuW6XDjS0avVjlfL5TavLAgDEKQILBi1zlFMPrFwoV5JNf913THf96V2rSwIAxCkCC4ZkzkS3fvrFuZKkB3Ye0K//dtDiigAA8YjAgiH7u7m5+nbxDEnSht/v4c4hAEDEEVgQEbd+dppuWpIv05TWPv6Gfv/mEatLAgDEEQILIsIwDP3omtn6YtEk+fymVj9WRWgBAEQMgQURY7MZuusL5+kLC06HlicqPrK6LABAHCCwIKLsNkM//eJ5wZGW/++3b2jzXz+QaXLLMwBg8AgsiDi7zdBPv3Ce/umiKZKkn/5pn370zDvq8vktrgwAEKsILBgWNpuhdVcW6odXz5JhSA+XH9KND76shpYOq0sDAMQgAguG1VcvLNCWG4qUlmzXSwdO6Jp7dqmqptHqsgAAMYbAgmF3+ZxsPf2NZZoyPk21Te26/r5y/erFA/KzlD8AYIAILBgR0yak6+lbl+my2Vny+vz69z/s1cqHXtGRxlNWlwYAiAEEFoyYdFeS7ruxSHd+fo5cSTbt+qBBl/58hx4u/5DRFgDAWRFYMKIMw9ANi/L1h28tV1H+GLV6ffrh0+/oi/ft1p4jHqvLAwBEKQILLDF1/Cj99p+W6N+una1RToder27UVfe8qG//9g3VNnGZCAAQyjDjZEUvj8cjt9utpqYmZWRkWF0OwlDbdEp3/mGvfv9mrSTJ6bDp5gsLtOozU5XhSrK4OgDAcBro328CC6JGZfVJbdz+rl758IQkaUxqkv7PsgLdtOQcuVMJLgAQjwgsiEmmaer5vfX6yR/3av+xVknSKKdDNy7O11eXnaMJGS6LKwQARBKBBTGty+fX9rfrtPmFD/RuXbMkyWEzdPmcbK1cco7OP2eMDMOwuEoAwFARWBAX/H5Tf3m3Xvft2K/XDp0M7p+Zna4vL5qsqz6Vo3GjnBZWCAAYCgIL4s47R5r0m/JD+l3VYbV3Bh6k6LAZumjGeF07L1fFs7KVkmy3uEoAQDgILIhbTW2deuL1j/S7qsN686Om4P60ZLuKZ2ereFaWls8Yr1FOh4VVAgAGgsCChLD/WIuerjys31UdUfWJtuD+ZLtNS6aO0yWzsvS5mROUOzrFwioBAP0hsCChmKap16sb9ae3a1W256g+PN4W8v6UzDQtnTZOS6dmavGUcRqblmxRpQCAMxFYkLBM09T+Yy0q21Ovsj11qqpp1McfVVSYk6GlU8dpYf4YzZ88RtlubpcGACsQWIBuTac69crBE9q9v0G7PziufUebe7XJcbu0YPIYzZ88WudNGq2ZOemssgsAI4DAAvTjWHOHXjpwXC8dOK7K6ka9W+fpNQIjSXljUzQrJ0OFORnBr5PGpLD+CwBEEIEFGKDWji69+VGTKmtO6vVDjdpzpElHmtr7bJvucmj6hFGaMn6Upo4fpanj0zR1wihNHpuqJDvPEgWAcBFYgCE42erV3jqP9hzxaG9ts/bUevRBfbM6fX3/5+KwGZo8LlXnjEvT5LGpmjQmRZPHpiqve+MWawDoG4EFiDBvl1/7j7UEtvpWHWg4/fpUp++sx45NS1be2FRNGp2ibLdL2RkuZbtdynG7lJUR2JIdjNAASDwD/fvN/+0DBijZYVNh91yWM5mmqTpPu/bXt+rQiVbVnDilmhNtqj7RppqTbWps69SJVq9OtHr1Rk1jv+fPHJXcHWZSNCHDqcy0ZGWmOzUuzanMUYHXmWlOZaQ4mEcDIOEQWIAhMgxDOe4U5bhTdKEye73vae9UzYk21Zxo05HGdtV52lXXFNhqPad0tKlDXp9fDS1eNbR49fZhz1l/XpLdCISY9GSNS3NqbFqy3ClJGpOarNGpSd1bskZ373OnJinDRcgBENsILMAwy3AlaXauW7Nz3X2+b5qmTrR6g0Gmtqldx5o7dLy1Qw3NXjW0dOh4q1cNzR1q7uhSpy8wolPn6XticF/sNkPulCSNTkmSOzVJ6a4kpTsdSnc5NMrpCHzvcmiUy6EMl0OjnKe/T3c5lO5MkivJRugBYBkCC2AxwzA0bpRT40Y5+w01Pdo7fTre6tXxlg41tAQCTeMpr062daqxrVNNp7w62dqpxlOdamzzqrGtU6c6ffL5zeBlqcFy2IxggElLdigl2a7UZLtSkhxKc55+nZpsV6rTrtQku1K726U5z3gv2R7Y1/2e00EQAvDJCCxADHEl2TVxdIomhvFspPZOnzynOrtDjVeNpzrV0t6l5vZOtXR0qbm9S83dX1vaOwNfe/Z3t/GbUpffVGN3MIq0ZIdNLodNriS7nEk2uRynv7qSAqGm56szyS5Xkk1OR+jXj7dLdtiUbLcpqftrssOmpOBXQ067XUkOQ0l2mxw2g9AERDkCCxDnXEmBP/oTMgb3+AHTNNXm9XUHmU552rt0yutTa0eXTnX61Nbz2utTW6dPbR1daut+/fF2bR1dgTZen7xd/uDP8Hb55e3yy9PeFamPHRbDkJLsNjm7A06S3TgdcM4MOyEByOi1z24z5LAbSrIFXifZDTm6A5HDdsbr4FdDDtvp10n2M44LnuOTznW6LRDPBhVYNm/erP/8z/9UbW2tZs+erU2bNmn58uX9tt+xY4fWrl2rd955R7m5ufrOd76jVatWhbR54okndPvtt2v//v2aOnWq7rzzTn3+858fTHkAIsgwDKU5HUpzOiRF7plLXT6/TnX61NHlV3tfXzv96ujyqf2Mr321a/9Yu45Ov9q7AoHI6/Or0+dXZ5cZeN3lV4fPHxKWJMk0T4cmdUTsI44ow1AwKDlshmxnfLUbhuy2j21G93s2yW6zyW4o5H2bETi+5/XHjw226/k5fbTpee/M8wXqkex2W/d5JJtx+njDOPP7wL+/wPeSzXbG6177z9wXOI/9jPaG0VOHer3f8zPtPcfaTn8ffM92+jywRtiBpbS0VGvWrNHmzZu1bNky3X///briiiu0Z88eTZ48uVf7gwcP6sorr9TXvvY1PfLII/rb3/6mf/mXf9H48eP1hS98QZJUXl6ukpIS/du//Zs+//nP66mnntL111+vXbt2adGiRUP/lACijsNuU7rdpnQLfrZpmvL5e0KMqQ6fT50+U53dIScYdrr86vSZ8vp88naZ6ux+r9N3ul2nzwzu6/Kb6ur56very2eq02fK5/ers/s9nz+wr+f9kGN8pjr9gTaBY3va95wz0LavR0mYpuT1+aWzLwmECLB1hx2j3/DUe79hGLJ1ByFDp0NTzzkMnQ5HZ349/X7fx/ScUwo9NjDg1vOzT9ci48wa1Me+wDn7PFbSzRcWKG9sqhXdHv7CcYsWLdKCBQu0ZcuW4L7CwkJdd9112rhxY6/23/3ud/XMM89o7969wX2rVq3SG2+8ofLycklSSUmJPB6P/vjHPwbbXH755RozZoy2bds2oLpYOA5AovD3hBe/vzsQhYaeLr9ffjPQxuc35fdLPjMQnHx+BfZ1v+/vbtPVvS/4ns+UzzSDP6vnveBm9hyrwHnNM177FWwf/Blm72PPfM9vBoLk6Rp6vg/U2/O6532z57V5+rXfDHzW4Gsz0Ff+M471+894fcb++FhCdfg9+S9LtWDymIiec1gWjvN6vaqoqND3vve9kP3FxcXavXt3n8eUl5eruLg4ZN9ll12mBx98UJ2dnUpKSlJ5ebluu+22Xm02bdrUby0dHR3q6Dg9duvxnH3tCgCIFzaboWSboWSxOnKknBmIegKMz9938DHN0yHL3x2efMHjToesM8/jC4aiM45T4OfJ1OngFLIvNLgFjz0jpEk9QUx9H9t9jMyzHGsqdJ+//2OzBzkXLhLCCiwNDQ3y+XzKysoK2Z+VlaW6uro+j6mrq+uzfVdXlxoaGpSTk9Nvm/7OKUkbN27UHXfcEU75AAD0yTC659aIOSrRalDx/OOTjkzTPOtEpL7af3x/uOdct26dmpqagltNTc2A6wcAALElrBGWzMxM2e32XiMf9fX1vUZIemRnZ/fZ3uFwaNy4cWdt0985JcnpdMrpdIZTPgAAiFFhjbAkJyerqKhIZWVlIfvLysq0dOnSPo9ZsmRJr/bPPfecFi5cqKSkpLO26e+cAAAgsYR9W/PatWu1YsUKLVy4UEuWLNEDDzyg6urq4Loq69at0+HDh/Xwww9LCtwR9N///d9au3atvva1r6m8vFwPPvhgyN0/q1ev1kUXXaS77rpL1157rZ5++mk9//zz2rVrV4Q+JgAAiGVhB5aSkhIdP35cGzZsUG1trebMmaPt27crPz9fklRbW6vq6upg+4KCAm3fvl233Xab7r33XuXm5uruu+8OrsEiSUuXLtVjjz2mH/zgB7r99ts1depUlZaWsgYLAACQNIh1WKIV67AAABB7Bvr3m5v4AQBA1COwAACAqEdgAQAAUY/AAgAAoh6BBQAARD0CCwAAiHoEFgAAEPXCXjguWvUsJ+PxeCyuBAAADFTP3+1PWhYubgJLc3OzJCkvL8/iSgAAQLiam5vldrv7fT9uVrr1+/06cuSI0tPTZRhGxM7r8XiUl5enmpoaVtAdZvT1yKCfRwb9PDLo55EzXH1tmqaam5uVm5srm63/mSpxM8Jis9k0adKkYTt/RkYG/zGMEPp6ZNDPI4N+Hhn088gZjr4+28hKDybdAgCAqEdgAQAAUY/A8gmcTqd+9KMfyel0Wl1K3KOvRwb9PDLo55FBP48cq/s6bibdAgCA+MUICwAAiHoEFgAAEPUILAAAIOoRWAAAQNQjsHyCzZs3q6CgQC6XS0VFRXrxxRetLilmbNy4Ueeff77S09M1YcIEXXfdddq3b19IG9M09eMf/1i5ublKSUnRZz7zGb3zzjshbTo6OvTNb35TmZmZSktL09/93d/po48+GsmPElM2btwowzC0Zs2a4D76OXIOHz6sG2+8UePGjVNqaqrmzZunioqK4Pv09dB1dXXpBz/4gQoKCpSSkqIpU6Zow4YN8vv9wTb0c/h27typa665Rrm5uTIMQ7/73e9C3o9Un548eVIrVqyQ2+2W2+3WihUr1NjYOPQPYKJfjz32mJmUlGT+8pe/NPfs2WOuXr3aTEtLMw8dOmR1aTHhsssuM3/961+bb7/9tllVVWVeddVV5uTJk82WlpZgm5/85Cdmenq6+cQTT5hvvfWWWVJSYubk5JgejyfYZtWqVebEiRPNsrIy8/XXXzc/+9nPmnPnzjW7urqs+FhR7ZVXXjHPOecc87zzzjNXr14d3E8/R8aJEyfM/Px88ytf+Yr58ssvmwcPHjSff/5584MPPgi2oa+H7t///d/NcePGmb///e/NgwcPmr/97W/NUaNGmZs2bQq2oZ/Dt337dnP9+vXmE088YUoyn3rqqZD3I9Wnl19+uTlnzhxz9+7d5u7du805c+aYV1999ZDrJ7CcxQUXXGCuWrUqZN/MmTPN733vexZVFNvq6+tNSeaOHTtM0zRNv99vZmdnmz/5yU+Cbdrb2023223ed999pmmaZmNjo5mUlGQ+9thjwTaHDx82bTab+ac//WlkP0CUa25uNqdPn26WlZWZn/70p4OBhX6OnO9+97vmhRde2O/79HVkXHXVVeZXv/rVkH1///d/b954442madLPkfDxwBKpPt2zZ48pyXzppZeCbcrLy01J5rvvvjukmrkk1A+v16uKigoVFxeH7C8uLtbu3bstqiq2NTU1SZLGjh0rSTp48KDq6upC+tjpdOrTn/50sI8rKirU2dkZ0iY3N1dz5szh9/Axt956q6666ipdcsklIfvp58h55plntHDhQv3DP/yDJkyYoPnz5+uXv/xl8H36OjIuvPBC/fnPf9Z7770nSXrjjTe0a9cuXXnllZLo5+EQqT4tLy+X2+3WokWLgm0WL14st9s95H6Pm4cfRlpDQ4N8Pp+ysrJC9mdlZamurs6iqmKXaZpau3atLrzwQs2ZM0eSgv3YVx8fOnQo2CY5OVljxozp1Ybfw2mPPfaYXn/9db366qu93qOfI+fAgQPasmWL1q5dq+9///t65ZVX9K1vfUtOp1MrV66kryPku9/9rpqamjRz5kzZ7Xb5fD7deeed+tKXviSJf9PDIVJ9WldXpwkTJvQ6/4QJE4bc7wSWT2AYRsj3pmn22odP9o1vfENvvvmmdu3a1eu9wfQxv4fTampqtHr1aj333HNyuVz9tqOfh87v92vhwoX6j//4D0nS/Pnz9c4772jLli1auXJlsB19PTSlpaV65JFH9Oijj2r27NmqqqrSmjVrlJubq5tuuinYjn6OvEj0aV/tI9HvXBLqR2Zmpux2e69EWF9f3yuB4uy++c1v6plnntELL7ygSZMmBfdnZ2dL0ln7ODs7W16vVydPnuy3TaKrqKhQfX29ioqK5HA45HA4tGPHDt19991yOBzBfqKfhy4nJ0ezZs0K2VdYWKjq6mpJ/JuOlH/913/V9773Pf3jP/6jPvWpT2nFihW67bbbtHHjRkn083CIVJ9mZ2fr6NGjvc5/7NixIfc7gaUfycnJKioqUllZWcj+srIyLV261KKqYotpmvrGN76hJ598Un/5y19UUFAQ8n5BQYGys7ND+tjr9WrHjh3BPi4qKlJSUlJIm9raWr399tv8Hrp97nOf01tvvaWqqqrgtnDhQt1www2qqqrSlClT6OcIWbZsWa9b89977z3l5+dL4t90pLS1tclmC/3zZLfbg7c108+RF6k+XbJkiZqamvTKK68E27z88stqamoaer8PacpunOu5rfnBBx809+zZY65Zs8ZMS0szP/zwQ6tLiwn//M//bLrdbvOvf/2rWVtbG9za2tqCbX7yk5+YbrfbfPLJJ8233nrL/NKXvtTnbXSTJk0yn3/+efP11183L7744oS+NXEgzrxLyDTp50h55ZVXTIfDYd55553m+++/b/7P//yPmZqaaj7yyCPBNvT10N10003mxIkTg7c1P/nkk2ZmZqb5ne98J9iGfg5fc3OzWVlZaVZWVpqSzJ///OdmZWVlcKmOSPXp5Zdfbp533nlmeXm5WV5ebn7qU5/ituaRcO+995r5+flmcnKyuWDBguAtufhkkvrcfv3rXwfb+P1+80c/+pGZnZ1tOp1O86KLLjLfeuutkPOcOnXK/MY3vmGOHTvWTElJMa+++mqzurp6hD9NbPl4YKGfI+d///d/zTlz5phOp9OcOXOm+cADD4S8T18PncfjMVevXm1OnjzZdLlc5pQpU8z169ebHR0dwTb0c/heeOGFPv83+aabbjJNM3J9evz4cfOGG24w09PTzfT0dPOGG24wT548OeT6DdM0zaGN0QAAAAwv5rAAAICoR2ABAABRj8ACAACiHoEFAABEPQILAACIegQWAAAQ9QgsAAAg6hFYAABA1COwAACAqEdgAQAAUY/AAgAAoh6BBQAARL3/B51SIXdVjZbvAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 측정치 변화량 (손실의 변화량)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec241f40",
   "metadata": {},
   "source": [
    "## DATA API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b7d522",
   "metadata": {},
   "source": [
    "### TF 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ce1b7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_RangeDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>\n"
     ]
    }
   ],
   "source": [
    "# print (dir(tf.data))\n",
    "dataset = tf.data.Dataset.range(10) # 0~9 까지의 데이터를 가지고 데이터셋을 구성\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9028407c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(3, shape=(), dtype=int64)\n",
      "tf.Tensor(4, shape=(), dtype=int64)\n",
      "tf.Tensor(5, shape=(), dtype=int64)\n",
      "tf.Tensor(6, shape=(), dtype=int64)\n",
      "tf.Tensor(7, shape=(), dtype=int64)\n",
      "tf.Tensor(8, shape=(), dtype=int64)\n",
      "tf.Tensor(9, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# 대다수의 데이터 셋은 이터레이터를 구현하고 있음\n",
    "for item in dataset :\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb8805dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4], shape=(5,), dtype=int64)\n",
      "tf.Tensor([5 6 7 8 9], shape=(5,), dtype=int64)\n",
      "tf.Tensor([0 1 2 3 4], shape=(5,), dtype=int64)\n",
      "tf.Tensor([5 6 7 8 9], shape=(5,), dtype=int64)\n",
      "tf.Tensor([0 1 2 3 4], shape=(5,), dtype=int64)\n",
      "tf.Tensor([5 6 7 8 9], shape=(5,), dtype=int64)\n",
      "tf.Tensor([0 1 2 3 4], shape=(5,), dtype=int64)\n",
      "tf.Tensor([5 6 7 8 9], shape=(5,), dtype=int64)\n",
      "tf.Tensor([0 1 2 3 4], shape=(5,), dtype=int64)\n",
      "tf.Tensor([5 6 7 8 9], shape=(5,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# 데이터의 마지막이 batch 개수와 맞지 않으면 drop_reminder = True 를 설정하면\n",
    "# 마지막 배치는 사용하지 않음\n",
    "dataset = dataset.repeat(5).batch(5, drop_remainder = True)\n",
    "for item in dataset :\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af6c8011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 2 4 6 8], shape=(5,), dtype=int64)\n",
      "tf.Tensor([10 12 14 16 18], shape=(5,), dtype=int64)\n",
      "tf.Tensor([0 2 4 6 8], shape=(5,), dtype=int64)\n",
      "tf.Tensor([10 12 14 16 18], shape=(5,), dtype=int64)\n",
      "tf.Tensor([0 2 4 6 8], shape=(5,), dtype=int64)\n",
      "tf.Tensor([10 12 14 16 18], shape=(5,), dtype=int64)\n",
      "tf.Tensor([0 2 4 6 8], shape=(5,), dtype=int64)\n",
      "tf.Tensor([10 12 14 16 18], shape=(5,), dtype=int64)\n",
      "tf.Tensor([0 2 4 6 8], shape=(5,), dtype=int64)\n",
      "tf.Tensor([10 12 14 16 18], shape=(5,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 변환\n",
    "dataset1 = dataset.map(lambda x : x * 2)\n",
    "for item in dataset1 :\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f05f9736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(3, shape=(), dtype=int64)\n",
      "tf.Tensor(4, shape=(), dtype=int64)\n",
      "tf.Tensor(5, shape=(), dtype=int64)\n",
      "tf.Tensor(6, shape=(), dtype=int64)\n",
      "tf.Tensor(7, shape=(), dtype=int64)\n",
      "tf.Tensor(8, shape=(), dtype=int64)\n",
      "tf.Tensor(9, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# 원하는 데이터만 추출\n",
    "dataset = tf.data.Dataset.range(10)\n",
    "dataset = dataset.filter(lambda x : x <10)\n",
    "for item in dataset :\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0314cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# 원하는 데이터만 추출\n",
    "dataset = tf.data.Dataset.range(10)\n",
    "dataset = dataset.take(3)\n",
    "for item in dataset :\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "224f3bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 3 4 2 1 5 8], shape=(7,), dtype=int64)\n",
      "tf.Tensor([6 9 7 2 3 1 4], shape=(7,), dtype=int64)\n",
      "tf.Tensor([6 0 7 9 0 1 2], shape=(7,), dtype=int64)\n",
      "tf.Tensor([8 4 5 5 3 8 9], shape=(7,), dtype=int64)\n",
      "tf.Tensor([7 6], shape=(2,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 shuffling\n",
    "# 경사하강법은 훈련 세트에 있는 데이터들이 독립적이고 동일한 분포를 가졌을 떄\n",
    "# 최고의 성능을 발휘\n",
    "\n",
    "# 셔플링을 할 때 주의 할 점은 랜덤 시드를 부여해서 shuffling 되는 순서를 동일하게 \n",
    "# 만들어야 합니다.\n",
    "\n",
    "dataset = tf.data.Dataset.range(10).repeat(3)\n",
    "dataset = dataset.shuffle(buffer_size = 3, seed = 42).batch(7)\n",
    "for item in dataset :\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b96933",
   "metadata": {},
   "source": [
    "### mnist 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b14cdac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_datasets in c:\\users\\user\\anaconda3\\lib\\site-packages (4.9.4)\n",
      "Requirement already satisfied: absl-py in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (1.4.0)\n",
      "Requirement already satisfied: click in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (8.0.4)\n",
      "Requirement already satisfied: dm-tree in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (0.1.8)\n",
      "Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (1.7.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (1.24.3)\n",
      "Requirement already satisfied: promise in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (2.3)\n",
      "Requirement already satisfied: protobuf>=3.20 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (3.20.3)\n",
      "Requirement already satisfied: psutil in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (5.9.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (2.31.0)\n",
      "Requirement already satisfied: tensorflow-metadata in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (1.14.0)\n",
      "Requirement already satisfied: termcolor in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (2.4.0)\n",
      "Requirement already satisfied: toml in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (0.10.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (4.65.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (1.14.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\anaconda3\\lib\\site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (2023.4.0)\n",
      "Requirement already satisfied: importlib_resources in c:\\users\\user\\anaconda3\\lib\\site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (6.3.1)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\user\\anaconda3\\lib\\site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (4.9.0)\n",
      "Requirement already satisfied: zipp in c:\\users\\user\\anaconda3\\lib\\site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (3.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from click->tensorflow_datasets) (0.4.6)\n",
      "Requirement already satisfied: six in c:\\users\\user\\anaconda3\\lib\\site-packages (from promise->tensorflow_datasets) (1.16.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-metadata->tensorflow_datasets) (1.63.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a33ec4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4, shape=(), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "datasets = tfds.load(name = 'mnist')\n",
    "# dict 형태로 데이터 가져옵니다.\n",
    "#print(type(datasets))\n",
    "\n",
    "# 모든 키 확인\n",
    "# print(datasets.keys())\n",
    "\n",
    "# print(type(datasets['train']))\n",
    "\n",
    "# 하나의 데이터도 dict 로 되어있음\n",
    "for item in datasets['train'] :\n",
    "    #print(type(item))\n",
    "    #print(item.keys())\n",
    "    print(item['label'])\n",
    "    plt.imshow(item['image'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f36763",
   "metadata": {},
   "source": [
    "## Keras 의 NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb92e0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9253fb2f",
   "metadata": {},
   "source": [
    "## 선형 회귀의 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4fd4839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5]\n",
      "[ 5  8 11 14 17]\n"
     ]
    }
   ],
   "source": [
    "# 샘플 데이터 생성\n",
    "X = np.arange(1, 6)\n",
    "y = 3 * X + 2\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96dd112c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#단순 선형 회귀\n",
    "#Layer가 1개면 가능\n",
    "#입력 데이터는 피처가 1개\n",
    "#출력도 하나의 숫자\n",
    "\n",
    "# 첫 번째 층은 입력 구조가 필수\n",
    "# 마지막 층으 뉴런의 개수는 출력하는 데이터의 피처 개수\n",
    "model = tf.keras.Sequential([\n",
    "                        #뉴런의 개수, 활성화 함수, 입력 구조\n",
    "    tf.keras.layers.Dense(1, input_shape = (1, ))\n",
    "])\n",
    "\n",
    "# sequential 모델은 summary로 확인 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0db5ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m2\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (8.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2\u001b[0m (8.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (8.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2\u001b[0m (8.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델의 구조 확인\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08dd4013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "model.compile(optimizer = 'sgd', loss = 'mean_squared_error',\n",
    "              metrics = ['mean_squared_eroor', 'mean_absolute_error']) # 긴 문자열 사용\n",
    "model.compile(optimizer = 'sgd', loss = 'mse',\n",
    "              metrics = ['mse', 'mae']) # 짧은 문자열 사용\n",
    "model.compile(optimizer = tf.keras.optimizers.SGD(learning_rate = 0.05),\n",
    "              loss = tf.keras.losses.MeanSquaredError(),\n",
    "              metrics = [tf.keras.metrics.MeanSquaredError(),\n",
    "                        tf.keras.metrics.MeanAbsoluteError()]) # 세부 조정 가능, 권장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79334d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련\n",
    "history = model.fit(X, y, epochs = 1000, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7e95225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 훈련 과정에서 발생한 손실과 평가지표를 시각화\n",
    "plt.plot(history.history['loss'], label = 'loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7583dcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 3.0923e-12 - mean_absolute_error: 1.3351e-06 - mean_squared_error: 3.0923e-12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.09228207276413e-12, 1.3351440202313825e-06, 3.09228207276413e-12]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 검증 및 예측\n",
    "# 검증\n",
    "model.evaluate(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e0dae1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[32.000008]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측\n",
    "model.predict(np.array([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce146f2",
   "metadata": {},
   "source": [
    "## 레드와 화이트 와인 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51a6c3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4898 entries, 0 to 4897\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         4898 non-null   float64\n",
      " 1   volatile acidity      4898 non-null   float64\n",
      " 2   citric acid           4898 non-null   float64\n",
      " 3   residual sugar        4898 non-null   float64\n",
      " 4   chlorides             4898 non-null   float64\n",
      " 5   free sulfur dioxide   4898 non-null   float64\n",
      " 6   total sulfur dioxide  4898 non-null   float64\n",
      " 7   density               4898 non-null   float64\n",
      " 8   pH                    4898 non-null   float64\n",
      " 9   sulphates             4898 non-null   float64\n",
      " 10  alcohol               4898 non-null   float64\n",
      " 11  quality               4898 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 459.3 KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#데이터 가져온 후 확인 \n",
    "red = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv', sep = \";\")\n",
    "white = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv', sep = \";\")\n",
    "\n",
    "white.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed600c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6497 entries, 0 to 4897\n",
      "Data columns (total 13 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         6497 non-null   float64\n",
      " 1   volatile acidity      6497 non-null   float64\n",
      " 2   citric acid           6497 non-null   float64\n",
      " 3   residual sugar        6497 non-null   float64\n",
      " 4   chlorides             6497 non-null   float64\n",
      " 5   free sulfur dioxide   6497 non-null   float64\n",
      " 6   total sulfur dioxide  6497 non-null   float64\n",
      " 7   density               6497 non-null   float64\n",
      " 8   pH                    6497 non-null   float64\n",
      " 9   sulphates             6497 non-null   float64\n",
      " 10  alcohol               6497 non-null   float64\n",
      " 11  quality               6497 non-null   int64  \n",
      " 12  type                  6497 non-null   int64  \n",
      "dtypes: float64(11), int64(2)\n",
      "memory usage: 710.6 KB\n"
     ]
    }
   ],
   "source": [
    "#타겟 생성\n",
    "red['type'] = 0\n",
    "white['type'] = 1\n",
    "\n",
    "#2개의 데이터를 행 방향으로 합치기\n",
    "wine = pd.concat([red,white], axis = 0)\n",
    "wine.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f93fdd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.215307</td>\n",
       "      <td>0.339666</td>\n",
       "      <td>0.318633</td>\n",
       "      <td>5.443235</td>\n",
       "      <td>0.056034</td>\n",
       "      <td>30.525319</td>\n",
       "      <td>115.744574</td>\n",
       "      <td>0.994697</td>\n",
       "      <td>3.218501</td>\n",
       "      <td>0.531268</td>\n",
       "      <td>10.491801</td>\n",
       "      <td>5.818378</td>\n",
       "      <td>0.753886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.296434</td>\n",
       "      <td>0.164636</td>\n",
       "      <td>0.145318</td>\n",
       "      <td>4.757804</td>\n",
       "      <td>0.035034</td>\n",
       "      <td>17.749400</td>\n",
       "      <td>56.521855</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>0.160787</td>\n",
       "      <td>0.148806</td>\n",
       "      <td>1.192712</td>\n",
       "      <td>0.873255</td>\n",
       "      <td>0.430779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.987110</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>0.992340</td>\n",
       "      <td>3.110000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>0.994890</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.700000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>0.996990</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>11.300000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>65.800000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>1.038980</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    6497.000000       6497.000000  6497.000000     6497.000000   \n",
       "mean        7.215307          0.339666     0.318633        5.443235   \n",
       "std         1.296434          0.164636     0.145318        4.757804   \n",
       "min         3.800000          0.080000     0.000000        0.600000   \n",
       "25%         6.400000          0.230000     0.250000        1.800000   \n",
       "50%         7.000000          0.290000     0.310000        3.000000   \n",
       "75%         7.700000          0.400000     0.390000        8.100000   \n",
       "max        15.900000          1.580000     1.660000       65.800000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  6497.000000          6497.000000           6497.000000  6497.000000   \n",
       "mean      0.056034            30.525319            115.744574     0.994697   \n",
       "std       0.035034            17.749400             56.521855     0.002999   \n",
       "min       0.009000             1.000000              6.000000     0.987110   \n",
       "25%       0.038000            17.000000             77.000000     0.992340   \n",
       "50%       0.047000            29.000000            118.000000     0.994890   \n",
       "75%       0.065000            41.000000            156.000000     0.996990   \n",
       "max       0.611000           289.000000            440.000000     1.038980   \n",
       "\n",
       "                pH    sulphates      alcohol      quality         type  \n",
       "count  6497.000000  6497.000000  6497.000000  6497.000000  6497.000000  \n",
       "mean      3.218501     0.531268    10.491801     5.818378     0.753886  \n",
       "std       0.160787     0.148806     1.192712     0.873255     0.430779  \n",
       "min       2.720000     0.220000     8.000000     3.000000     0.000000  \n",
       "25%       3.110000     0.430000     9.500000     5.000000     1.000000  \n",
       "50%       3.210000     0.510000    10.300000     6.000000     1.000000  \n",
       "75%       3.320000     0.600000    11.300000     6.000000     1.000000  \n",
       "max       4.010000     2.000000    14.900000     9.000000     1.000000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#기술 통계량 확인\n",
    "wine.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "59abb572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.282257</td>\n",
       "      <td>0.173111</td>\n",
       "      <td>0.191948</td>\n",
       "      <td>0.074283</td>\n",
       "      <td>0.078129</td>\n",
       "      <td>0.102518</td>\n",
       "      <td>0.252868</td>\n",
       "      <td>0.146262</td>\n",
       "      <td>0.386435</td>\n",
       "      <td>0.174870</td>\n",
       "      <td>0.361131</td>\n",
       "      <td>0.469730</td>\n",
       "      <td>0.753886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.109758</td>\n",
       "      <td>0.087541</td>\n",
       "      <td>0.072972</td>\n",
       "      <td>0.058195</td>\n",
       "      <td>0.061630</td>\n",
       "      <td>0.130235</td>\n",
       "      <td>0.057811</td>\n",
       "      <td>0.124641</td>\n",
       "      <td>0.083599</td>\n",
       "      <td>0.172857</td>\n",
       "      <td>0.145543</td>\n",
       "      <td>0.430779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.214876</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.150602</td>\n",
       "      <td>0.018405</td>\n",
       "      <td>0.048173</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.163594</td>\n",
       "      <td>0.100829</td>\n",
       "      <td>0.302326</td>\n",
       "      <td>0.117978</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.264463</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.186747</td>\n",
       "      <td>0.036810</td>\n",
       "      <td>0.063123</td>\n",
       "      <td>0.097222</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.149990</td>\n",
       "      <td>0.379845</td>\n",
       "      <td>0.162921</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.322314</td>\n",
       "      <td>0.213333</td>\n",
       "      <td>0.234940</td>\n",
       "      <td>0.115031</td>\n",
       "      <td>0.093023</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.345622</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>0.213483</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    6497.000000       6497.000000  6497.000000     6497.000000   \n",
       "mean        0.282257          0.173111     0.191948        0.074283   \n",
       "std         0.107143          0.109758     0.087541        0.072972   \n",
       "min         0.000000          0.000000     0.000000        0.000000   \n",
       "25%         0.214876          0.100000     0.150602        0.018405   \n",
       "50%         0.264463          0.140000     0.186747        0.036810   \n",
       "75%         0.322314          0.213333     0.234940        0.115031   \n",
       "max         1.000000          1.000000     1.000000        1.000000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  6497.000000          6497.000000           6497.000000  6497.000000   \n",
       "mean      0.078129             0.102518              0.252868     0.146262   \n",
       "std       0.058195             0.061630              0.130235     0.057811   \n",
       "min       0.000000             0.000000              0.000000     0.000000   \n",
       "25%       0.048173             0.055556              0.163594     0.100829   \n",
       "50%       0.063123             0.097222              0.258065     0.149990   \n",
       "75%       0.093023             0.138889              0.345622     0.190476   \n",
       "max       1.000000             1.000000              1.000000     1.000000   \n",
       "\n",
       "                pH    sulphates      alcohol      quality         type  \n",
       "count  6497.000000  6497.000000  6497.000000  6497.000000  6497.000000  \n",
       "mean      0.386435     0.174870     0.361131     0.469730     0.753886  \n",
       "std       0.124641     0.083599     0.172857     0.145543     0.430779  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.302326     0.117978     0.217391     0.333333     1.000000  \n",
       "50%       0.379845     0.162921     0.333333     0.500000     1.000000  \n",
       "75%       0.465116     0.213483     0.478261     0.500000     1.000000  \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#데이터 값을 0 ~ 1로 정규화\n",
    "wine_norm = (wine-wine.min()) / (wine.max() - wine.min())\n",
    "wine_norm.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e50e3a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.30578512 0.10666667 0.1746988  0.00766871 0.06146179 0.11458333\n",
      "  0.1797235  0.05957201 0.24806202 0.09550562 0.5        0.5\n",
      "  1.        ]\n",
      " [0.23966942 0.64       0.04819277 0.02607362 0.09634551 0.0625\n",
      "  0.05990783 0.18064392 0.62015504 0.19662921 0.43478261 0.16666667\n",
      "  0.        ]\n",
      " [0.27272727 0.12       0.19277108 0.2392638  0.05813953 0.10416667\n",
      "  0.37788018 0.17987276 0.34883721 0.08426966 0.46376812 0.33333333\n",
      "  1.        ]\n",
      " [0.51239669 0.2        0.22891566 0.01533742 0.26578073 0.09027778\n",
      "  0.19354839 0.23192597 0.33333333 0.24157303 0.07246377 0.33333333\n",
      "  0.        ]\n",
      " [0.31404959 0.12666667 0.31325301 0.0398773  0.05647841 0.09375\n",
      "  0.33640553 0.08058608 0.23255814 0.1741573  0.49275362 0.5\n",
      "  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "#데이터를 합치다보니 데이터가 정렬이 되어있을 수 있으므로 섞어줘야합니다.\n",
    "wine_shuffle = wine_norm.sample(frac=1)\n",
    "wine_np = wine_shuffle.to_numpy()\n",
    "print(wine_np[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "afcffd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#훈련 데이터와 테스트 데이터 만들기\n",
    "\n",
    "#8-%에 해당하는 인덱스 구하기\n",
    "train_idx = int(len(wine_np) * 0.8)\n",
    "\n",
    "# :-1은 마지막 피처(타겟)뺴고, -1는 마지막 피처(타겟만)\n",
    "train_X, train_y = wine_np[:train_idx, :-1], wine_np[:train_idx, -1]\n",
    "test_X, test_y = wine_np[train_idx:, :-1], wine_np[train_idx:, -1]\n",
    "\n",
    "#타겟을 원핫인코딩 수행\n",
    "#일반 머신러닝 알고리즘에서는 타겟을 원핫인코딩하지 않습니다.\n",
    "train_y = tf.keras.utils.to_categorical(train_y, num_classes = 2)\n",
    "test_y = tf.keras.utils.to_categorical(test_y, num_classes = 2)\n",
    "\n",
    "print(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e20c8af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)             │           \u001b[38;5;34m624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │         \u001b[38;5;34m1,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m300\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m26\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,126</span> (8.30 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,126\u001b[0m (8.30 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,126</span> (8.30 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,126\u001b[0m (8.30 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#분류 모델 생성\n",
    "model = tf.keras.Sequential([\n",
    "    #처음에는 input_shape를 꼭 넣어 줘야함!\n",
    "    tf.keras.layers.Dense(units = 48 , activation = 'relu', input_shape=(12, )),\n",
    "    tf.keras.layers.Dense(units = 24 , activation = 'relu'),\n",
    "    tf.keras.layers.Dense(units = 12 , activation = 'relu'),\n",
    "    #마지막에는 출력의 개수가 unit의 수랑 같아야 함!\n",
    "    #분류에서는 보통 마지막 함수를 일반적으로 softmax를 사용합니다.\n",
    "    tf.keras.layers.Dense(units = 2 , activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.07),\n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "#softmax 함수는 자연로그의 밑이 e인 지수를 사용해 계산한 뒤 모두 더한 값으로 나누는데, 이렇게 나온 결과는 총합이 1.0인 확률 값입니다.\n",
    "#softmax는 분류나 RNN에서 다음 토큰 예측 등 결과값으로 확률이 필요한 분야에서 사용합니다.\n",
    "#이 경우는 [0.97, 0.03]으로 나오는데 앞이 red와인일 확률이고, 1이 white와인일 확률입니다.\n",
    "#시그모이드 처럼 곡선 함수 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "131f4c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#소프트맥스 함수 \n",
    "import math\n",
    "\n",
    "x = np.arange(-2, 2, 0.01)\n",
    "e_x = math.e ** x\n",
    "plt.plot(x, e_x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "45070574",
   "metadata": {},
   "outputs": [],
   "source": [
    "#확률이 높은 사건일수록 정보량이 적다고 판단하기 때문에 엔트로피를 사용합니다.\n",
    "\n",
    "#엔트로피 : 정보이론에 정보량을 나타내기 위해서 사용하는 단위 - 확률의 역수에 로그를 취한 값 : -log(확률)\n",
    "#엔트로피의 기댓값 : 엔트로피 * 확률\n",
    "#엔트로피가 높다는 것은 높은 불확실성을 나타냅니다.\n",
    "#분류 문제에서는 불확실성을 낮추는 방향으로 학습을 진행합니다.\n",
    "#분류 문제에서는 어느 한쪽의 확률이 높은 쪽으로 학습을 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f5e21016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9163 - loss: 0.2037 - val_accuracy: 0.9754 - val_loss: 0.0850\n",
      "Epoch 2/25\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9828 - loss: 0.0651 - val_accuracy: 0.9862 - val_loss: 0.0647\n",
      "Epoch 3/25\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9843 - loss: 0.0600 - val_accuracy: 0.9877 - val_loss: 0.0649\n",
      "Epoch 4/25\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9843 - loss: 0.0630 - val_accuracy: 0.9831 - val_loss: 0.0596\n",
      "Epoch 5/25\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9873 - loss: 0.0469 - val_accuracy: 0.9869 - val_loss: 0.0501\n",
      "Epoch 6/25\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9900 - loss: 0.0420 - val_accuracy: 0.9854 - val_loss: 0.0724\n",
      "Epoch 7/25\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9900 - loss: 0.0397 - val_accuracy: 0.9908 - val_loss: 0.0535\n",
      "Epoch 8/25\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9944 - loss: 0.0256 - val_accuracy: 0.9892 - val_loss: 0.0495\n",
      "Epoch 9/25\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9867 - loss: 0.0422 - val_accuracy: 0.9877 - val_loss: 0.0537\n",
      "Epoch 10/25\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9937 - loss: 0.0248 - val_accuracy: 0.9915 - val_loss: 0.0554\n",
      "Epoch 11/25\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9904 - loss: 0.0355 - val_accuracy: 0.9892 - val_loss: 0.0671\n",
      "Epoch 12/25\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9893 - loss: 0.0293 - val_accuracy: 0.9908 - val_loss: 0.0638\n",
      "Epoch 13/25\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9893 - loss: 0.0377 - val_accuracy: 0.9915 - val_loss: 0.0652\n",
      "Epoch 14/25\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9903 - loss: 0.0415 - val_accuracy: 0.9900 - val_loss: 0.0549\n",
      "Epoch 15/25\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9942 - loss: 0.0267 - val_accuracy: 0.9900 - val_loss: 0.0547\n",
      "Epoch 16/25\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9910 - loss: 0.0278 - val_accuracy: 0.9900 - val_loss: 0.0535\n",
      "Epoch 17/25\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9922 - loss: 0.0361 - val_accuracy: 0.9938 - val_loss: 0.0538\n",
      "Epoch 18/25\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9953 - loss: 0.0319 - val_accuracy: 0.9938 - val_loss: 0.0546\n",
      "Epoch 19/25\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9930 - loss: 0.0306 - val_accuracy: 0.9885 - val_loss: 0.0667\n",
      "Epoch 20/25\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9861 - loss: 0.0338 - val_accuracy: 0.9908 - val_loss: 0.1401\n",
      "Epoch 21/25\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9902 - loss: 0.0552 - val_accuracy: 0.9892 - val_loss: 0.0575\n",
      "Epoch 22/25\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9947 - loss: 0.0287 - val_accuracy: 0.9877 - val_loss: 0.0648\n",
      "Epoch 23/25\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9901 - loss: 0.0366 - val_accuracy: 0.9869 - val_loss: 0.0808\n",
      "Epoch 24/25\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9894 - loss: 0.0429 - val_accuracy: 0.9915 - val_loss: 0.0627\n",
      "Epoch 25/25\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9895 - loss: 0.0440 - val_accuracy: 0.9923 - val_loss: 0.0746\n"
     ]
    }
   ],
   "source": [
    "#훈련\n",
    "#32개씩 가지고 학습\n",
    "#25% 검증 데이터로 만들어서 확인\n",
    "#총 25번 진행\n",
    "history = model.fit(train_X, train_y, epochs = 25, \n",
    "                    batch_size = 32, validation_split = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9302c391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9981 - loss: 0.0139 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.01756390556693077, 0.9969230890274048]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#모델 평가\n",
    "model.evaluate(test_X, test_y)\n",
    "\n",
    "#이진 분류를 할 때는 타겟의 2개의 속성으로 만들어져야 하고, 출력 층에서 unit의 개수는 2개\n",
    "#손실 함수로 cross_entropy를 사용합니다.\n",
    "#출력 층의 activation 함수는 softmax 를 사용합니다.\n",
    "#다중 클래스 분류는 출력 층에서 unit 개수만 변경하면 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6a3dcf",
   "metadata": {},
   "source": [
    "## 다중 클래스 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82eeed46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "       ..\n",
      "4893    6\n",
      "4894    5\n",
      "4895    6\n",
      "4896    7\n",
      "4897    6\n",
      "Name: quality, Length: 6497, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#타켓으로 사용할 특성 확인\n",
    "print(wine['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "980e8b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    6497.000000\n",
      "mean        5.818378\n",
      "std         0.873255\n",
      "min         3.000000\n",
      "25%         5.000000\n",
      "50%         6.000000\n",
      "75%         6.000000\n",
      "max         9.000000\n",
      "Name: quality, dtype: float64\n",
      "quality\n",
      "6    2836\n",
      "5    2138\n",
      "7    1079\n",
      "4     216\n",
      "8     193\n",
      "3      30\n",
      "9       5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(wine['quality'].describe())\n",
    "print(wine['quality'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2e13c179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6을 기준으로 6보다 작으면 0, 6이면 1, 7 이상이면 2로 구간화\n",
    "wine.loc[wine['quality'] <= 5, 'new_quality'] = 0\n",
    "wine.loc[wine['quality'] == 6, 'new_quality'] = 1\n",
    "wine.loc[wine['quality'] >= 7, 'new_quality'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e4bd115c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불필요한 데이터 제거\n",
    "del wine['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f8600e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_backup = wine.copy()\n",
    "\n",
    "# 정규화 - 딥러닝을 할 때는 이 작업을 하지 않아도 되는데 대신에\n",
    "# 이런 경우 epoch 를 늘려주던지 아니면 layer 을 더 많이 쌓아서 해결\n",
    "# MinMax 정규화\n",
    "wine_norm = (wine - wine.min()) / (wine.max() - wine.min())\n",
    "wine_norm['new_quality'] = wine_backup['new_quality']\n",
    "\n",
    "# 셔플 - 데이터를 읽을 때 순서대로 데이터를 읽었기 때문에 셔플을 하지 않으면\n",
    "# 샘플링할 때 어느 한 쪽 데이터가 과표집(많이 표집) 될 수 있습니다. \n",
    "# 여론 조사에서 많이 사용, 컨벤션 효과라는 것 때문에 과표집 문제가 많이 발생합니다.\n",
    "\n",
    "wine_shuffle = wine_norm.sample(frac = 1)\n",
    "# print(type(wine_shuffle))\n",
    "\n",
    "wine_np = wine_shuffle.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "155c7f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = int(len(wine_np) * 0.8)\n",
    "train_X, train_Y = wine_np[:train_idx, :-1], wine_np[:train_idx, -1]\n",
    "test_X, test_Y = wine_np[train_idx :, :-1], wine_np[train_idx :, -1]\n",
    "\n",
    "# 딥러닝을 이용해서 분류를 할 때는 타겟을 원핫인코딩 하는 경우가 많습니다.\n",
    "# 분류를 할때는 activation 을 softmax로 하는 경우가 많은데\n",
    "# soft Max는 각 클래스에 대한 기대값을 확률의 형태로 나타냅니다.\n",
    "# 출력이 여러개의 값으로 구성됩니다.\n",
    "# 가장 기대값이 높은 인덱스에 1을 설정하고 나머지는 0으로 설정\n",
    "\n",
    "train_Y = tf.keras.utils.to_categorical(train_Y, num_classes = 3)\n",
    "test_Y = tf.keras.utils.to_categorical(test_Y, num_classes = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3971ce0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5197, 12)\n",
      "(1300, 12)\n",
      "(5197, 3)\n",
      "(1300, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape)\n",
    "print(test_X.shape)\n",
    "print(train_Y.shape)\n",
    "print(test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6c31a428",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)             │           \u001b[38;5;34m624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │         \u001b[38;5;34m1,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m300\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │            \u001b[38;5;34m78\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m21\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,199</span> (8.59 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,199\u001b[0m (8.59 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,199</span> (8.59 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,199\u001b[0m (8.59 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#분류 모델 생성\n",
    "model = tf.keras.Sequential([\n",
    "    #처음에는 input_shape를 꼭 넣어 줘야함!\n",
    "    tf.keras.layers.Dense(units = 48 , activation = 'relu', input_shape=(12, )),\n",
    "    tf.keras.layers.Dense(units = 24 , activation = 'relu'),\n",
    "    tf.keras.layers.Dense(units = 12 , activation = 'relu'),\n",
    "    tf.keras.layers.Dense(units = 6 , activation = 'relu'),\n",
    "    #마지막에는 출력의 개수가 unit의 수랑 같아야 함!\n",
    "    #분류에서는 보통 마지막 함수를 일반적으로 softmax를 사용합니다.\n",
    "    #분류을 할 때 3가지 모양을 가져야 하므로 마지막 층의 units 만 3으로 수정\n",
    "    tf.keras.layers.Dense(units = 3 , activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.03),\n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fb9e6a25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4204 - loss: 1.0294 - val_accuracy: 0.5577 - val_loss: 0.9162\n",
      "Epoch 2/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5671 - loss: 0.8787 - val_accuracy: 0.5831 - val_loss: 0.9139\n",
      "Epoch 3/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5496 - loss: 0.8865 - val_accuracy: 0.5831 - val_loss: 0.9126\n",
      "Epoch 4/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5718 - loss: 0.8644 - val_accuracy: 0.5662 - val_loss: 0.8857\n",
      "Epoch 5/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5800 - loss: 0.8606 - val_accuracy: 0.5569 - val_loss: 0.9167\n",
      "Epoch 6/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5622 - loss: 0.8807 - val_accuracy: 0.5408 - val_loss: 0.9043\n",
      "Epoch 7/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5677 - loss: 0.8723 - val_accuracy: 0.5869 - val_loss: 0.8920\n",
      "Epoch 8/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5803 - loss: 0.8655 - val_accuracy: 0.5577 - val_loss: 0.8850\n",
      "Epoch 9/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5861 - loss: 0.8456 - val_accuracy: 0.5808 - val_loss: 0.8675\n",
      "Epoch 10/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5675 - loss: 0.8601 - val_accuracy: 0.5754 - val_loss: 0.8721\n",
      "Epoch 11/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5813 - loss: 0.8554 - val_accuracy: 0.5746 - val_loss: 0.8750\n",
      "Epoch 12/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5696 - loss: 0.8511 - val_accuracy: 0.5792 - val_loss: 0.8637\n",
      "Epoch 13/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5624 - loss: 0.8650 - val_accuracy: 0.5723 - val_loss: 0.8934\n",
      "Epoch 14/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5908 - loss: 0.8436 - val_accuracy: 0.5715 - val_loss: 0.9147\n",
      "Epoch 15/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5766 - loss: 0.8492 - val_accuracy: 0.5562 - val_loss: 0.8717\n",
      "Epoch 16/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5788 - loss: 0.8583 - val_accuracy: 0.5377 - val_loss: 0.9260\n",
      "Epoch 17/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5803 - loss: 0.8697 - val_accuracy: 0.5785 - val_loss: 0.8590\n",
      "Epoch 18/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5795 - loss: 0.8472 - val_accuracy: 0.5923 - val_loss: 0.8469\n",
      "Epoch 19/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5851 - loss: 0.8343 - val_accuracy: 0.5738 - val_loss: 0.8606\n",
      "Epoch 20/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5712 - loss: 0.8479 - val_accuracy: 0.5662 - val_loss: 0.8673\n",
      "Epoch 21/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5830 - loss: 0.8404 - val_accuracy: 0.5569 - val_loss: 0.8620\n",
      "Epoch 22/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5854 - loss: 0.8354 - val_accuracy: 0.5638 - val_loss: 0.8723\n",
      "Epoch 23/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5919 - loss: 0.8292 - val_accuracy: 0.5938 - val_loss: 0.8513\n",
      "Epoch 24/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5944 - loss: 0.8335 - val_accuracy: 0.5331 - val_loss: 0.9039\n",
      "Epoch 25/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5943 - loss: 0.8390 - val_accuracy: 0.5938 - val_loss: 0.8541\n",
      "Epoch 26/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5811 - loss: 0.8371 - val_accuracy: 0.5862 - val_loss: 0.8364\n",
      "Epoch 27/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6034 - loss: 0.8199 - val_accuracy: 0.6069 - val_loss: 0.8556\n",
      "Epoch 28/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5907 - loss: 0.8303 - val_accuracy: 0.5685 - val_loss: 0.8616\n",
      "Epoch 29/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6077 - loss: 0.8290 - val_accuracy: 0.5923 - val_loss: 0.8311\n",
      "Epoch 30/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5909 - loss: 0.8383 - val_accuracy: 0.6031 - val_loss: 0.8420\n",
      "Epoch 31/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5963 - loss: 0.8341 - val_accuracy: 0.5854 - val_loss: 0.8446\n",
      "Epoch 32/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6060 - loss: 0.8278 - val_accuracy: 0.5977 - val_loss: 0.8480\n",
      "Epoch 33/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5948 - loss: 0.8222 - val_accuracy: 0.5762 - val_loss: 0.8573\n",
      "Epoch 34/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5849 - loss: 0.8270 - val_accuracy: 0.5792 - val_loss: 0.8701\n",
      "Epoch 35/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5876 - loss: 0.8349 - val_accuracy: 0.6069 - val_loss: 0.8411\n",
      "Epoch 36/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5898 - loss: 0.8270 - val_accuracy: 0.5908 - val_loss: 0.8287\n",
      "Epoch 37/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5898 - loss: 0.8142 - val_accuracy: 0.5838 - val_loss: 0.8371\n",
      "Epoch 38/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5960 - loss: 0.8298 - val_accuracy: 0.5762 - val_loss: 0.8429\n",
      "Epoch 39/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5919 - loss: 0.8223 - val_accuracy: 0.6038 - val_loss: 0.8302\n",
      "Epoch 40/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5920 - loss: 0.8347 - val_accuracy: 0.5962 - val_loss: 0.8287\n",
      "Epoch 41/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5943 - loss: 0.8164 - val_accuracy: 0.5869 - val_loss: 0.8486\n",
      "Epoch 42/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5929 - loss: 0.8280 - val_accuracy: 0.5769 - val_loss: 0.8820\n",
      "Epoch 43/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5959 - loss: 0.8195 - val_accuracy: 0.5962 - val_loss: 0.8453\n",
      "Epoch 44/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5950 - loss: 0.8313 - val_accuracy: 0.6015 - val_loss: 0.8420\n",
      "Epoch 45/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6093 - loss: 0.8330 - val_accuracy: 0.5938 - val_loss: 0.8406\n",
      "Epoch 46/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5926 - loss: 0.8325 - val_accuracy: 0.6031 - val_loss: 0.8191\n",
      "Epoch 47/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6000 - loss: 0.8231 - val_accuracy: 0.6146 - val_loss: 0.8533\n",
      "Epoch 48/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5867 - loss: 0.8257 - val_accuracy: 0.6023 - val_loss: 0.8297\n",
      "Epoch 49/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6219 - loss: 0.8087 - val_accuracy: 0.6092 - val_loss: 0.8293\n",
      "Epoch 50/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5993 - loss: 0.8190 - val_accuracy: 0.5969 - val_loss: 0.8390\n",
      "Epoch 51/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5802 - loss: 0.8281 - val_accuracy: 0.6154 - val_loss: 0.8348\n",
      "Epoch 52/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6097 - loss: 0.8252 - val_accuracy: 0.5754 - val_loss: 0.8510\n",
      "Epoch 53/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6017 - loss: 0.8194 - val_accuracy: 0.5769 - val_loss: 0.8540\n",
      "Epoch 54/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5973 - loss: 0.8239 - val_accuracy: 0.5654 - val_loss: 0.8599\n",
      "Epoch 55/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5914 - loss: 0.8379 - val_accuracy: 0.6108 - val_loss: 0.8350\n",
      "Epoch 56/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6006 - loss: 0.8195 - val_accuracy: 0.5577 - val_loss: 0.8511\n",
      "Epoch 57/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6154 - loss: 0.8150 - val_accuracy: 0.5908 - val_loss: 0.8420\n",
      "Epoch 58/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6089 - loss: 0.8196 - val_accuracy: 0.6046 - val_loss: 0.8374\n",
      "Epoch 59/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5954 - loss: 0.8280 - val_accuracy: 0.5985 - val_loss: 0.8359\n",
      "Epoch 60/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5942 - loss: 0.8366 - val_accuracy: 0.5877 - val_loss: 0.8277\n",
      "Epoch 61/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5884 - loss: 0.8207 - val_accuracy: 0.5715 - val_loss: 0.8460\n",
      "Epoch 62/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6089 - loss: 0.8147 - val_accuracy: 0.6046 - val_loss: 0.8317\n",
      "Epoch 63/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5987 - loss: 0.8182 - val_accuracy: 0.5954 - val_loss: 0.8337\n",
      "Epoch 64/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6141 - loss: 0.8120 - val_accuracy: 0.5823 - val_loss: 0.8426\n",
      "Epoch 65/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6040 - loss: 0.8251 - val_accuracy: 0.5838 - val_loss: 0.8351\n",
      "Epoch 66/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6060 - loss: 0.8176 - val_accuracy: 0.5938 - val_loss: 0.8319\n",
      "Epoch 67/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6057 - loss: 0.8224 - val_accuracy: 0.5808 - val_loss: 0.8455\n",
      "Epoch 68/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6015 - loss: 0.8199 - val_accuracy: 0.5846 - val_loss: 0.8473\n",
      "Epoch 69/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6016 - loss: 0.8219 - val_accuracy: 0.5815 - val_loss: 0.8368\n",
      "Epoch 70/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5858 - loss: 0.8197 - val_accuracy: 0.5777 - val_loss: 0.8486\n",
      "Epoch 71/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6036 - loss: 0.8164 - val_accuracy: 0.6031 - val_loss: 0.8247\n",
      "Epoch 72/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5998 - loss: 0.8222 - val_accuracy: 0.6008 - val_loss: 0.8257\n",
      "Epoch 73/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6080 - loss: 0.8152 - val_accuracy: 0.5900 - val_loss: 0.8253\n",
      "Epoch 74/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5993 - loss: 0.8265 - val_accuracy: 0.5954 - val_loss: 0.8302\n",
      "Epoch 75/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6200 - loss: 0.8014 - val_accuracy: 0.5954 - val_loss: 0.8278\n",
      "Epoch 76/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6188 - loss: 0.8021 - val_accuracy: 0.5900 - val_loss: 0.8372\n",
      "Epoch 77/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5982 - loss: 0.8200 - val_accuracy: 0.5900 - val_loss: 0.8552\n",
      "Epoch 78/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6121 - loss: 0.8183 - val_accuracy: 0.6000 - val_loss: 0.8369\n",
      "Epoch 79/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6033 - loss: 0.8163 - val_accuracy: 0.5869 - val_loss: 0.8497\n",
      "Epoch 80/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5777 - loss: 0.8346 - val_accuracy: 0.5900 - val_loss: 0.8357\n",
      "Epoch 81/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5975 - loss: 0.8086 - val_accuracy: 0.5992 - val_loss: 0.8406\n",
      "Epoch 82/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6034 - loss: 0.8228 - val_accuracy: 0.6000 - val_loss: 0.8358\n",
      "Epoch 83/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6075 - loss: 0.8273 - val_accuracy: 0.5892 - val_loss: 0.8545\n",
      "Epoch 84/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6039 - loss: 0.8189 - val_accuracy: 0.6000 - val_loss: 0.8300\n",
      "Epoch 85/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6058 - loss: 0.8144 - val_accuracy: 0.5508 - val_loss: 0.9100\n",
      "Epoch 86/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5938 - loss: 0.8444 - val_accuracy: 0.5700 - val_loss: 0.8631\n",
      "Epoch 87/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5922 - loss: 0.8216 - val_accuracy: 0.5985 - val_loss: 0.8264\n",
      "Epoch 88/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5944 - loss: 0.8205 - val_accuracy: 0.5877 - val_loss: 0.8330\n",
      "Epoch 89/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6090 - loss: 0.8076 - val_accuracy: 0.5931 - val_loss: 0.8531\n",
      "Epoch 90/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5927 - loss: 0.8351 - val_accuracy: 0.5885 - val_loss: 0.8464\n",
      "Epoch 91/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6057 - loss: 0.8246 - val_accuracy: 0.5608 - val_loss: 0.8644\n",
      "Epoch 92/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5755 - loss: 0.8422 - val_accuracy: 0.5877 - val_loss: 0.8394\n",
      "Epoch 93/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6094 - loss: 0.8164 - val_accuracy: 0.5746 - val_loss: 0.8576\n",
      "Epoch 94/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5838 - loss: 0.8467 - val_accuracy: 0.5862 - val_loss: 0.8395\n",
      "Epoch 95/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6223 - loss: 0.8155 - val_accuracy: 0.5685 - val_loss: 0.8686\n",
      "Epoch 96/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6077 - loss: 0.8344 - val_accuracy: 0.5954 - val_loss: 0.8327\n",
      "Epoch 97/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5859 - loss: 0.8237 - val_accuracy: 0.6031 - val_loss: 0.8325\n",
      "Epoch 98/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5921 - loss: 0.8163 - val_accuracy: 0.6038 - val_loss: 0.8223\n",
      "Epoch 99/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6122 - loss: 0.8178 - val_accuracy: 0.6000 - val_loss: 0.8295\n",
      "Epoch 100/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6037 - loss: 0.8122 - val_accuracy: 0.5954 - val_loss: 0.8253\n",
      "Epoch 101/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6065 - loss: 0.8271 - val_accuracy: 0.5938 - val_loss: 0.8319\n",
      "Epoch 102/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5925 - loss: 0.8222 - val_accuracy: 0.5485 - val_loss: 0.9008\n",
      "Epoch 103/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5923 - loss: 0.8365 - val_accuracy: 0.5662 - val_loss: 0.8477\n",
      "Epoch 104/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6126 - loss: 0.8125 - val_accuracy: 0.5931 - val_loss: 0.8475\n",
      "Epoch 105/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5998 - loss: 0.8394 - val_accuracy: 0.5992 - val_loss: 0.8364\n",
      "Epoch 106/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5858 - loss: 0.8267 - val_accuracy: 0.5815 - val_loss: 0.8524\n",
      "Epoch 107/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5982 - loss: 0.8182 - val_accuracy: 0.6069 - val_loss: 0.8361\n",
      "Epoch 108/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5993 - loss: 0.8147 - val_accuracy: 0.6023 - val_loss: 0.8263\n",
      "Epoch 109/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6066 - loss: 0.8211 - val_accuracy: 0.5908 - val_loss: 0.8383\n",
      "Epoch 110/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6044 - loss: 0.8188 - val_accuracy: 0.5938 - val_loss: 0.8882\n",
      "Epoch 111/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5973 - loss: 0.8416 - val_accuracy: 0.6046 - val_loss: 0.8412\n",
      "Epoch 112/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5893 - loss: 0.8405 - val_accuracy: 0.5562 - val_loss: 0.8613\n",
      "Epoch 113/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6064 - loss: 0.8246 - val_accuracy: 0.5869 - val_loss: 0.8365\n",
      "Epoch 114/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5844 - loss: 0.8386 - val_accuracy: 0.5646 - val_loss: 0.8593\n",
      "Epoch 115/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5957 - loss: 0.8307 - val_accuracy: 0.5946 - val_loss: 0.8356\n",
      "Epoch 116/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6123 - loss: 0.8253 - val_accuracy: 0.5538 - val_loss: 0.8581\n",
      "Epoch 117/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5974 - loss: 0.8165 - val_accuracy: 0.5623 - val_loss: 0.8526\n",
      "Epoch 118/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5862 - loss: 0.8342 - val_accuracy: 0.6115 - val_loss: 0.8282\n",
      "Epoch 119/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6014 - loss: 0.8267 - val_accuracy: 0.5700 - val_loss: 0.8583\n",
      "Epoch 120/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5928 - loss: 0.8179 - val_accuracy: 0.5877 - val_loss: 0.8316\n",
      "Epoch 121/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6243 - loss: 0.7987 - val_accuracy: 0.5915 - val_loss: 0.8382\n",
      "Epoch 122/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5672 - loss: 0.8527 - val_accuracy: 0.5608 - val_loss: 0.8835\n",
      "Epoch 123/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5907 - loss: 0.8250 - val_accuracy: 0.5923 - val_loss: 0.8332\n",
      "Epoch 124/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6130 - loss: 0.8072 - val_accuracy: 0.5946 - val_loss: 0.8364\n",
      "Epoch 125/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6116 - loss: 0.8251 - val_accuracy: 0.6000 - val_loss: 0.8445\n",
      "Epoch 126/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5986 - loss: 0.8333 - val_accuracy: 0.5969 - val_loss: 0.8621\n",
      "Epoch 127/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6071 - loss: 0.8069 - val_accuracy: 0.5985 - val_loss: 0.8288\n",
      "Epoch 128/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6070 - loss: 0.8138 - val_accuracy: 0.6092 - val_loss: 0.8295\n",
      "Epoch 129/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6181 - loss: 0.8061 - val_accuracy: 0.6108 - val_loss: 0.8440\n",
      "Epoch 130/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6145 - loss: 0.7992 - val_accuracy: 0.6123 - val_loss: 0.8231\n",
      "Epoch 131/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6024 - loss: 0.8118 - val_accuracy: 0.5931 - val_loss: 0.8406\n",
      "Epoch 132/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6045 - loss: 0.8281 - val_accuracy: 0.5962 - val_loss: 0.8267\n",
      "Epoch 133/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5925 - loss: 0.8103 - val_accuracy: 0.5900 - val_loss: 0.8400\n",
      "Epoch 134/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6138 - loss: 0.8161 - val_accuracy: 0.5823 - val_loss: 0.8820\n",
      "Epoch 135/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5811 - loss: 0.8569 - val_accuracy: 0.6062 - val_loss: 0.8409\n",
      "Epoch 136/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5868 - loss: 0.8359 - val_accuracy: 0.5569 - val_loss: 0.8500\n",
      "Epoch 137/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6175 - loss: 0.8164 - val_accuracy: 0.5723 - val_loss: 0.8786\n",
      "Epoch 138/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5912 - loss: 0.8469 - val_accuracy: 0.5892 - val_loss: 0.8348\n",
      "Epoch 139/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6147 - loss: 0.8112 - val_accuracy: 0.5938 - val_loss: 0.8272\n",
      "Epoch 140/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6135 - loss: 0.8122 - val_accuracy: 0.5154 - val_loss: 0.8755\n",
      "Epoch 141/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5842 - loss: 0.8248 - val_accuracy: 0.6100 - val_loss: 0.8235\n",
      "Epoch 142/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6245 - loss: 0.7829 - val_accuracy: 0.5769 - val_loss: 0.8522\n",
      "Epoch 143/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6137 - loss: 0.8094 - val_accuracy: 0.5985 - val_loss: 0.8280\n",
      "Epoch 144/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6202 - loss: 0.8208 - val_accuracy: 0.6031 - val_loss: 0.8219\n",
      "Epoch 145/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6021 - loss: 0.8235 - val_accuracy: 0.6023 - val_loss: 0.8231\n",
      "Epoch 146/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6112 - loss: 0.8061 - val_accuracy: 0.5854 - val_loss: 0.8563\n",
      "Epoch 147/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6055 - loss: 0.8166 - val_accuracy: 0.5977 - val_loss: 0.8366\n",
      "Epoch 148/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6159 - loss: 0.8162 - val_accuracy: 0.5785 - val_loss: 0.8500\n",
      "Epoch 149/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5936 - loss: 0.8330 - val_accuracy: 0.5877 - val_loss: 0.8618\n",
      "Epoch 150/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5983 - loss: 0.8228 - val_accuracy: 0.5662 - val_loss: 0.8338\n",
      "Epoch 151/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6099 - loss: 0.8051 - val_accuracy: 0.5815 - val_loss: 0.8508\n",
      "Epoch 152/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6115 - loss: 0.8164 - val_accuracy: 0.5954 - val_loss: 0.8210\n",
      "Epoch 153/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6200 - loss: 0.8121 - val_accuracy: 0.5946 - val_loss: 0.8367\n",
      "Epoch 154/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5875 - loss: 0.8520 - val_accuracy: 0.5562 - val_loss: 0.8633\n",
      "Epoch 155/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5841 - loss: 0.8424 - val_accuracy: 0.5923 - val_loss: 0.8348\n",
      "Epoch 156/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5802 - loss: 0.8484 - val_accuracy: 0.6077 - val_loss: 0.8510\n",
      "Epoch 157/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6179 - loss: 0.8030 - val_accuracy: 0.5846 - val_loss: 0.8488\n",
      "Epoch 158/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6092 - loss: 0.8093 - val_accuracy: 0.5662 - val_loss: 0.8648\n",
      "Epoch 159/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5790 - loss: 0.8513 - val_accuracy: 0.5600 - val_loss: 0.8837\n",
      "Epoch 160/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5753 - loss: 0.8513 - val_accuracy: 0.5623 - val_loss: 0.8707\n",
      "Epoch 161/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5909 - loss: 0.8400 - val_accuracy: 0.5338 - val_loss: 0.8867\n",
      "Epoch 162/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5928 - loss: 0.8376 - val_accuracy: 0.5608 - val_loss: 0.8814\n",
      "Epoch 163/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5967 - loss: 0.8377 - val_accuracy: 0.5838 - val_loss: 0.8608\n",
      "Epoch 164/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5970 - loss: 0.8206 - val_accuracy: 0.5800 - val_loss: 0.8569\n",
      "Epoch 165/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5898 - loss: 0.8311 - val_accuracy: 0.5738 - val_loss: 0.8550\n",
      "Epoch 166/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5934 - loss: 0.8150 - val_accuracy: 0.5815 - val_loss: 0.8467\n",
      "Epoch 167/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6061 - loss: 0.8115 - val_accuracy: 0.5892 - val_loss: 0.8505\n",
      "Epoch 168/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6040 - loss: 0.8241 - val_accuracy: 0.5662 - val_loss: 0.8672\n",
      "Epoch 169/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5869 - loss: 0.8301 - val_accuracy: 0.5615 - val_loss: 0.8427\n",
      "Epoch 170/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6016 - loss: 0.8151 - val_accuracy: 0.5808 - val_loss: 0.8763\n",
      "Epoch 171/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6037 - loss: 0.8050 - val_accuracy: 0.5946 - val_loss: 0.8315\n",
      "Epoch 172/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6044 - loss: 0.8157 - val_accuracy: 0.5754 - val_loss: 0.8428\n",
      "Epoch 173/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5967 - loss: 0.8229 - val_accuracy: 0.5708 - val_loss: 0.8438\n",
      "Epoch 174/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5956 - loss: 0.8239 - val_accuracy: 0.5877 - val_loss: 0.8385\n",
      "Epoch 175/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6148 - loss: 0.8134 - val_accuracy: 0.5815 - val_loss: 0.8565\n",
      "Epoch 176/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5952 - loss: 0.8197 - val_accuracy: 0.5792 - val_loss: 0.8696\n",
      "Epoch 177/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5955 - loss: 0.8138 - val_accuracy: 0.5962 - val_loss: 0.8264\n",
      "Epoch 178/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6104 - loss: 0.8142 - val_accuracy: 0.5815 - val_loss: 0.8464\n",
      "Epoch 179/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6021 - loss: 0.8145 - val_accuracy: 0.6085 - val_loss: 0.8403\n",
      "Epoch 180/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6176 - loss: 0.8063 - val_accuracy: 0.5738 - val_loss: 0.8673\n",
      "Epoch 181/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6026 - loss: 0.8408 - val_accuracy: 0.6008 - val_loss: 0.8301\n",
      "Epoch 182/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6021 - loss: 0.8158 - val_accuracy: 0.5869 - val_loss: 0.8673\n",
      "Epoch 183/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6038 - loss: 0.8293 - val_accuracy: 0.5808 - val_loss: 0.8377\n",
      "Epoch 184/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6069 - loss: 0.8144 - val_accuracy: 0.5877 - val_loss: 0.8471\n",
      "Epoch 185/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6058 - loss: 0.8097 - val_accuracy: 0.5492 - val_loss: 0.8890\n",
      "Epoch 186/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6077 - loss: 0.8367 - val_accuracy: 0.5700 - val_loss: 0.8599\n",
      "Epoch 187/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6002 - loss: 0.8373 - val_accuracy: 0.6054 - val_loss: 0.8296\n",
      "Epoch 188/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6165 - loss: 0.8062 - val_accuracy: 0.5946 - val_loss: 0.8445\n",
      "Epoch 189/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6141 - loss: 0.8124 - val_accuracy: 0.6131 - val_loss: 0.8293\n",
      "Epoch 190/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6182 - loss: 0.8003 - val_accuracy: 0.6085 - val_loss: 0.8202\n",
      "Epoch 191/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5907 - loss: 0.8202 - val_accuracy: 0.5654 - val_loss: 0.8857\n",
      "Epoch 192/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5855 - loss: 0.8488 - val_accuracy: 0.5923 - val_loss: 0.8447\n",
      "Epoch 193/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6121 - loss: 0.7909 - val_accuracy: 0.5769 - val_loss: 0.8499\n",
      "Epoch 194/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6024 - loss: 0.8266 - val_accuracy: 0.5985 - val_loss: 0.8469\n",
      "Epoch 195/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5963 - loss: 0.8175 - val_accuracy: 0.5985 - val_loss: 0.8325\n",
      "Epoch 196/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6121 - loss: 0.8136 - val_accuracy: 0.6023 - val_loss: 0.8255\n",
      "Epoch 197/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6118 - loss: 0.8097 - val_accuracy: 0.6146 - val_loss: 0.8451\n",
      "Epoch 198/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6055 - loss: 0.8108 - val_accuracy: 0.6169 - val_loss: 0.8604\n",
      "Epoch 199/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6024 - loss: 0.8145 - val_accuracy: 0.6054 - val_loss: 0.8222\n",
      "Epoch 200/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6109 - loss: 0.8097 - val_accuracy: 0.6023 - val_loss: 0.8155\n",
      "Epoch 201/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6156 - loss: 0.8077 - val_accuracy: 0.5838 - val_loss: 0.8429\n",
      "Epoch 202/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6250 - loss: 0.8036 - val_accuracy: 0.5538 - val_loss: 0.8878\n",
      "Epoch 203/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6177 - loss: 0.8017 - val_accuracy: 0.5969 - val_loss: 0.8306\n",
      "Epoch 204/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6190 - loss: 0.7958 - val_accuracy: 0.5877 - val_loss: 0.8579\n",
      "Epoch 205/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6225 - loss: 0.8040 - val_accuracy: 0.6138 - val_loss: 0.8324\n",
      "Epoch 206/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6027 - loss: 0.8183 - val_accuracy: 0.5908 - val_loss: 0.8416\n",
      "Epoch 207/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6296 - loss: 0.8028 - val_accuracy: 0.5892 - val_loss: 0.8287\n",
      "Epoch 208/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6084 - loss: 0.8045 - val_accuracy: 0.5992 - val_loss: 0.8320\n",
      "Epoch 209/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6083 - loss: 0.8221 - val_accuracy: 0.6100 - val_loss: 0.8221\n",
      "Epoch 210/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6292 - loss: 0.7995 - val_accuracy: 0.6131 - val_loss: 0.8352\n",
      "Epoch 211/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6102 - loss: 0.8190 - val_accuracy: 0.5892 - val_loss: 0.8517\n",
      "Epoch 212/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6172 - loss: 0.8102 - val_accuracy: 0.5946 - val_loss: 0.8488\n",
      "Epoch 213/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6124 - loss: 0.8053 - val_accuracy: 0.6008 - val_loss: 0.8506\n",
      "Epoch 214/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6028 - loss: 0.8254 - val_accuracy: 0.5723 - val_loss: 0.8459\n",
      "Epoch 215/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6208 - loss: 0.8003 - val_accuracy: 0.6000 - val_loss: 0.8509\n",
      "Epoch 216/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6068 - loss: 0.8046 - val_accuracy: 0.5938 - val_loss: 0.8445\n",
      "Epoch 217/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6036 - loss: 0.8084 - val_accuracy: 0.5985 - val_loss: 0.8411\n",
      "Epoch 218/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5979 - loss: 0.8118 - val_accuracy: 0.5892 - val_loss: 0.8447\n",
      "Epoch 219/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6097 - loss: 0.8027 - val_accuracy: 0.6046 - val_loss: 0.8273\n",
      "Epoch 220/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6199 - loss: 0.7979 - val_accuracy: 0.5969 - val_loss: 0.8346\n",
      "Epoch 221/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6170 - loss: 0.8115 - val_accuracy: 0.5962 - val_loss: 0.8500\n",
      "Epoch 222/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6139 - loss: 0.8061 - val_accuracy: 0.5969 - val_loss: 0.8359\n",
      "Epoch 223/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6233 - loss: 0.7950 - val_accuracy: 0.6077 - val_loss: 0.8465\n",
      "Epoch 224/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6185 - loss: 0.8045 - val_accuracy: 0.5708 - val_loss: 0.8573\n",
      "Epoch 225/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5953 - loss: 0.8181 - val_accuracy: 0.5831 - val_loss: 0.8518\n",
      "Epoch 226/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6170 - loss: 0.7978 - val_accuracy: 0.5754 - val_loss: 0.8520\n",
      "Epoch 227/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5992 - loss: 0.8275 - val_accuracy: 0.5923 - val_loss: 0.8452\n",
      "Epoch 228/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6077 - loss: 0.7997 - val_accuracy: 0.5577 - val_loss: 0.8657\n",
      "Epoch 229/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6052 - loss: 0.8091 - val_accuracy: 0.5985 - val_loss: 0.8226\n",
      "Epoch 230/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6244 - loss: 0.7764 - val_accuracy: 0.6015 - val_loss: 0.8437\n",
      "Epoch 231/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6118 - loss: 0.8030 - val_accuracy: 0.5938 - val_loss: 0.8292\n",
      "Epoch 232/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6204 - loss: 0.8011 - val_accuracy: 0.6108 - val_loss: 0.8341\n",
      "Epoch 233/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6206 - loss: 0.7869 - val_accuracy: 0.5977 - val_loss: 0.8284\n",
      "Epoch 234/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6158 - loss: 0.8001 - val_accuracy: 0.6062 - val_loss: 0.8264\n",
      "Epoch 235/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6191 - loss: 0.7957 - val_accuracy: 0.6008 - val_loss: 0.8304\n",
      "Epoch 236/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6270 - loss: 0.7991 - val_accuracy: 0.6085 - val_loss: 0.8127\n",
      "Epoch 237/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6161 - loss: 0.7933 - val_accuracy: 0.6100 - val_loss: 0.8186\n",
      "Epoch 238/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6137 - loss: 0.8180 - val_accuracy: 0.6115 - val_loss: 0.8248\n",
      "Epoch 239/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6211 - loss: 0.7979 - val_accuracy: 0.5923 - val_loss: 0.8248\n",
      "Epoch 240/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6058 - loss: 0.8140 - val_accuracy: 0.6115 - val_loss: 0.8284\n",
      "Epoch 241/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6250 - loss: 0.8078 - val_accuracy: 0.5977 - val_loss: 0.8539\n",
      "Epoch 242/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6171 - loss: 0.8074 - val_accuracy: 0.6062 - val_loss: 0.8330\n",
      "Epoch 243/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6193 - loss: 0.8122 - val_accuracy: 0.6008 - val_loss: 0.8255\n",
      "Epoch 244/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6117 - loss: 0.8120 - val_accuracy: 0.5469 - val_loss: 0.8747\n",
      "Epoch 245/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6072 - loss: 0.8141 - val_accuracy: 0.5977 - val_loss: 0.8361\n",
      "Epoch 246/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6078 - loss: 0.7968 - val_accuracy: 0.6046 - val_loss: 0.8248\n",
      "Epoch 247/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6144 - loss: 0.8035 - val_accuracy: 0.5892 - val_loss: 0.8414\n",
      "Epoch 248/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6056 - loss: 0.7995 - val_accuracy: 0.6046 - val_loss: 0.8381\n",
      "Epoch 249/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6139 - loss: 0.8072 - val_accuracy: 0.5992 - val_loss: 0.8336\n",
      "Epoch 250/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6086 - loss: 0.8153 - val_accuracy: 0.5738 - val_loss: 0.8580\n",
      "Epoch 251/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6099 - loss: 0.8083 - val_accuracy: 0.5962 - val_loss: 0.8452\n",
      "Epoch 252/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6041 - loss: 0.8078 - val_accuracy: 0.6062 - val_loss: 0.8395\n",
      "Epoch 253/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6006 - loss: 0.8115 - val_accuracy: 0.5877 - val_loss: 0.8407\n",
      "Epoch 254/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6146 - loss: 0.8197 - val_accuracy: 0.6023 - val_loss: 0.8321\n",
      "Epoch 255/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6252 - loss: 0.8012 - val_accuracy: 0.6200 - val_loss: 0.8318\n",
      "Epoch 256/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6003 - loss: 0.8189 - val_accuracy: 0.6146 - val_loss: 0.8249\n",
      "Epoch 257/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6201 - loss: 0.7915 - val_accuracy: 0.5954 - val_loss: 0.8305\n",
      "Epoch 258/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6273 - loss: 0.7818 - val_accuracy: 0.6092 - val_loss: 0.8220\n",
      "Epoch 259/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6281 - loss: 0.7984 - val_accuracy: 0.6038 - val_loss: 0.8299\n",
      "Epoch 260/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6194 - loss: 0.8147 - val_accuracy: 0.6000 - val_loss: 0.8526\n",
      "Epoch 261/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6188 - loss: 0.8054 - val_accuracy: 0.6046 - val_loss: 0.8375\n",
      "Epoch 262/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6004 - loss: 0.8227 - val_accuracy: 0.6054 - val_loss: 0.8517\n",
      "Epoch 263/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6271 - loss: 0.7863 - val_accuracy: 0.5715 - val_loss: 0.8486\n",
      "Epoch 264/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6420 - loss: 0.7828 - val_accuracy: 0.6054 - val_loss: 0.8285\n",
      "Epoch 265/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6096 - loss: 0.8099 - val_accuracy: 0.6038 - val_loss: 0.8274\n",
      "Epoch 266/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6177 - loss: 0.8022 - val_accuracy: 0.5969 - val_loss: 0.8526\n",
      "Epoch 267/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6230 - loss: 0.7950 - val_accuracy: 0.6023 - val_loss: 0.8405\n",
      "Epoch 268/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6243 - loss: 0.7951 - val_accuracy: 0.6023 - val_loss: 0.8142\n",
      "Epoch 269/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6169 - loss: 0.7969 - val_accuracy: 0.6123 - val_loss: 0.8274\n",
      "Epoch 270/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6105 - loss: 0.8045 - val_accuracy: 0.6046 - val_loss: 0.8301\n",
      "Epoch 271/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6261 - loss: 0.8019 - val_accuracy: 0.6069 - val_loss: 0.8138\n",
      "Epoch 272/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6281 - loss: 0.7948 - val_accuracy: 0.6054 - val_loss: 0.8263\n",
      "Epoch 273/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6362 - loss: 0.7908 - val_accuracy: 0.5915 - val_loss: 0.8298\n",
      "Epoch 274/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6273 - loss: 0.7984 - val_accuracy: 0.6077 - val_loss: 0.8310\n",
      "Epoch 275/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6023 - loss: 0.8156 - val_accuracy: 0.5992 - val_loss: 0.8258\n",
      "Epoch 276/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6064 - loss: 0.8033 - val_accuracy: 0.5969 - val_loss: 0.8293\n",
      "Epoch 277/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6062 - loss: 0.8036 - val_accuracy: 0.5854 - val_loss: 0.8236\n",
      "Epoch 278/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6145 - loss: 0.8079 - val_accuracy: 0.5915 - val_loss: 0.8177\n",
      "Epoch 279/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6139 - loss: 0.7998 - val_accuracy: 0.5992 - val_loss: 0.8451\n",
      "Epoch 280/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6035 - loss: 0.8214 - val_accuracy: 0.6008 - val_loss: 0.8426\n",
      "Epoch 281/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6166 - loss: 0.8102 - val_accuracy: 0.5915 - val_loss: 0.8392\n",
      "Epoch 282/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6240 - loss: 0.7931 - val_accuracy: 0.6031 - val_loss: 0.8260\n",
      "Epoch 283/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6145 - loss: 0.7946 - val_accuracy: 0.6046 - val_loss: 0.8362\n",
      "Epoch 284/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6173 - loss: 0.8020 - val_accuracy: 0.5985 - val_loss: 0.8326\n",
      "Epoch 285/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6173 - loss: 0.7894 - val_accuracy: 0.5877 - val_loss: 0.8330\n",
      "Epoch 286/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6168 - loss: 0.8011 - val_accuracy: 0.6038 - val_loss: 0.8430\n",
      "Epoch 287/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6120 - loss: 0.8144 - val_accuracy: 0.6023 - val_loss: 0.8379\n",
      "Epoch 288/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6004 - loss: 0.8155 - val_accuracy: 0.5985 - val_loss: 0.8274\n",
      "Epoch 289/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6280 - loss: 0.8016 - val_accuracy: 0.6015 - val_loss: 0.8509\n",
      "Epoch 290/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6102 - loss: 0.8207 - val_accuracy: 0.5985 - val_loss: 0.8302\n",
      "Epoch 291/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6186 - loss: 0.7939 - val_accuracy: 0.6015 - val_loss: 0.8388\n",
      "Epoch 292/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6071 - loss: 0.8182 - val_accuracy: 0.6092 - val_loss: 0.8322\n",
      "Epoch 293/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6244 - loss: 0.8137 - val_accuracy: 0.5900 - val_loss: 0.8267\n",
      "Epoch 294/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6179 - loss: 0.8026 - val_accuracy: 0.6115 - val_loss: 0.8311\n",
      "Epoch 295/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6058 - loss: 0.8149 - val_accuracy: 0.6185 - val_loss: 0.8463\n",
      "Epoch 296/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5897 - loss: 0.8387 - val_accuracy: 0.5838 - val_loss: 0.8956\n",
      "Epoch 297/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6013 - loss: 0.8256 - val_accuracy: 0.5992 - val_loss: 0.8640\n",
      "Epoch 298/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6045 - loss: 0.8075 - val_accuracy: 0.6077 - val_loss: 0.8318\n",
      "Epoch 299/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5955 - loss: 0.7998 - val_accuracy: 0.6000 - val_loss: 0.8148\n",
      "Epoch 300/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5983 - loss: 0.8137 - val_accuracy: 0.6069 - val_loss: 0.8420\n",
      "Epoch 301/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6137 - loss: 0.7972 - val_accuracy: 0.6092 - val_loss: 0.8429\n",
      "Epoch 302/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6375 - loss: 0.7835 - val_accuracy: 0.5977 - val_loss: 0.8490\n",
      "Epoch 303/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6112 - loss: 0.8086 - val_accuracy: 0.6123 - val_loss: 0.8459\n",
      "Epoch 304/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6047 - loss: 0.8088 - val_accuracy: 0.6092 - val_loss: 0.8305\n",
      "Epoch 305/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6329 - loss: 0.7951 - val_accuracy: 0.5962 - val_loss: 0.8312\n",
      "Epoch 306/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6000 - loss: 0.8092 - val_accuracy: 0.6085 - val_loss: 0.8480\n",
      "Epoch 307/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6113 - loss: 0.8148 - val_accuracy: 0.6100 - val_loss: 0.8455\n",
      "Epoch 308/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6175 - loss: 0.7901 - val_accuracy: 0.5931 - val_loss: 0.8369\n",
      "Epoch 309/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6134 - loss: 0.7997 - val_accuracy: 0.5123 - val_loss: 0.8870\n",
      "Epoch 310/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5922 - loss: 0.8171 - val_accuracy: 0.5977 - val_loss: 0.8575\n",
      "Epoch 311/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6104 - loss: 0.8121 - val_accuracy: 0.6077 - val_loss: 0.8464\n",
      "Epoch 312/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6240 - loss: 0.7974 - val_accuracy: 0.6162 - val_loss: 0.8398\n",
      "Epoch 313/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6067 - loss: 0.7979 - val_accuracy: 0.6069 - val_loss: 0.8341\n",
      "Epoch 314/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6046 - loss: 0.8067 - val_accuracy: 0.6015 - val_loss: 0.8390\n",
      "Epoch 315/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6152 - loss: 0.7910 - val_accuracy: 0.5715 - val_loss: 0.8705\n",
      "Epoch 316/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5873 - loss: 0.8230 - val_accuracy: 0.6100 - val_loss: 0.8402\n",
      "Epoch 317/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6051 - loss: 0.8095 - val_accuracy: 0.6131 - val_loss: 0.8158\n",
      "Epoch 318/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6151 - loss: 0.8065 - val_accuracy: 0.6192 - val_loss: 0.8238\n",
      "Epoch 319/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6256 - loss: 0.7816 - val_accuracy: 0.6062 - val_loss: 0.8342\n",
      "Epoch 320/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6212 - loss: 0.7935 - val_accuracy: 0.5985 - val_loss: 0.8312\n",
      "Epoch 321/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6177 - loss: 0.7926 - val_accuracy: 0.5754 - val_loss: 0.8419\n",
      "Epoch 322/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6134 - loss: 0.8036 - val_accuracy: 0.5992 - val_loss: 0.8456\n",
      "Epoch 323/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6294 - loss: 0.7794 - val_accuracy: 0.6069 - val_loss: 0.8354\n",
      "Epoch 324/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6244 - loss: 0.7865 - val_accuracy: 0.5746 - val_loss: 0.8546\n",
      "Epoch 325/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5955 - loss: 0.8080 - val_accuracy: 0.5462 - val_loss: 0.8899\n",
      "Epoch 326/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5876 - loss: 0.8325 - val_accuracy: 0.6031 - val_loss: 0.8352\n",
      "Epoch 327/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6171 - loss: 0.7992 - val_accuracy: 0.6154 - val_loss: 0.8313\n",
      "Epoch 328/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6208 - loss: 0.7940 - val_accuracy: 0.6085 - val_loss: 0.8363\n",
      "Epoch 329/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6181 - loss: 0.8023 - val_accuracy: 0.5885 - val_loss: 0.8421\n",
      "Epoch 330/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6235 - loss: 0.8059 - val_accuracy: 0.5823 - val_loss: 0.8495\n",
      "Epoch 331/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6209 - loss: 0.8051 - val_accuracy: 0.6015 - val_loss: 0.8382\n",
      "Epoch 332/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6202 - loss: 0.7891 - val_accuracy: 0.5908 - val_loss: 0.8530\n",
      "Epoch 333/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5970 - loss: 0.8088 - val_accuracy: 0.5515 - val_loss: 0.8683\n",
      "Epoch 334/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6287 - loss: 0.7880 - val_accuracy: 0.5762 - val_loss: 0.8700\n",
      "Epoch 335/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6085 - loss: 0.8165 - val_accuracy: 0.6154 - val_loss: 0.8413\n",
      "Epoch 336/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6091 - loss: 0.8014 - val_accuracy: 0.6177 - val_loss: 0.8389\n",
      "Epoch 337/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6186 - loss: 0.7890 - val_accuracy: 0.6023 - val_loss: 0.8381\n",
      "Epoch 338/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6268 - loss: 0.7791 - val_accuracy: 0.5785 - val_loss: 0.8434\n",
      "Epoch 339/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6259 - loss: 0.7900 - val_accuracy: 0.6000 - val_loss: 0.8385\n",
      "Epoch 340/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6247 - loss: 0.7865 - val_accuracy: 0.5646 - val_loss: 0.8668\n",
      "Epoch 341/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6089 - loss: 0.8062 - val_accuracy: 0.5692 - val_loss: 0.8754\n",
      "Epoch 342/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6120 - loss: 0.8126 - val_accuracy: 0.6177 - val_loss: 0.8314\n",
      "Epoch 343/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6301 - loss: 0.7838 - val_accuracy: 0.5915 - val_loss: 0.8383\n",
      "Epoch 344/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6152 - loss: 0.8012 - val_accuracy: 0.6023 - val_loss: 0.8383\n",
      "Epoch 345/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6099 - loss: 0.8120 - val_accuracy: 0.5731 - val_loss: 0.8531\n",
      "Epoch 346/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6235 - loss: 0.7969 - val_accuracy: 0.5962 - val_loss: 0.8725\n",
      "Epoch 347/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5959 - loss: 0.8051 - val_accuracy: 0.6092 - val_loss: 0.8264\n",
      "Epoch 348/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6368 - loss: 0.7720 - val_accuracy: 0.6062 - val_loss: 0.8271\n",
      "Epoch 349/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6260 - loss: 0.7969 - val_accuracy: 0.5969 - val_loss: 0.8447\n",
      "Epoch 350/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6342 - loss: 0.7795 - val_accuracy: 0.5908 - val_loss: 0.8402\n",
      "Epoch 351/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6047 - loss: 0.8087 - val_accuracy: 0.6177 - val_loss: 0.8527\n",
      "Epoch 352/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6251 - loss: 0.7937 - val_accuracy: 0.6062 - val_loss: 0.8325\n",
      "Epoch 353/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6247 - loss: 0.7994 - val_accuracy: 0.6038 - val_loss: 0.8505\n",
      "Epoch 354/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6082 - loss: 0.8031 - val_accuracy: 0.5708 - val_loss: 0.8471\n",
      "Epoch 355/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6100 - loss: 0.8009 - val_accuracy: 0.5446 - val_loss: 0.8770\n",
      "Epoch 356/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6075 - loss: 0.8062 - val_accuracy: 0.5900 - val_loss: 0.8485\n",
      "Epoch 357/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6145 - loss: 0.7928 - val_accuracy: 0.6054 - val_loss: 0.8476\n",
      "Epoch 358/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6176 - loss: 0.8027 - val_accuracy: 0.5938 - val_loss: 0.8404\n",
      "Epoch 359/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6275 - loss: 0.7914 - val_accuracy: 0.5762 - val_loss: 0.8628\n",
      "Epoch 360/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6158 - loss: 0.7967 - val_accuracy: 0.5723 - val_loss: 0.8628\n",
      "Epoch 361/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6158 - loss: 0.7968 - val_accuracy: 0.5977 - val_loss: 0.8435\n",
      "Epoch 362/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6261 - loss: 0.8029 - val_accuracy: 0.5846 - val_loss: 0.8519\n",
      "Epoch 363/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6402 - loss: 0.7893 - val_accuracy: 0.5885 - val_loss: 0.8488\n",
      "Epoch 364/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6170 - loss: 0.8170 - val_accuracy: 0.5931 - val_loss: 0.8593\n",
      "Epoch 365/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6020 - loss: 0.8051 - val_accuracy: 0.6031 - val_loss: 0.8374\n",
      "Epoch 366/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6149 - loss: 0.7904 - val_accuracy: 0.5992 - val_loss: 0.8454\n",
      "Epoch 367/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6234 - loss: 0.8081 - val_accuracy: 0.6108 - val_loss: 0.8432\n",
      "Epoch 368/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6115 - loss: 0.8006 - val_accuracy: 0.5654 - val_loss: 0.8561\n",
      "Epoch 369/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6157 - loss: 0.8121 - val_accuracy: 0.6023 - val_loss: 0.8478\n",
      "Epoch 370/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6269 - loss: 0.8037 - val_accuracy: 0.6069 - val_loss: 0.8329\n",
      "Epoch 371/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6060 - loss: 0.8054 - val_accuracy: 0.5885 - val_loss: 0.8493\n",
      "Epoch 372/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6279 - loss: 0.7942 - val_accuracy: 0.5946 - val_loss: 0.8573\n",
      "Epoch 373/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6271 - loss: 0.7960 - val_accuracy: 0.5962 - val_loss: 0.8303\n",
      "Epoch 374/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6167 - loss: 0.8095 - val_accuracy: 0.6077 - val_loss: 0.8490\n",
      "Epoch 375/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6067 - loss: 0.8111 - val_accuracy: 0.5985 - val_loss: 0.8876\n",
      "Epoch 376/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6122 - loss: 0.8020 - val_accuracy: 0.6177 - val_loss: 0.8339\n",
      "Epoch 377/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5914 - loss: 0.8314 - val_accuracy: 0.6131 - val_loss: 0.8328\n",
      "Epoch 378/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6183 - loss: 0.7944 - val_accuracy: 0.6023 - val_loss: 0.8354\n",
      "Epoch 379/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6253 - loss: 0.7824 - val_accuracy: 0.5908 - val_loss: 0.8416\n",
      "Epoch 380/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6061 - loss: 0.8011 - val_accuracy: 0.6123 - val_loss: 0.8299\n",
      "Epoch 381/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6200 - loss: 0.7870 - val_accuracy: 0.6154 - val_loss: 0.8324\n",
      "Epoch 382/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6227 - loss: 0.7944 - val_accuracy: 0.6069 - val_loss: 0.8447\n",
      "Epoch 383/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6075 - loss: 0.8021 - val_accuracy: 0.5915 - val_loss: 0.8643\n",
      "Epoch 384/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6049 - loss: 0.8249 - val_accuracy: 0.6077 - val_loss: 0.8669\n",
      "Epoch 385/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5962 - loss: 0.8246 - val_accuracy: 0.6123 - val_loss: 0.8334\n",
      "Epoch 386/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5968 - loss: 0.8175 - val_accuracy: 0.6038 - val_loss: 0.8423\n",
      "Epoch 387/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6069 - loss: 0.8028 - val_accuracy: 0.6077 - val_loss: 0.8509\n",
      "Epoch 388/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6159 - loss: 0.7993 - val_accuracy: 0.5631 - val_loss: 0.8816\n",
      "Epoch 389/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6031 - loss: 0.8026 - val_accuracy: 0.6169 - val_loss: 0.8306\n",
      "Epoch 390/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6318 - loss: 0.7948 - val_accuracy: 0.6200 - val_loss: 0.8415\n",
      "Epoch 391/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6165 - loss: 0.8062 - val_accuracy: 0.6146 - val_loss: 0.8267\n",
      "Epoch 392/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6283 - loss: 0.7950 - val_accuracy: 0.6085 - val_loss: 0.8393\n",
      "Epoch 393/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6280 - loss: 0.7835 - val_accuracy: 0.6215 - val_loss: 0.8273\n",
      "Epoch 394/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6195 - loss: 0.7848 - val_accuracy: 0.6231 - val_loss: 0.8333\n",
      "Epoch 395/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6189 - loss: 0.7911 - val_accuracy: 0.6038 - val_loss: 0.8662\n",
      "Epoch 396/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6168 - loss: 0.7970 - val_accuracy: 0.6062 - val_loss: 0.8485\n",
      "Epoch 397/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6206 - loss: 0.8015 - val_accuracy: 0.6138 - val_loss: 0.8270\n",
      "Epoch 398/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6101 - loss: 0.8165 - val_accuracy: 0.6162 - val_loss: 0.8449\n",
      "Epoch 399/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6070 - loss: 0.8242 - val_accuracy: 0.5646 - val_loss: 0.8699\n",
      "Epoch 400/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5939 - loss: 0.8150 - val_accuracy: 0.6069 - val_loss: 0.8258\n",
      "Epoch 401/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6202 - loss: 0.7925 - val_accuracy: 0.5900 - val_loss: 0.8485\n",
      "Epoch 402/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6099 - loss: 0.8087 - val_accuracy: 0.6069 - val_loss: 0.8383\n",
      "Epoch 403/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6382 - loss: 0.7661 - val_accuracy: 0.6038 - val_loss: 0.8336\n",
      "Epoch 404/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6266 - loss: 0.7918 - val_accuracy: 0.5877 - val_loss: 0.8641\n",
      "Epoch 405/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6097 - loss: 0.8111 - val_accuracy: 0.5892 - val_loss: 0.8627\n",
      "Epoch 406/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6193 - loss: 0.8037 - val_accuracy: 0.6192 - val_loss: 0.8273\n",
      "Epoch 407/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6288 - loss: 0.7855 - val_accuracy: 0.6177 - val_loss: 0.8313\n",
      "Epoch 408/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6091 - loss: 0.8126 - val_accuracy: 0.5623 - val_loss: 0.8984\n",
      "Epoch 409/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6315 - loss: 0.7995 - val_accuracy: 0.6177 - val_loss: 0.8331\n",
      "Epoch 410/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5989 - loss: 0.8080 - val_accuracy: 0.6015 - val_loss: 0.8484\n",
      "Epoch 411/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5980 - loss: 0.8062 - val_accuracy: 0.5762 - val_loss: 0.8643\n",
      "Epoch 412/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5949 - loss: 0.8293 - val_accuracy: 0.6108 - val_loss: 0.8515\n",
      "Epoch 413/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6117 - loss: 0.8122 - val_accuracy: 0.6123 - val_loss: 0.8301\n",
      "Epoch 414/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6338 - loss: 0.7826 - val_accuracy: 0.6077 - val_loss: 0.8219\n",
      "Epoch 415/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6197 - loss: 0.8127 - val_accuracy: 0.5754 - val_loss: 0.8491\n",
      "Epoch 416/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6183 - loss: 0.7981 - val_accuracy: 0.6123 - val_loss: 0.8297\n",
      "Epoch 417/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6217 - loss: 0.7854 - val_accuracy: 0.6108 - val_loss: 0.8438\n",
      "Epoch 418/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6194 - loss: 0.8178 - val_accuracy: 0.5715 - val_loss: 0.8820\n",
      "Epoch 419/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5931 - loss: 0.8103 - val_accuracy: 0.6200 - val_loss: 0.8282\n",
      "Epoch 420/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6362 - loss: 0.7726 - val_accuracy: 0.6131 - val_loss: 0.8257\n",
      "Epoch 421/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6347 - loss: 0.7933 - val_accuracy: 0.6069 - val_loss: 0.8600\n",
      "Epoch 422/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5968 - loss: 0.8031 - val_accuracy: 0.5977 - val_loss: 0.8397\n",
      "Epoch 423/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6073 - loss: 0.8072 - val_accuracy: 0.6062 - val_loss: 0.8514\n",
      "Epoch 424/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6112 - loss: 0.8065 - val_accuracy: 0.5638 - val_loss: 0.8815\n",
      "Epoch 425/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6174 - loss: 0.8144 - val_accuracy: 0.6185 - val_loss: 0.8464\n",
      "Epoch 426/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6165 - loss: 0.7896 - val_accuracy: 0.5754 - val_loss: 0.8676\n",
      "Epoch 427/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6171 - loss: 0.7933 - val_accuracy: 0.5862 - val_loss: 0.8494\n",
      "Epoch 428/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6210 - loss: 0.8087 - val_accuracy: 0.5962 - val_loss: 0.8399\n",
      "Epoch 429/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6268 - loss: 0.7858 - val_accuracy: 0.5792 - val_loss: 0.8451\n",
      "Epoch 430/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6249 - loss: 0.7962 - val_accuracy: 0.6123 - val_loss: 0.8366\n",
      "Epoch 431/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6172 - loss: 0.7979 - val_accuracy: 0.6046 - val_loss: 0.8462\n",
      "Epoch 432/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6204 - loss: 0.8026 - val_accuracy: 0.6100 - val_loss: 0.8378\n",
      "Epoch 433/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6132 - loss: 0.8016 - val_accuracy: 0.6108 - val_loss: 0.8361\n",
      "Epoch 434/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6150 - loss: 0.8052 - val_accuracy: 0.6015 - val_loss: 0.8826\n",
      "Epoch 435/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6130 - loss: 0.8012 - val_accuracy: 0.6031 - val_loss: 0.8325\n",
      "Epoch 436/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6305 - loss: 0.7948 - val_accuracy: 0.6100 - val_loss: 0.8332\n",
      "Epoch 437/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6205 - loss: 0.7811 - val_accuracy: 0.6015 - val_loss: 0.8536\n",
      "Epoch 438/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6162 - loss: 0.7988 - val_accuracy: 0.6046 - val_loss: 0.8427\n",
      "Epoch 439/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6189 - loss: 0.7866 - val_accuracy: 0.6000 - val_loss: 0.8526\n",
      "Epoch 440/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6228 - loss: 0.7935 - val_accuracy: 0.6131 - val_loss: 0.8378\n",
      "Epoch 441/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6250 - loss: 0.7908 - val_accuracy: 0.5977 - val_loss: 0.8457\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6203 - loss: 0.7907 - val_accuracy: 0.5985 - val_loss: 0.8697\n",
      "Epoch 443/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6110 - loss: 0.7851 - val_accuracy: 0.5869 - val_loss: 0.8597\n",
      "Epoch 444/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6066 - loss: 0.8049 - val_accuracy: 0.5623 - val_loss: 0.8771\n",
      "Epoch 445/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6183 - loss: 0.8085 - val_accuracy: 0.6100 - val_loss: 0.8438\n",
      "Epoch 446/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6200 - loss: 0.7919 - val_accuracy: 0.5715 - val_loss: 0.8643\n",
      "Epoch 447/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6214 - loss: 0.8061 - val_accuracy: 0.6192 - val_loss: 0.8264\n",
      "Epoch 448/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6284 - loss: 0.7965 - val_accuracy: 0.6092 - val_loss: 0.8464\n",
      "Epoch 449/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6213 - loss: 0.8039 - val_accuracy: 0.6031 - val_loss: 0.8391\n",
      "Epoch 450/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6425 - loss: 0.7742 - val_accuracy: 0.6023 - val_loss: 0.8354\n",
      "Epoch 451/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6226 - loss: 0.7917 - val_accuracy: 0.6077 - val_loss: 0.8274\n",
      "Epoch 452/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6279 - loss: 0.7997 - val_accuracy: 0.5931 - val_loss: 0.8786\n",
      "Epoch 453/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6184 - loss: 0.7919 - val_accuracy: 0.6031 - val_loss: 0.8471\n",
      "Epoch 454/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6258 - loss: 0.7803 - val_accuracy: 0.6000 - val_loss: 0.8445\n",
      "Epoch 455/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5875 - loss: 0.8623 - val_accuracy: 0.5600 - val_loss: 0.8712\n",
      "Epoch 456/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5665 - loss: 0.8532 - val_accuracy: 0.5654 - val_loss: 0.8626\n",
      "Epoch 457/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5905 - loss: 0.8316 - val_accuracy: 0.5838 - val_loss: 0.8580\n",
      "Epoch 458/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6127 - loss: 0.8077 - val_accuracy: 0.5962 - val_loss: 0.8685\n",
      "Epoch 459/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6048 - loss: 0.8103 - val_accuracy: 0.6177 - val_loss: 0.8366\n",
      "Epoch 460/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6302 - loss: 0.8024 - val_accuracy: 0.6046 - val_loss: 0.8419\n",
      "Epoch 461/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5954 - loss: 0.8396 - val_accuracy: 0.5954 - val_loss: 0.8487\n",
      "Epoch 462/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6163 - loss: 0.8089 - val_accuracy: 0.5962 - val_loss: 0.8703\n",
      "Epoch 463/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6049 - loss: 0.8092 - val_accuracy: 0.6000 - val_loss: 0.8479\n",
      "Epoch 464/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6187 - loss: 0.7977 - val_accuracy: 0.6208 - val_loss: 0.8385\n",
      "Epoch 465/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6235 - loss: 0.7890 - val_accuracy: 0.5985 - val_loss: 0.8557\n",
      "Epoch 466/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6255 - loss: 0.7880 - val_accuracy: 0.6085 - val_loss: 0.8324\n",
      "Epoch 467/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6154 - loss: 0.7865 - val_accuracy: 0.6131 - val_loss: 0.8180\n",
      "Epoch 468/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6109 - loss: 0.8018 - val_accuracy: 0.5862 - val_loss: 0.8361\n",
      "Epoch 469/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6132 - loss: 0.8045 - val_accuracy: 0.6115 - val_loss: 0.8315\n",
      "Epoch 470/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6128 - loss: 0.8045 - val_accuracy: 0.6085 - val_loss: 0.8148\n",
      "Epoch 471/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6021 - loss: 0.8067 - val_accuracy: 0.6069 - val_loss: 0.8531\n",
      "Epoch 472/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6093 - loss: 0.8016 - val_accuracy: 0.6100 - val_loss: 0.8193\n",
      "Epoch 473/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6194 - loss: 0.8010 - val_accuracy: 0.6215 - val_loss: 0.8254\n",
      "Epoch 474/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6214 - loss: 0.7900 - val_accuracy: 0.5862 - val_loss: 0.8606\n",
      "Epoch 475/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6208 - loss: 0.7866 - val_accuracy: 0.6185 - val_loss: 0.8336\n",
      "Epoch 476/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6092 - loss: 0.7999 - val_accuracy: 0.6008 - val_loss: 0.8446\n",
      "Epoch 477/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6311 - loss: 0.7768 - val_accuracy: 0.6123 - val_loss: 0.8178\n",
      "Epoch 478/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6281 - loss: 0.7879 - val_accuracy: 0.6123 - val_loss: 0.8377\n",
      "Epoch 479/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6008 - loss: 0.8109 - val_accuracy: 0.5977 - val_loss: 0.8739\n",
      "Epoch 480/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5998 - loss: 0.8115 - val_accuracy: 0.6015 - val_loss: 0.8434\n",
      "Epoch 481/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6009 - loss: 0.7892 - val_accuracy: 0.6154 - val_loss: 0.8327\n",
      "Epoch 482/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6114 - loss: 0.7957 - val_accuracy: 0.5854 - val_loss: 0.8395\n",
      "Epoch 483/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6150 - loss: 0.8073 - val_accuracy: 0.6138 - val_loss: 0.8346\n",
      "Epoch 484/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6060 - loss: 0.7847 - val_accuracy: 0.6000 - val_loss: 0.8386\n",
      "Epoch 485/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6203 - loss: 0.7966 - val_accuracy: 0.5992 - val_loss: 0.8328\n",
      "Epoch 486/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6031 - loss: 0.8039 - val_accuracy: 0.5785 - val_loss: 0.8584\n",
      "Epoch 487/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6260 - loss: 0.8011 - val_accuracy: 0.6192 - val_loss: 0.8222\n",
      "Epoch 488/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5988 - loss: 0.8084 - val_accuracy: 0.5846 - val_loss: 0.8488\n",
      "Epoch 489/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6155 - loss: 0.7916 - val_accuracy: 0.6200 - val_loss: 0.8327\n",
      "Epoch 490/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6176 - loss: 0.7946 - val_accuracy: 0.5915 - val_loss: 0.8377\n",
      "Epoch 491/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6176 - loss: 0.7986 - val_accuracy: 0.6015 - val_loss: 0.8393\n",
      "Epoch 492/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6167 - loss: 0.7950 - val_accuracy: 0.6085 - val_loss: 0.8394\n",
      "Epoch 493/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6003 - loss: 0.8096 - val_accuracy: 0.5938 - val_loss: 0.8278\n",
      "Epoch 494/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6160 - loss: 0.8033 - val_accuracy: 0.5754 - val_loss: 0.8646\n",
      "Epoch 495/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6061 - loss: 0.8354 - val_accuracy: 0.5715 - val_loss: 0.8670\n",
      "Epoch 496/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5843 - loss: 0.8361 - val_accuracy: 0.5600 - val_loss: 0.8632\n",
      "Epoch 497/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5751 - loss: 0.8476 - val_accuracy: 0.5885 - val_loss: 0.8362\n",
      "Epoch 498/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5962 - loss: 0.8373 - val_accuracy: 0.5908 - val_loss: 0.8773\n",
      "Epoch 499/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5986 - loss: 0.8117 - val_accuracy: 0.5969 - val_loss: 0.8274\n",
      "Epoch 500/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6237 - loss: 0.8057 - val_accuracy: 0.5646 - val_loss: 0.8376\n",
      "Epoch 501/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6044 - loss: 0.8147 - val_accuracy: 0.6077 - val_loss: 0.8283\n",
      "Epoch 502/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6067 - loss: 0.8164 - val_accuracy: 0.6162 - val_loss: 0.8174\n",
      "Epoch 503/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6323 - loss: 0.7929 - val_accuracy: 0.5985 - val_loss: 0.8336\n",
      "Epoch 504/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6056 - loss: 0.8080 - val_accuracy: 0.6177 - val_loss: 0.8138\n",
      "Epoch 505/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6064 - loss: 0.8079 - val_accuracy: 0.6015 - val_loss: 0.8404\n",
      "Epoch 506/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6289 - loss: 0.7951 - val_accuracy: 0.6162 - val_loss: 0.8343\n",
      "Epoch 507/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6354 - loss: 0.7818 - val_accuracy: 0.6115 - val_loss: 0.8359\n",
      "Epoch 508/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6057 - loss: 0.7969 - val_accuracy: 0.5969 - val_loss: 0.8526\n",
      "Epoch 509/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5985 - loss: 0.8179 - val_accuracy: 0.6077 - val_loss: 0.8451\n",
      "Epoch 510/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6044 - loss: 0.8067 - val_accuracy: 0.5854 - val_loss: 0.8629\n",
      "Epoch 511/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6106 - loss: 0.8002 - val_accuracy: 0.5962 - val_loss: 0.8442\n",
      "Epoch 512/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6020 - loss: 0.8044 - val_accuracy: 0.6092 - val_loss: 0.8290\n",
      "Epoch 513/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6240 - loss: 0.7795 - val_accuracy: 0.5938 - val_loss: 0.8424\n",
      "Epoch 514/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6242 - loss: 0.7989 - val_accuracy: 0.6146 - val_loss: 0.8276\n",
      "Epoch 515/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6046 - loss: 0.8092 - val_accuracy: 0.5769 - val_loss: 0.8709\n",
      "Epoch 516/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6071 - loss: 0.8216 - val_accuracy: 0.6115 - val_loss: 0.8433\n",
      "Epoch 517/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6083 - loss: 0.7990 - val_accuracy: 0.5577 - val_loss: 0.9101\n",
      "Epoch 518/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6085 - loss: 0.8036 - val_accuracy: 0.5754 - val_loss: 0.8539\n",
      "Epoch 519/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6079 - loss: 0.8000 - val_accuracy: 0.6000 - val_loss: 0.8221\n",
      "Epoch 520/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6238 - loss: 0.7876 - val_accuracy: 0.5869 - val_loss: 0.8618\n",
      "Epoch 521/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6193 - loss: 0.7937 - val_accuracy: 0.5592 - val_loss: 0.8681\n",
      "Epoch 522/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6171 - loss: 0.7858 - val_accuracy: 0.6015 - val_loss: 0.8367\n",
      "Epoch 523/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6230 - loss: 0.7998 - val_accuracy: 0.6192 - val_loss: 0.8206\n",
      "Epoch 524/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6169 - loss: 0.7825 - val_accuracy: 0.6000 - val_loss: 0.8387\n",
      "Epoch 525/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6472 - loss: 0.7709 - val_accuracy: 0.5908 - val_loss: 0.8205\n",
      "Epoch 526/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6258 - loss: 0.7962 - val_accuracy: 0.5623 - val_loss: 0.8548\n",
      "Epoch 527/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5994 - loss: 0.8078 - val_accuracy: 0.5962 - val_loss: 0.8232\n",
      "Epoch 528/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6157 - loss: 0.7979 - val_accuracy: 0.6108 - val_loss: 0.8172\n",
      "Epoch 529/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6026 - loss: 0.7909 - val_accuracy: 0.6138 - val_loss: 0.8134\n",
      "Epoch 530/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6310 - loss: 0.7849 - val_accuracy: 0.6115 - val_loss: 0.8278\n",
      "Epoch 531/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6141 - loss: 0.7897 - val_accuracy: 0.5938 - val_loss: 0.8424\n",
      "Epoch 532/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6183 - loss: 0.7944 - val_accuracy: 0.5769 - val_loss: 0.8393\n",
      "Epoch 533/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6093 - loss: 0.7912 - val_accuracy: 0.6046 - val_loss: 0.8389\n",
      "Epoch 534/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6257 - loss: 0.7881 - val_accuracy: 0.4762 - val_loss: 0.9461\n",
      "Epoch 535/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5707 - loss: 0.8533 - val_accuracy: 0.5946 - val_loss: 0.8261\n",
      "Epoch 536/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6187 - loss: 0.7944 - val_accuracy: 0.5923 - val_loss: 0.8522\n",
      "Epoch 537/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6222 - loss: 0.7954 - val_accuracy: 0.6131 - val_loss: 0.8303\n",
      "Epoch 538/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6145 - loss: 0.7988 - val_accuracy: 0.5854 - val_loss: 0.8449\n",
      "Epoch 539/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6333 - loss: 0.7730 - val_accuracy: 0.5969 - val_loss: 0.8814\n",
      "Epoch 540/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6122 - loss: 0.8009 - val_accuracy: 0.6092 - val_loss: 0.8496\n",
      "Epoch 541/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6304 - loss: 0.7829 - val_accuracy: 0.5538 - val_loss: 0.8634\n",
      "Epoch 542/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5800 - loss: 0.8570 - val_accuracy: 0.5254 - val_loss: 0.8826\n",
      "Epoch 543/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5814 - loss: 0.8271 - val_accuracy: 0.6015 - val_loss: 0.8384\n",
      "Epoch 544/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6095 - loss: 0.8167 - val_accuracy: 0.6077 - val_loss: 0.8472\n",
      "Epoch 545/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5951 - loss: 0.8287 - val_accuracy: 0.5900 - val_loss: 0.8523\n",
      "Epoch 546/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6293 - loss: 0.7941 - val_accuracy: 0.5946 - val_loss: 0.8573\n",
      "Epoch 547/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6104 - loss: 0.8193 - val_accuracy: 0.5792 - val_loss: 0.8687\n",
      "Epoch 548/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6094 - loss: 0.8084 - val_accuracy: 0.6038 - val_loss: 0.8373\n",
      "Epoch 549/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6002 - loss: 0.8148 - val_accuracy: 0.6008 - val_loss: 0.8470\n",
      "Epoch 550/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6179 - loss: 0.8064 - val_accuracy: 0.6023 - val_loss: 0.8636\n",
      "Epoch 551/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6158 - loss: 0.8162 - val_accuracy: 0.5885 - val_loss: 0.8547\n",
      "Epoch 552/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6136 - loss: 0.8036 - val_accuracy: 0.5715 - val_loss: 0.8559\n",
      "Epoch 553/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5993 - loss: 0.8129 - val_accuracy: 0.5954 - val_loss: 0.8560\n",
      "Epoch 554/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6000 - loss: 0.8114 - val_accuracy: 0.5915 - val_loss: 0.8614\n",
      "Epoch 555/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6076 - loss: 0.8078 - val_accuracy: 0.5862 - val_loss: 0.8862\n",
      "Epoch 556/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6206 - loss: 0.8102 - val_accuracy: 0.6000 - val_loss: 0.8603\n",
      "Epoch 557/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6138 - loss: 0.7991 - val_accuracy: 0.5931 - val_loss: 0.8653\n",
      "Epoch 558/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6221 - loss: 0.8134 - val_accuracy: 0.5631 - val_loss: 0.8805\n",
      "Epoch 559/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6095 - loss: 0.8124 - val_accuracy: 0.5900 - val_loss: 0.8777\n",
      "Epoch 560/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6082 - loss: 0.8027 - val_accuracy: 0.5754 - val_loss: 0.8930\n",
      "Epoch 561/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6030 - loss: 0.8336 - val_accuracy: 0.6069 - val_loss: 0.8576\n",
      "Epoch 562/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6126 - loss: 0.8303 - val_accuracy: 0.6077 - val_loss: 0.8882\n",
      "Epoch 563/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6006 - loss: 0.8294 - val_accuracy: 0.5723 - val_loss: 0.8896\n",
      "Epoch 564/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6085 - loss: 0.8329 - val_accuracy: 0.5869 - val_loss: 0.9071\n",
      "Epoch 565/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6150 - loss: 0.8044 - val_accuracy: 0.6077 - val_loss: 0.8609\n",
      "Epoch 566/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6155 - loss: 0.7886 - val_accuracy: 0.6000 - val_loss: 0.8518\n",
      "Epoch 567/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6098 - loss: 0.7927 - val_accuracy: 0.5723 - val_loss: 0.8681\n",
      "Epoch 568/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6072 - loss: 0.8151 - val_accuracy: 0.5769 - val_loss: 0.8826\n",
      "Epoch 569/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5944 - loss: 0.8355 - val_accuracy: 0.5662 - val_loss: 0.8739\n",
      "Epoch 570/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5917 - loss: 0.8436 - val_accuracy: 0.6031 - val_loss: 0.8627\n",
      "Epoch 571/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5910 - loss: 0.8345 - val_accuracy: 0.6100 - val_loss: 0.8437\n",
      "Epoch 572/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6159 - loss: 0.8149 - val_accuracy: 0.5515 - val_loss: 0.8837\n",
      "Epoch 573/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6076 - loss: 0.8299 - val_accuracy: 0.5908 - val_loss: 0.8802\n",
      "Epoch 574/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6129 - loss: 0.8131 - val_accuracy: 0.6023 - val_loss: 0.8672\n",
      "Epoch 575/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6090 - loss: 0.8197 - val_accuracy: 0.6015 - val_loss: 0.8789\n",
      "Epoch 576/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6043 - loss: 0.8202 - val_accuracy: 0.6062 - val_loss: 0.8640\n",
      "Epoch 577/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6183 - loss: 0.8040 - val_accuracy: 0.5869 - val_loss: 0.8732\n",
      "Epoch 578/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5805 - loss: 0.8545 - val_accuracy: 0.5685 - val_loss: 0.9001\n",
      "Epoch 579/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6145 - loss: 0.8192 - val_accuracy: 0.5992 - val_loss: 0.8550\n",
      "Epoch 580/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6173 - loss: 0.8094 - val_accuracy: 0.5992 - val_loss: 0.8508\n",
      "Epoch 581/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5963 - loss: 0.8118 - val_accuracy: 0.5831 - val_loss: 0.8774\n",
      "Epoch 582/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5951 - loss: 0.8181 - val_accuracy: 0.5685 - val_loss: 0.8673\n",
      "Epoch 583/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6005 - loss: 0.8120 - val_accuracy: 0.5854 - val_loss: 0.8648\n",
      "Epoch 584/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6166 - loss: 0.8096 - val_accuracy: 0.6069 - val_loss: 0.8472\n",
      "Epoch 585/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6119 - loss: 0.8133 - val_accuracy: 0.6085 - val_loss: 0.8425\n",
      "Epoch 586/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6121 - loss: 0.7967 - val_accuracy: 0.5823 - val_loss: 0.8579\n",
      "Epoch 587/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5964 - loss: 0.8188 - val_accuracy: 0.5600 - val_loss: 0.8639\n",
      "Epoch 588/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5999 - loss: 0.8196 - val_accuracy: 0.6038 - val_loss: 0.8387\n",
      "Epoch 589/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6246 - loss: 0.7975 - val_accuracy: 0.6038 - val_loss: 0.8518\n",
      "Epoch 590/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6303 - loss: 0.7912 - val_accuracy: 0.5892 - val_loss: 0.8403\n",
      "Epoch 591/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6116 - loss: 0.8023 - val_accuracy: 0.6015 - val_loss: 0.8478\n",
      "Epoch 592/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6177 - loss: 0.7939 - val_accuracy: 0.5608 - val_loss: 0.8709\n",
      "Epoch 593/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5985 - loss: 0.8128 - val_accuracy: 0.5946 - val_loss: 0.8645\n",
      "Epoch 594/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6095 - loss: 0.8195 - val_accuracy: 0.6054 - val_loss: 0.8364\n",
      "Epoch 595/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5931 - loss: 0.8078 - val_accuracy: 0.5915 - val_loss: 0.8708\n",
      "Epoch 596/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5849 - loss: 0.8242 - val_accuracy: 0.5946 - val_loss: 0.8872\n",
      "Epoch 597/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6016 - loss: 0.8225 - val_accuracy: 0.4631 - val_loss: 0.9108\n",
      "Epoch 598/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5857 - loss: 0.8167 - val_accuracy: 0.6023 - val_loss: 0.8460\n",
      "Epoch 599/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5925 - loss: 0.8111 - val_accuracy: 0.6085 - val_loss: 0.8582\n",
      "Epoch 600/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6181 - loss: 0.7987 - val_accuracy: 0.6115 - val_loss: 0.8444\n",
      "Epoch 601/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6220 - loss: 0.7877 - val_accuracy: 0.6123 - val_loss: 0.8451\n",
      "Epoch 602/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6114 - loss: 0.8135 - val_accuracy: 0.5869 - val_loss: 0.8854\n",
      "Epoch 603/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5917 - loss: 0.8431 - val_accuracy: 0.5954 - val_loss: 0.8739\n",
      "Epoch 604/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5986 - loss: 0.8301 - val_accuracy: 0.5654 - val_loss: 0.8706\n",
      "Epoch 605/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5823 - loss: 0.8372 - val_accuracy: 0.5977 - val_loss: 0.8421\n",
      "Epoch 606/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6148 - loss: 0.7969 - val_accuracy: 0.6023 - val_loss: 0.8434\n",
      "Epoch 607/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6085 - loss: 0.8216 - val_accuracy: 0.5562 - val_loss: 0.8962\n",
      "Epoch 608/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5587 - loss: 0.8813 - val_accuracy: 0.5538 - val_loss: 0.8751\n",
      "Epoch 609/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5880 - loss: 0.8397 - val_accuracy: 0.5577 - val_loss: 0.8741\n",
      "Epoch 610/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5829 - loss: 0.8409 - val_accuracy: 0.5638 - val_loss: 0.8734\n",
      "Epoch 611/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5885 - loss: 0.8312 - val_accuracy: 0.5892 - val_loss: 0.8454\n",
      "Epoch 612/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6032 - loss: 0.7936 - val_accuracy: 0.5869 - val_loss: 0.8582\n",
      "Epoch 613/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6019 - loss: 0.7945 - val_accuracy: 0.5938 - val_loss: 0.8466\n",
      "Epoch 614/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5982 - loss: 0.7999 - val_accuracy: 0.5954 - val_loss: 0.8598\n",
      "Epoch 615/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6350 - loss: 0.7826 - val_accuracy: 0.5915 - val_loss: 0.8522\n",
      "Epoch 616/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6108 - loss: 0.7997 - val_accuracy: 0.5915 - val_loss: 0.8912\n",
      "Epoch 617/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5931 - loss: 0.8374 - val_accuracy: 0.5962 - val_loss: 0.8767\n",
      "Epoch 618/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6123 - loss: 0.8057 - val_accuracy: 0.5954 - val_loss: 0.8703\n",
      "Epoch 619/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6261 - loss: 0.7916 - val_accuracy: 0.6008 - val_loss: 0.8803\n",
      "Epoch 620/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5959 - loss: 0.8498 - val_accuracy: 0.5877 - val_loss: 0.8885\n",
      "Epoch 621/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5987 - loss: 0.8246 - val_accuracy: 0.5977 - val_loss: 0.8769\n",
      "Epoch 622/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6208 - loss: 0.8095 - val_accuracy: 0.5900 - val_loss: 0.8824\n",
      "Epoch 623/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6077 - loss: 0.8258 - val_accuracy: 0.5992 - val_loss: 0.8759\n",
      "Epoch 624/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6001 - loss: 0.8276 - val_accuracy: 0.5869 - val_loss: 0.8923\n",
      "Epoch 625/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6155 - loss: 0.7868 - val_accuracy: 0.5492 - val_loss: 0.8795\n",
      "Epoch 626/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6038 - loss: 0.8286 - val_accuracy: 0.6123 - val_loss: 0.8422\n",
      "Epoch 627/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6133 - loss: 0.8095 - val_accuracy: 0.5915 - val_loss: 0.8550\n",
      "Epoch 628/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5854 - loss: 0.8254 - val_accuracy: 0.6023 - val_loss: 0.9036\n",
      "Epoch 629/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6215 - loss: 0.8224 - val_accuracy: 0.6000 - val_loss: 0.8633\n",
      "Epoch 630/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6157 - loss: 0.7932 - val_accuracy: 0.6046 - val_loss: 0.8566\n",
      "Epoch 631/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6072 - loss: 0.8045 - val_accuracy: 0.5908 - val_loss: 0.8852\n",
      "Epoch 632/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6078 - loss: 0.8012 - val_accuracy: 0.6054 - val_loss: 0.8587\n",
      "Epoch 633/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6253 - loss: 0.7818 - val_accuracy: 0.5762 - val_loss: 0.8629\n",
      "Epoch 634/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6135 - loss: 0.8056 - val_accuracy: 0.6077 - val_loss: 0.8589\n",
      "Epoch 635/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5998 - loss: 0.8062 - val_accuracy: 0.5838 - val_loss: 0.8688\n",
      "Epoch 636/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6160 - loss: 0.7900 - val_accuracy: 0.5969 - val_loss: 0.8596\n",
      "Epoch 637/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6170 - loss: 0.8006 - val_accuracy: 0.5931 - val_loss: 0.8471\n",
      "Epoch 638/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6290 - loss: 0.7847 - val_accuracy: 0.6062 - val_loss: 0.8704\n",
      "Epoch 639/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6176 - loss: 0.8030 - val_accuracy: 0.5715 - val_loss: 0.8876\n",
      "Epoch 640/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6178 - loss: 0.8196 - val_accuracy: 0.5923 - val_loss: 0.8897\n",
      "Epoch 641/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6036 - loss: 0.8288 - val_accuracy: 0.5477 - val_loss: 0.8946\n",
      "Epoch 642/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6141 - loss: 0.8113 - val_accuracy: 0.6031 - val_loss: 0.8469\n",
      "Epoch 643/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6104 - loss: 0.7970 - val_accuracy: 0.6123 - val_loss: 0.8407\n",
      "Epoch 644/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6088 - loss: 0.8002 - val_accuracy: 0.5931 - val_loss: 0.8730\n",
      "Epoch 645/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6194 - loss: 0.8011 - val_accuracy: 0.5677 - val_loss: 0.8816\n",
      "Epoch 646/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6130 - loss: 0.8015 - val_accuracy: 0.6077 - val_loss: 0.8732\n",
      "Epoch 647/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6313 - loss: 0.7960 - val_accuracy: 0.5869 - val_loss: 0.8520\n",
      "Epoch 648/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6167 - loss: 0.8047 - val_accuracy: 0.6054 - val_loss: 0.8475\n",
      "Epoch 649/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6101 - loss: 0.7985 - val_accuracy: 0.5485 - val_loss: 0.8843\n",
      "Epoch 650/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5933 - loss: 0.8263 - val_accuracy: 0.5492 - val_loss: 0.8970\n",
      "Epoch 651/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5909 - loss: 0.8258 - val_accuracy: 0.5600 - val_loss: 0.8991\n",
      "Epoch 652/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5874 - loss: 0.8449 - val_accuracy: 0.5462 - val_loss: 0.8938\n",
      "Epoch 653/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5881 - loss: 0.8274 - val_accuracy: 0.5677 - val_loss: 0.8958\n",
      "Epoch 654/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6068 - loss: 0.8185 - val_accuracy: 0.5485 - val_loss: 0.8708\n",
      "Epoch 655/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5857 - loss: 0.8202 - val_accuracy: 0.5562 - val_loss: 0.8795\n",
      "Epoch 656/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5880 - loss: 0.8298 - val_accuracy: 0.5692 - val_loss: 0.8602\n",
      "Epoch 657/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6011 - loss: 0.8177 - val_accuracy: 0.5692 - val_loss: 0.8778\n",
      "Epoch 658/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6058 - loss: 0.8163 - val_accuracy: 0.5715 - val_loss: 0.8838\n",
      "Epoch 659/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6084 - loss: 0.8068 - val_accuracy: 0.5800 - val_loss: 0.8726\n",
      "Epoch 660/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6230 - loss: 0.7956 - val_accuracy: 0.5731 - val_loss: 0.8653\n",
      "Epoch 661/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6156 - loss: 0.7926 - val_accuracy: 0.5992 - val_loss: 0.8732\n",
      "Epoch 662/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5861 - loss: 0.8276 - val_accuracy: 0.6046 - val_loss: 0.8591\n",
      "Epoch 663/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6145 - loss: 0.8001 - val_accuracy: 0.5969 - val_loss: 0.8567\n",
      "Epoch 664/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5503 - loss: 0.8828 - val_accuracy: 0.5808 - val_loss: 0.8945\n",
      "Epoch 665/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5332 - loss: 0.8978 - val_accuracy: 0.6108 - val_loss: 0.8529\n",
      "Epoch 666/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5881 - loss: 0.8337 - val_accuracy: 0.5708 - val_loss: 0.8818\n",
      "Epoch 667/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5947 - loss: 0.8472 - val_accuracy: 0.6054 - val_loss: 0.8241\n",
      "Epoch 668/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5950 - loss: 0.8253 - val_accuracy: 0.5977 - val_loss: 0.8589\n",
      "Epoch 669/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6163 - loss: 0.8054 - val_accuracy: 0.5862 - val_loss: 0.8600\n",
      "Epoch 670/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5949 - loss: 0.8208 - val_accuracy: 0.6046 - val_loss: 0.8560\n",
      "Epoch 671/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6054 - loss: 0.8075 - val_accuracy: 0.6000 - val_loss: 0.8568\n",
      "Epoch 672/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6245 - loss: 0.8106 - val_accuracy: 0.6054 - val_loss: 0.8555\n",
      "Epoch 673/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5941 - loss: 0.8290 - val_accuracy: 0.5908 - val_loss: 0.8643\n",
      "Epoch 674/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6051 - loss: 0.8166 - val_accuracy: 0.6085 - val_loss: 0.8398\n",
      "Epoch 675/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6088 - loss: 0.8066 - val_accuracy: 0.5823 - val_loss: 0.8457\n",
      "Epoch 676/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6000 - loss: 0.8083 - val_accuracy: 0.5938 - val_loss: 0.9181\n",
      "Epoch 677/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5907 - loss: 0.8402 - val_accuracy: 0.6054 - val_loss: 0.8602\n",
      "Epoch 678/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5831 - loss: 0.8159 - val_accuracy: 0.6185 - val_loss: 0.8219\n",
      "Epoch 679/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6222 - loss: 0.7720 - val_accuracy: 0.6223 - val_loss: 0.8329\n",
      "Epoch 680/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6254 - loss: 0.7974 - val_accuracy: 0.5962 - val_loss: 0.8887\n",
      "Epoch 681/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6133 - loss: 0.8093 - val_accuracy: 0.6085 - val_loss: 0.8577\n",
      "Epoch 682/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6013 - loss: 0.7919 - val_accuracy: 0.6177 - val_loss: 0.8512\n",
      "Epoch 683/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6170 - loss: 0.8036 - val_accuracy: 0.6085 - val_loss: 0.8278\n",
      "Epoch 684/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6142 - loss: 0.7998 - val_accuracy: 0.6154 - val_loss: 0.8342\n",
      "Epoch 685/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6282 - loss: 0.7813 - val_accuracy: 0.5354 - val_loss: 0.9342\n",
      "Epoch 686/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5703 - loss: 0.8594 - val_accuracy: 0.6000 - val_loss: 0.8546\n",
      "Epoch 687/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6169 - loss: 0.8130 - val_accuracy: 0.6015 - val_loss: 0.8341\n",
      "Epoch 688/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6131 - loss: 0.8076 - val_accuracy: 0.5615 - val_loss: 0.8546\n",
      "Epoch 689/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6177 - loss: 0.8077 - val_accuracy: 0.6185 - val_loss: 0.8351\n",
      "Epoch 690/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6338 - loss: 0.7923 - val_accuracy: 0.6154 - val_loss: 0.8334\n",
      "Epoch 691/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6270 - loss: 0.8045 - val_accuracy: 0.6015 - val_loss: 0.8459\n",
      "Epoch 692/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6272 - loss: 0.7865 - val_accuracy: 0.6154 - val_loss: 0.8253\n",
      "Epoch 693/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6292 - loss: 0.7868 - val_accuracy: 0.6023 - val_loss: 0.8296\n",
      "Epoch 694/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6055 - loss: 0.7986 - val_accuracy: 0.5600 - val_loss: 0.8643\n",
      "Epoch 695/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5924 - loss: 0.8317 - val_accuracy: 0.5938 - val_loss: 0.8583\n",
      "Epoch 696/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6167 - loss: 0.8138 - val_accuracy: 0.5969 - val_loss: 0.8515\n",
      "Epoch 697/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5862 - loss: 0.8341 - val_accuracy: 0.5731 - val_loss: 0.8856\n",
      "Epoch 698/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6101 - loss: 0.8157 - val_accuracy: 0.5769 - val_loss: 0.9471\n",
      "Epoch 699/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6090 - loss: 0.8128 - val_accuracy: 0.5554 - val_loss: 0.9095\n",
      "Epoch 700/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5889 - loss: 0.8384 - val_accuracy: 0.5754 - val_loss: 0.8699\n",
      "Epoch 701/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6005 - loss: 0.8262 - val_accuracy: 0.5754 - val_loss: 0.8775\n",
      "Epoch 702/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6083 - loss: 0.8367 - val_accuracy: 0.6100 - val_loss: 0.8511\n",
      "Epoch 703/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6109 - loss: 0.8179 - val_accuracy: 0.5738 - val_loss: 0.8776\n",
      "Epoch 704/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5938 - loss: 0.8491 - val_accuracy: 0.6031 - val_loss: 0.8520\n",
      "Epoch 705/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6186 - loss: 0.8059 - val_accuracy: 0.5777 - val_loss: 0.8583\n",
      "Epoch 706/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6317 - loss: 0.7956 - val_accuracy: 0.6092 - val_loss: 0.8336\n",
      "Epoch 707/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6473 - loss: 0.7750 - val_accuracy: 0.6015 - val_loss: 0.8359\n",
      "Epoch 708/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6345 - loss: 0.7802 - val_accuracy: 0.6123 - val_loss: 0.8386\n",
      "Epoch 709/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6169 - loss: 0.7872 - val_accuracy: 0.6177 - val_loss: 0.8298\n",
      "Epoch 710/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6169 - loss: 0.7876 - val_accuracy: 0.5985 - val_loss: 0.8334\n",
      "Epoch 711/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6299 - loss: 0.7904 - val_accuracy: 0.6231 - val_loss: 0.8311\n",
      "Epoch 712/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6196 - loss: 0.7788 - val_accuracy: 0.6054 - val_loss: 0.8462\n",
      "Epoch 713/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6091 - loss: 0.8099 - val_accuracy: 0.6169 - val_loss: 0.8262\n",
      "Epoch 714/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6290 - loss: 0.7842 - val_accuracy: 0.5992 - val_loss: 0.8595\n",
      "Epoch 715/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6100 - loss: 0.8001 - val_accuracy: 0.5846 - val_loss: 0.8439\n",
      "Epoch 716/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6155 - loss: 0.8038 - val_accuracy: 0.5938 - val_loss: 0.8289\n",
      "Epoch 717/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6112 - loss: 0.7963 - val_accuracy: 0.5962 - val_loss: 0.8413\n",
      "Epoch 718/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6282 - loss: 0.7969 - val_accuracy: 0.6169 - val_loss: 0.8556\n",
      "Epoch 719/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6357 - loss: 0.7659 - val_accuracy: 0.6192 - val_loss: 0.8310\n",
      "Epoch 720/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6241 - loss: 0.7833 - val_accuracy: 0.6054 - val_loss: 0.8424\n",
      "Epoch 721/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6084 - loss: 0.8041 - val_accuracy: 0.6108 - val_loss: 0.8347\n",
      "Epoch 722/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6101 - loss: 0.8010 - val_accuracy: 0.6154 - val_loss: 0.8274\n",
      "Epoch 723/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6166 - loss: 0.7958 - val_accuracy: 0.6208 - val_loss: 0.8526\n",
      "Epoch 724/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6061 - loss: 0.7999 - val_accuracy: 0.5992 - val_loss: 0.8350\n",
      "Epoch 725/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6131 - loss: 0.8181 - val_accuracy: 0.5808 - val_loss: 0.8775\n",
      "Epoch 726/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5897 - loss: 0.8274 - val_accuracy: 0.5877 - val_loss: 0.8663\n",
      "Epoch 727/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6041 - loss: 0.8137 - val_accuracy: 0.6077 - val_loss: 0.8451\n",
      "Epoch 728/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6068 - loss: 0.8310 - val_accuracy: 0.5923 - val_loss: 0.8767\n",
      "Epoch 729/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6019 - loss: 0.8146 - val_accuracy: 0.6131 - val_loss: 0.8876\n",
      "Epoch 730/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6190 - loss: 0.7970 - val_accuracy: 0.5969 - val_loss: 0.8647\n",
      "Epoch 731/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6106 - loss: 0.8073 - val_accuracy: 0.6062 - val_loss: 0.8469\n",
      "Epoch 732/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6187 - loss: 0.7977 - val_accuracy: 0.6123 - val_loss: 0.8470\n",
      "Epoch 733/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6302 - loss: 0.7916 - val_accuracy: 0.6023 - val_loss: 0.8785\n",
      "Epoch 734/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6216 - loss: 0.8032 - val_accuracy: 0.6015 - val_loss: 0.8529\n",
      "Epoch 735/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6297 - loss: 0.7823 - val_accuracy: 0.6023 - val_loss: 0.8368\n",
      "Epoch 736/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6105 - loss: 0.8131 - val_accuracy: 0.5769 - val_loss: 0.8674\n",
      "Epoch 737/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6265 - loss: 0.7967 - val_accuracy: 0.6085 - val_loss: 0.8433\n",
      "Epoch 738/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6151 - loss: 0.7919 - val_accuracy: 0.5846 - val_loss: 0.8585\n",
      "Epoch 739/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6173 - loss: 0.7988 - val_accuracy: 0.5831 - val_loss: 0.8732\n",
      "Epoch 740/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6153 - loss: 0.8126 - val_accuracy: 0.5977 - val_loss: 0.8388\n",
      "Epoch 741/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6064 - loss: 0.8214 - val_accuracy: 0.5900 - val_loss: 0.8741\n",
      "Epoch 742/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5845 - loss: 0.8342 - val_accuracy: 0.5908 - val_loss: 0.8613\n",
      "Epoch 743/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5998 - loss: 0.8302 - val_accuracy: 0.5792 - val_loss: 0.8981\n",
      "Epoch 744/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5745 - loss: 0.8476 - val_accuracy: 0.5592 - val_loss: 0.8831\n",
      "Epoch 745/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6047 - loss: 0.8174 - val_accuracy: 0.5592 - val_loss: 0.8895\n",
      "Epoch 746/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6036 - loss: 0.8280 - val_accuracy: 0.5954 - val_loss: 0.8490\n",
      "Epoch 747/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6015 - loss: 0.8145 - val_accuracy: 0.5923 - val_loss: 0.8466\n",
      "Epoch 748/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6009 - loss: 0.8157 - val_accuracy: 0.6108 - val_loss: 0.8399\n",
      "Epoch 749/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6247 - loss: 0.7982 - val_accuracy: 0.6085 - val_loss: 0.8462\n",
      "Epoch 750/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6173 - loss: 0.7888 - val_accuracy: 0.6062 - val_loss: 0.8537\n",
      "Epoch 751/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6183 - loss: 0.8059 - val_accuracy: 0.6046 - val_loss: 0.8248\n",
      "Epoch 752/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6002 - loss: 0.8209 - val_accuracy: 0.5869 - val_loss: 0.8594\n",
      "Epoch 753/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6027 - loss: 0.8079 - val_accuracy: 0.5885 - val_loss: 0.8491\n",
      "Epoch 754/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6239 - loss: 0.7920 - val_accuracy: 0.5631 - val_loss: 0.8742\n",
      "Epoch 755/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5790 - loss: 0.8408 - val_accuracy: 0.6038 - val_loss: 0.8572\n",
      "Epoch 756/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6041 - loss: 0.8261 - val_accuracy: 0.5785 - val_loss: 0.8711\n",
      "Epoch 757/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5985 - loss: 0.8536 - val_accuracy: 0.5546 - val_loss: 0.9200\n",
      "Epoch 758/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5823 - loss: 0.8541 - val_accuracy: 0.5585 - val_loss: 0.9104\n",
      "Epoch 759/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6004 - loss: 0.8605 - val_accuracy: 0.5369 - val_loss: 0.9145\n",
      "Epoch 760/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6034 - loss: 0.8284 - val_accuracy: 0.5846 - val_loss: 0.8854\n",
      "Epoch 761/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5979 - loss: 0.8308 - val_accuracy: 0.5992 - val_loss: 0.8485\n",
      "Epoch 762/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6188 - loss: 0.8115 - val_accuracy: 0.6108 - val_loss: 0.8405\n",
      "Epoch 763/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5916 - loss: 0.8235 - val_accuracy: 0.5746 - val_loss: 0.8718\n",
      "Epoch 764/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6084 - loss: 0.8121 - val_accuracy: 0.5877 - val_loss: 0.8462\n",
      "Epoch 765/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6068 - loss: 0.8173 - val_accuracy: 0.6062 - val_loss: 0.8457\n",
      "Epoch 766/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6150 - loss: 0.8067 - val_accuracy: 0.6069 - val_loss: 0.8406\n",
      "Epoch 767/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6244 - loss: 0.7906 - val_accuracy: 0.6100 - val_loss: 0.8594\n",
      "Epoch 768/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6113 - loss: 0.8037 - val_accuracy: 0.5769 - val_loss: 0.8556\n",
      "Epoch 769/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6297 - loss: 0.7965 - val_accuracy: 0.5862 - val_loss: 0.8845\n",
      "Epoch 770/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6151 - loss: 0.8011 - val_accuracy: 0.5846 - val_loss: 0.8686\n",
      "Epoch 771/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6276 - loss: 0.7923 - val_accuracy: 0.6123 - val_loss: 0.8386\n",
      "Epoch 772/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6007 - loss: 0.8090 - val_accuracy: 0.6015 - val_loss: 0.8473\n",
      "Epoch 773/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6155 - loss: 0.7811 - val_accuracy: 0.6031 - val_loss: 0.8304\n",
      "Epoch 774/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6083 - loss: 0.8117 - val_accuracy: 0.5985 - val_loss: 0.8372\n",
      "Epoch 775/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5879 - loss: 0.8234 - val_accuracy: 0.6069 - val_loss: 0.8353\n",
      "Epoch 776/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6228 - loss: 0.7920 - val_accuracy: 0.6046 - val_loss: 0.8419\n",
      "Epoch 777/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6061 - loss: 0.8216 - val_accuracy: 0.5862 - val_loss: 0.8992\n",
      "Epoch 778/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5983 - loss: 0.8415 - val_accuracy: 0.5746 - val_loss: 0.8725\n",
      "Epoch 779/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6009 - loss: 0.8233 - val_accuracy: 0.5962 - val_loss: 0.8786\n",
      "Epoch 780/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6049 - loss: 0.8297 - val_accuracy: 0.5862 - val_loss: 0.8690\n",
      "Epoch 781/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6103 - loss: 0.8268 - val_accuracy: 0.5962 - val_loss: 0.8379\n",
      "Epoch 782/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6106 - loss: 0.8318 - val_accuracy: 0.5846 - val_loss: 0.8529\n",
      "Epoch 783/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6169 - loss: 0.8327 - val_accuracy: 0.5900 - val_loss: 0.8610\n",
      "Epoch 784/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6109 - loss: 0.8125 - val_accuracy: 0.6000 - val_loss: 0.8453\n",
      "Epoch 785/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6178 - loss: 0.8093 - val_accuracy: 0.5985 - val_loss: 0.8522\n",
      "Epoch 786/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5881 - loss: 0.8338 - val_accuracy: 0.5977 - val_loss: 0.8568\n",
      "Epoch 787/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5982 - loss: 0.8351 - val_accuracy: 0.5977 - val_loss: 0.8510\n",
      "Epoch 788/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6043 - loss: 0.8317 - val_accuracy: 0.5631 - val_loss: 0.8872\n",
      "Epoch 789/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5954 - loss: 0.8354 - val_accuracy: 0.5931 - val_loss: 0.8474\n",
      "Epoch 790/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6162 - loss: 0.8261 - val_accuracy: 0.5992 - val_loss: 0.8867\n",
      "Epoch 791/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5927 - loss: 0.8486 - val_accuracy: 0.5862 - val_loss: 0.8660\n",
      "Epoch 792/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6069 - loss: 0.8194 - val_accuracy: 0.6023 - val_loss: 0.8593\n",
      "Epoch 793/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6180 - loss: 0.8217 - val_accuracy: 0.5969 - val_loss: 0.8654\n",
      "Epoch 794/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5972 - loss: 0.8535 - val_accuracy: 0.5677 - val_loss: 0.9505\n",
      "Epoch 795/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5858 - loss: 0.8451 - val_accuracy: 0.6069 - val_loss: 0.8668\n",
      "Epoch 796/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6060 - loss: 0.8248 - val_accuracy: 0.5685 - val_loss: 0.8833\n",
      "Epoch 797/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5980 - loss: 0.8294 - val_accuracy: 0.6015 - val_loss: 0.8606\n",
      "Epoch 798/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6247 - loss: 0.8121 - val_accuracy: 0.6077 - val_loss: 0.8658\n",
      "Epoch 799/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5999 - loss: 0.8329 - val_accuracy: 0.5985 - val_loss: 0.8736\n",
      "Epoch 800/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5913 - loss: 0.8315 - val_accuracy: 0.5877 - val_loss: 0.8753\n",
      "Epoch 801/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6187 - loss: 0.8021 - val_accuracy: 0.6054 - val_loss: 0.8519\n",
      "Epoch 802/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5978 - loss: 0.8289 - val_accuracy: 0.5715 - val_loss: 0.8801\n",
      "Epoch 803/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5978 - loss: 0.8162 - val_accuracy: 0.5746 - val_loss: 0.8722\n",
      "Epoch 804/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6069 - loss: 0.8249 - val_accuracy: 0.5869 - val_loss: 0.8696\n",
      "Epoch 805/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6005 - loss: 0.8123 - val_accuracy: 0.5854 - val_loss: 0.8849\n",
      "Epoch 806/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5821 - loss: 0.8415 - val_accuracy: 0.6031 - val_loss: 0.8715\n",
      "Epoch 807/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6181 - loss: 0.8181 - val_accuracy: 0.5908 - val_loss: 0.8829\n",
      "Epoch 808/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6175 - loss: 0.8131 - val_accuracy: 0.5831 - val_loss: 0.8937\n",
      "Epoch 809/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5960 - loss: 0.8275 - val_accuracy: 0.5785 - val_loss: 0.8867\n",
      "Epoch 810/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6093 - loss: 0.8134 - val_accuracy: 0.5808 - val_loss: 0.8945\n",
      "Epoch 811/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6023 - loss: 0.8201 - val_accuracy: 0.5869 - val_loss: 0.8678\n",
      "Epoch 812/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6097 - loss: 0.8267 - val_accuracy: 0.5969 - val_loss: 0.8763\n",
      "Epoch 813/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6221 - loss: 0.8125 - val_accuracy: 0.5746 - val_loss: 0.9074\n",
      "Epoch 814/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6171 - loss: 0.8124 - val_accuracy: 0.5777 - val_loss: 0.8717\n",
      "Epoch 815/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6114 - loss: 0.8188 - val_accuracy: 0.5900 - val_loss: 0.8874\n",
      "Epoch 816/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6094 - loss: 0.8195 - val_accuracy: 0.6077 - val_loss: 0.8828\n",
      "Epoch 817/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6123 - loss: 0.8152 - val_accuracy: 0.5846 - val_loss: 0.8762\n",
      "Epoch 818/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6200 - loss: 0.8066 - val_accuracy: 0.5946 - val_loss: 0.8835\n",
      "Epoch 819/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6109 - loss: 0.8137 - val_accuracy: 0.5677 - val_loss: 0.9015\n",
      "Epoch 820/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6124 - loss: 0.8162 - val_accuracy: 0.5831 - val_loss: 0.8898\n",
      "Epoch 821/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6238 - loss: 0.8052 - val_accuracy: 0.5900 - val_loss: 0.8754\n",
      "Epoch 822/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6163 - loss: 0.8219 - val_accuracy: 0.5338 - val_loss: 0.9075\n",
      "Epoch 823/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6121 - loss: 0.8076 - val_accuracy: 0.5869 - val_loss: 0.8889\n",
      "Epoch 824/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6118 - loss: 0.8051 - val_accuracy: 0.5908 - val_loss: 0.8695\n",
      "Epoch 825/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5900 - loss: 0.8229 - val_accuracy: 0.5954 - val_loss: 0.8794\n",
      "Epoch 826/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6043 - loss: 0.8169 - val_accuracy: 0.5731 - val_loss: 0.9107\n",
      "Epoch 827/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5959 - loss: 0.8266 - val_accuracy: 0.5785 - val_loss: 0.8900\n",
      "Epoch 828/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6141 - loss: 0.8163 - val_accuracy: 0.5792 - val_loss: 0.8707\n",
      "Epoch 829/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6063 - loss: 0.8181 - val_accuracy: 0.6062 - val_loss: 0.8765\n",
      "Epoch 830/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6028 - loss: 0.8343 - val_accuracy: 0.5854 - val_loss: 0.8745\n",
      "Epoch 831/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5900 - loss: 0.8357 - val_accuracy: 0.5923 - val_loss: 0.8818\n",
      "Epoch 832/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5905 - loss: 0.8339 - val_accuracy: 0.6085 - val_loss: 0.8717\n",
      "Epoch 833/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5789 - loss: 0.8451 - val_accuracy: 0.5962 - val_loss: 0.9109\n",
      "Epoch 834/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6022 - loss: 0.8274 - val_accuracy: 0.6015 - val_loss: 0.8937\n",
      "Epoch 835/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6093 - loss: 0.8244 - val_accuracy: 0.5731 - val_loss: 0.8876\n",
      "Epoch 836/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5980 - loss: 0.8209 - val_accuracy: 0.5531 - val_loss: 0.8993\n",
      "Epoch 837/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6080 - loss: 0.8271 - val_accuracy: 0.5954 - val_loss: 0.8835\n",
      "Epoch 838/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6134 - loss: 0.8199 - val_accuracy: 0.6023 - val_loss: 0.8892\n",
      "Epoch 839/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6040 - loss: 0.8231 - val_accuracy: 0.5923 - val_loss: 0.8824\n",
      "Epoch 840/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6219 - loss: 0.8207 - val_accuracy: 0.6031 - val_loss: 0.8539\n",
      "Epoch 841/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6076 - loss: 0.8213 - val_accuracy: 0.5962 - val_loss: 0.8431\n",
      "Epoch 842/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6060 - loss: 0.8302 - val_accuracy: 0.6054 - val_loss: 0.8520\n",
      "Epoch 843/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5977 - loss: 0.8255 - val_accuracy: 0.5723 - val_loss: 0.8520\n",
      "Epoch 844/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5982 - loss: 0.8162 - val_accuracy: 0.5577 - val_loss: 0.8784\n",
      "Epoch 845/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6035 - loss: 0.8326 - val_accuracy: 0.5846 - val_loss: 0.8545\n",
      "Epoch 846/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5943 - loss: 0.8363 - val_accuracy: 0.5969 - val_loss: 0.8407\n",
      "Epoch 847/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5949 - loss: 0.8290 - val_accuracy: 0.5977 - val_loss: 0.8378\n",
      "Epoch 848/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5926 - loss: 0.8267 - val_accuracy: 0.5654 - val_loss: 0.8825\n",
      "Epoch 849/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5911 - loss: 0.8314 - val_accuracy: 0.5846 - val_loss: 0.8753\n",
      "Epoch 850/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5929 - loss: 0.8335 - val_accuracy: 0.5877 - val_loss: 0.8565\n",
      "Epoch 851/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5880 - loss: 0.8385 - val_accuracy: 0.5992 - val_loss: 0.8665\n",
      "Epoch 852/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5944 - loss: 0.8239 - val_accuracy: 0.5846 - val_loss: 0.8561\n",
      "Epoch 853/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5840 - loss: 0.8370 - val_accuracy: 0.6038 - val_loss: 0.8430\n",
      "Epoch 854/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6024 - loss: 0.8233 - val_accuracy: 0.5415 - val_loss: 0.8903\n",
      "Epoch 855/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5765 - loss: 0.8410 - val_accuracy: 0.5685 - val_loss: 0.8669\n",
      "Epoch 856/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6051 - loss: 0.8309 - val_accuracy: 0.5985 - val_loss: 0.8540\n",
      "Epoch 857/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6127 - loss: 0.8159 - val_accuracy: 0.5846 - val_loss: 0.8694\n",
      "Epoch 858/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5983 - loss: 0.8289 - val_accuracy: 0.5946 - val_loss: 0.8761\n",
      "Epoch 859/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6013 - loss: 0.8344 - val_accuracy: 0.5962 - val_loss: 0.8493\n",
      "Epoch 860/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6080 - loss: 0.8246 - val_accuracy: 0.5808 - val_loss: 0.8727\n",
      "Epoch 861/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5806 - loss: 0.8447 - val_accuracy: 0.5715 - val_loss: 0.9094\n",
      "Epoch 862/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5750 - loss: 0.8655 - val_accuracy: 0.5854 - val_loss: 0.8657\n",
      "Epoch 863/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5989 - loss: 0.8337 - val_accuracy: 0.6015 - val_loss: 0.8702\n",
      "Epoch 864/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6043 - loss: 0.8315 - val_accuracy: 0.5985 - val_loss: 0.8570\n",
      "Epoch 865/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6093 - loss: 0.8208 - val_accuracy: 0.5969 - val_loss: 0.8569\n",
      "Epoch 866/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6194 - loss: 0.8041 - val_accuracy: 0.6046 - val_loss: 0.8542\n",
      "Epoch 867/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5993 - loss: 0.8322 - val_accuracy: 0.5708 - val_loss: 0.9030\n",
      "Epoch 868/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6064 - loss: 0.8274 - val_accuracy: 0.5708 - val_loss: 0.8716\n",
      "Epoch 869/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6173 - loss: 0.8282 - val_accuracy: 0.6023 - val_loss: 0.8507\n",
      "Epoch 870/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6242 - loss: 0.8239 - val_accuracy: 0.6062 - val_loss: 0.8492\n",
      "Epoch 871/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6143 - loss: 0.8174 - val_accuracy: 0.5754 - val_loss: 0.8768\n",
      "Epoch 872/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6071 - loss: 0.8240 - val_accuracy: 0.5869 - val_loss: 0.8902\n",
      "Epoch 873/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6143 - loss: 0.8092 - val_accuracy: 0.6038 - val_loss: 0.8513\n",
      "Epoch 874/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6104 - loss: 0.8068 - val_accuracy: 0.5692 - val_loss: 0.8930\n",
      "Epoch 875/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6122 - loss: 0.8190 - val_accuracy: 0.6000 - val_loss: 0.8701\n",
      "Epoch 876/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5991 - loss: 0.8188 - val_accuracy: 0.5823 - val_loss: 0.8757\n",
      "Epoch 877/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6130 - loss: 0.8133 - val_accuracy: 0.5877 - val_loss: 0.8723\n",
      "Epoch 878/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6126 - loss: 0.8171 - val_accuracy: 0.5931 - val_loss: 0.8523\n",
      "Epoch 879/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6074 - loss: 0.8151 - val_accuracy: 0.6123 - val_loss: 0.8807\n",
      "Epoch 880/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5917 - loss: 0.8331 - val_accuracy: 0.5931 - val_loss: 0.8662\n",
      "Epoch 881/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6060 - loss: 0.8157 - val_accuracy: 0.5862 - val_loss: 0.8651\n",
      "Epoch 882/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6029 - loss: 0.8236 - val_accuracy: 0.5869 - val_loss: 0.8561\n",
      "Epoch 883/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5907 - loss: 0.8122 - val_accuracy: 0.5785 - val_loss: 0.8570\n",
      "Epoch 884/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5918 - loss: 0.8283 - val_accuracy: 0.5292 - val_loss: 0.8855\n",
      "Epoch 885/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5983 - loss: 0.8233 - val_accuracy: 0.6046 - val_loss: 0.8778\n",
      "Epoch 886/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6142 - loss: 0.8268 - val_accuracy: 0.6031 - val_loss: 0.8682\n",
      "Epoch 887/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5731 - loss: 0.8665 - val_accuracy: 0.5731 - val_loss: 0.8957\n",
      "Epoch 888/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5920 - loss: 0.8507 - val_accuracy: 0.5685 - val_loss: 0.8877\n",
      "Epoch 889/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5900 - loss: 0.8414 - val_accuracy: 0.5985 - val_loss: 0.8883\n",
      "Epoch 890/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6027 - loss: 0.8272 - val_accuracy: 0.5931 - val_loss: 0.8960\n",
      "Epoch 891/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5930 - loss: 0.8461 - val_accuracy: 0.5754 - val_loss: 0.8733\n",
      "Epoch 892/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6110 - loss: 0.8309 - val_accuracy: 0.5969 - val_loss: 0.8701\n",
      "Epoch 893/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5979 - loss: 0.8378 - val_accuracy: 0.5985 - val_loss: 0.8897\n",
      "Epoch 894/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6108 - loss: 0.8231 - val_accuracy: 0.5892 - val_loss: 0.8839\n",
      "Epoch 895/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6001 - loss: 0.8401 - val_accuracy: 0.6131 - val_loss: 0.8693\n",
      "Epoch 896/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6178 - loss: 0.8104 - val_accuracy: 0.6038 - val_loss: 0.8802\n",
      "Epoch 897/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6017 - loss: 0.8344 - val_accuracy: 0.5531 - val_loss: 0.8901\n",
      "Epoch 898/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6025 - loss: 0.8262 - val_accuracy: 0.5931 - val_loss: 0.8865\n",
      "Epoch 899/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5978 - loss: 0.8189 - val_accuracy: 0.5731 - val_loss: 0.8822\n",
      "Epoch 900/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6118 - loss: 0.8145 - val_accuracy: 0.5885 - val_loss: 0.8798\n",
      "Epoch 901/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6140 - loss: 0.8024 - val_accuracy: 0.5785 - val_loss: 0.9040\n",
      "Epoch 902/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6021 - loss: 0.8242 - val_accuracy: 0.6069 - val_loss: 0.9167\n",
      "Epoch 903/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5890 - loss: 0.8456 - val_accuracy: 0.6008 - val_loss: 0.8538\n",
      "Epoch 904/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5913 - loss: 0.8400 - val_accuracy: 0.5838 - val_loss: 0.8553\n",
      "Epoch 905/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6068 - loss: 0.8111 - val_accuracy: 0.5946 - val_loss: 0.8826\n",
      "Epoch 906/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6049 - loss: 0.8272 - val_accuracy: 0.5838 - val_loss: 0.8566\n",
      "Epoch 907/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5946 - loss: 0.8263 - val_accuracy: 0.6023 - val_loss: 0.8758\n",
      "Epoch 908/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6215 - loss: 0.8068 - val_accuracy: 0.5823 - val_loss: 0.8585\n",
      "Epoch 909/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5901 - loss: 0.8292 - val_accuracy: 0.5485 - val_loss: 0.9105\n",
      "Epoch 910/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5977 - loss: 0.8380 - val_accuracy: 0.5877 - val_loss: 0.8602\n",
      "Epoch 911/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5936 - loss: 0.8321 - val_accuracy: 0.5800 - val_loss: 0.8580\n",
      "Epoch 912/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5925 - loss: 0.8233 - val_accuracy: 0.5915 - val_loss: 0.8879\n",
      "Epoch 913/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6050 - loss: 0.8390 - val_accuracy: 0.5615 - val_loss: 0.8793\n",
      "Epoch 914/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5938 - loss: 0.8292 - val_accuracy: 0.5862 - val_loss: 0.8575\n",
      "Epoch 915/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6050 - loss: 0.8234 - val_accuracy: 0.5854 - val_loss: 0.8793\n",
      "Epoch 916/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5850 - loss: 0.8352 - val_accuracy: 0.5546 - val_loss: 0.9184\n",
      "Epoch 917/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5962 - loss: 0.8385 - val_accuracy: 0.5885 - val_loss: 0.8637\n",
      "Epoch 918/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6122 - loss: 0.8076 - val_accuracy: 0.5608 - val_loss: 0.9133\n",
      "Epoch 919/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5839 - loss: 0.8414 - val_accuracy: 0.5985 - val_loss: 0.9037\n",
      "Epoch 920/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6013 - loss: 0.8497 - val_accuracy: 0.6000 - val_loss: 0.8629\n",
      "Epoch 921/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6205 - loss: 0.8338 - val_accuracy: 0.5938 - val_loss: 0.8619\n",
      "Epoch 922/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6057 - loss: 0.8167 - val_accuracy: 0.6023 - val_loss: 0.8555\n",
      "Epoch 923/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6047 - loss: 0.8306 - val_accuracy: 0.5892 - val_loss: 0.8705\n",
      "Epoch 924/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6164 - loss: 0.8183 - val_accuracy: 0.6131 - val_loss: 0.8692\n",
      "Epoch 925/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6163 - loss: 0.8099 - val_accuracy: 0.5800 - val_loss: 0.8877\n",
      "Epoch 926/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6009 - loss: 0.8369 - val_accuracy: 0.6038 - val_loss: 0.8650\n",
      "Epoch 927/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5931 - loss: 0.8376 - val_accuracy: 0.6015 - val_loss: 0.8668\n",
      "Epoch 928/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6042 - loss: 0.8258 - val_accuracy: 0.5815 - val_loss: 0.9209\n",
      "Epoch 929/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6049 - loss: 0.8303 - val_accuracy: 0.5885 - val_loss: 0.8778\n",
      "Epoch 930/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6006 - loss: 0.8357 - val_accuracy: 0.5769 - val_loss: 0.9047\n",
      "Epoch 931/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5963 - loss: 0.8297 - val_accuracy: 0.5969 - val_loss: 0.8723\n",
      "Epoch 932/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6191 - loss: 0.8185 - val_accuracy: 0.5969 - val_loss: 0.8548\n",
      "Epoch 933/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6195 - loss: 0.8071 - val_accuracy: 0.5631 - val_loss: 0.8988\n",
      "Epoch 934/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5958 - loss: 0.8285 - val_accuracy: 0.5777 - val_loss: 0.8670\n",
      "Epoch 935/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5973 - loss: 0.8206 - val_accuracy: 0.5900 - val_loss: 0.8669\n",
      "Epoch 936/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6013 - loss: 0.8115 - val_accuracy: 0.5754 - val_loss: 0.8781\n",
      "Epoch 937/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5997 - loss: 0.8158 - val_accuracy: 0.5785 - val_loss: 0.8691\n",
      "Epoch 938/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6032 - loss: 0.8209 - val_accuracy: 0.5962 - val_loss: 0.8615\n",
      "Epoch 939/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6228 - loss: 0.8037 - val_accuracy: 0.5723 - val_loss: 0.8683\n",
      "Epoch 940/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5907 - loss: 0.8391 - val_accuracy: 0.5677 - val_loss: 0.8995\n",
      "Epoch 941/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5949 - loss: 0.8281 - val_accuracy: 0.5923 - val_loss: 0.8658\n",
      "Epoch 942/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5814 - loss: 0.8324 - val_accuracy: 0.5846 - val_loss: 0.8452\n",
      "Epoch 943/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6044 - loss: 0.8222 - val_accuracy: 0.5946 - val_loss: 0.8379\n",
      "Epoch 944/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6014 - loss: 0.8138 - val_accuracy: 0.6015 - val_loss: 0.8373\n",
      "Epoch 945/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5971 - loss: 0.8295 - val_accuracy: 0.5854 - val_loss: 0.8531\n",
      "Epoch 946/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5991 - loss: 0.8339 - val_accuracy: 0.6054 - val_loss: 0.8400\n",
      "Epoch 947/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6015 - loss: 0.8302 - val_accuracy: 0.5908 - val_loss: 0.8633\n",
      "Epoch 948/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6157 - loss: 0.8163 - val_accuracy: 0.5946 - val_loss: 0.8505\n",
      "Epoch 949/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5976 - loss: 0.8275 - val_accuracy: 0.5969 - val_loss: 0.8397\n",
      "Epoch 950/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6128 - loss: 0.8174 - val_accuracy: 0.5708 - val_loss: 0.9079\n",
      "Epoch 951/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5961 - loss: 0.8333 - val_accuracy: 0.5615 - val_loss: 0.9152\n",
      "Epoch 952/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5888 - loss: 0.8462 - val_accuracy: 0.5938 - val_loss: 0.8590\n",
      "Epoch 953/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6013 - loss: 0.8195 - val_accuracy: 0.5969 - val_loss: 0.8463\n",
      "Epoch 954/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6087 - loss: 0.8183 - val_accuracy: 0.5723 - val_loss: 0.8663\n",
      "Epoch 955/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6188 - loss: 0.8026 - val_accuracy: 0.5915 - val_loss: 0.8688\n",
      "Epoch 956/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5968 - loss: 0.8328 - val_accuracy: 0.5862 - val_loss: 0.8813\n",
      "Epoch 957/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6108 - loss: 0.8175 - val_accuracy: 0.6062 - val_loss: 0.8662\n",
      "Epoch 958/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6045 - loss: 0.8195 - val_accuracy: 0.6069 - val_loss: 0.8622\n",
      "Epoch 959/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6178 - loss: 0.8134 - val_accuracy: 0.6069 - val_loss: 0.8918\n",
      "Epoch 960/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6199 - loss: 0.8021 - val_accuracy: 0.5992 - val_loss: 0.8761\n",
      "Epoch 961/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6008 - loss: 0.8259 - val_accuracy: 0.5954 - val_loss: 0.8648\n",
      "Epoch 962/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6101 - loss: 0.8269 - val_accuracy: 0.6123 - val_loss: 0.8768\n",
      "Epoch 963/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6014 - loss: 0.8241 - val_accuracy: 0.5485 - val_loss: 0.9166\n",
      "Epoch 964/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5930 - loss: 0.8495 - val_accuracy: 0.6000 - val_loss: 0.8751\n",
      "Epoch 965/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6113 - loss: 0.8196 - val_accuracy: 0.5900 - val_loss: 0.9108\n",
      "Epoch 966/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6004 - loss: 0.8283 - val_accuracy: 0.5908 - val_loss: 0.8665\n",
      "Epoch 967/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6006 - loss: 0.8119 - val_accuracy: 0.6015 - val_loss: 0.8814\n",
      "Epoch 968/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6013 - loss: 0.8061 - val_accuracy: 0.5538 - val_loss: 0.8932\n",
      "Epoch 969/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5886 - loss: 0.8343 - val_accuracy: 0.6054 - val_loss: 0.8636\n",
      "Epoch 970/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5982 - loss: 0.8272 - val_accuracy: 0.5669 - val_loss: 0.8956\n",
      "Epoch 971/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5965 - loss: 0.8344 - val_accuracy: 0.6077 - val_loss: 0.8559\n",
      "Epoch 972/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6209 - loss: 0.8033 - val_accuracy: 0.6046 - val_loss: 0.8733\n",
      "Epoch 973/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6173 - loss: 0.8069 - val_accuracy: 0.5892 - val_loss: 0.8892\n",
      "Epoch 974/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6059 - loss: 0.8402 - val_accuracy: 0.5738 - val_loss: 0.9234\n",
      "Epoch 975/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5964 - loss: 0.8366 - val_accuracy: 0.6038 - val_loss: 0.8986\n",
      "Epoch 976/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6142 - loss: 0.7963 - val_accuracy: 0.5746 - val_loss: 0.8861\n",
      "Epoch 977/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6223 - loss: 0.8220 - val_accuracy: 0.5762 - val_loss: 0.9014\n",
      "Epoch 978/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5958 - loss: 0.8406 - val_accuracy: 0.6031 - val_loss: 0.8894\n",
      "Epoch 979/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6178 - loss: 0.8073 - val_accuracy: 0.6169 - val_loss: 0.8668\n",
      "Epoch 980/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5931 - loss: 0.8295 - val_accuracy: 0.6023 - val_loss: 0.8755\n",
      "Epoch 981/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6223 - loss: 0.8104 - val_accuracy: 0.5538 - val_loss: 0.9020\n",
      "Epoch 982/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6099 - loss: 0.8114 - val_accuracy: 0.5962 - val_loss: 0.8984\n",
      "Epoch 983/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5894 - loss: 0.8312 - val_accuracy: 0.6108 - val_loss: 0.8381\n",
      "Epoch 984/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6199 - loss: 0.8042 - val_accuracy: 0.5900 - val_loss: 0.8566\n",
      "Epoch 985/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5990 - loss: 0.8321 - val_accuracy: 0.6108 - val_loss: 0.8596\n",
      "Epoch 986/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6121 - loss: 0.8199 - val_accuracy: 0.5700 - val_loss: 0.8891\n",
      "Epoch 987/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6111 - loss: 0.8166 - val_accuracy: 0.6031 - val_loss: 0.8451\n",
      "Epoch 988/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6135 - loss: 0.8021 - val_accuracy: 0.5915 - val_loss: 0.8743\n",
      "Epoch 989/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6061 - loss: 0.8127 - val_accuracy: 0.6092 - val_loss: 0.8702\n",
      "Epoch 990/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6029 - loss: 0.8177 - val_accuracy: 0.6031 - val_loss: 0.8767\n",
      "Epoch 991/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5900 - loss: 0.8306 - val_accuracy: 0.6046 - val_loss: 0.8970\n",
      "Epoch 992/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6249 - loss: 0.7936 - val_accuracy: 0.5969 - val_loss: 0.8596\n",
      "Epoch 993/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6097 - loss: 0.8180 - val_accuracy: 0.5685 - val_loss: 0.8946\n",
      "Epoch 994/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5972 - loss: 0.8351 - val_accuracy: 0.5854 - val_loss: 0.8897\n",
      "Epoch 995/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6026 - loss: 0.8288 - val_accuracy: 0.5931 - val_loss: 0.9019\n",
      "Epoch 996/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6119 - loss: 0.8077 - val_accuracy: 0.6015 - val_loss: 0.8614\n",
      "Epoch 997/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6060 - loss: 0.8160 - val_accuracy: 0.5869 - val_loss: 0.9091\n",
      "Epoch 998/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6091 - loss: 0.8412 - val_accuracy: 0.6031 - val_loss: 0.8668\n",
      "Epoch 999/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6358 - loss: 0.8097 - val_accuracy: 0.5977 - val_loss: 0.8726\n",
      "Epoch 1000/1000\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6105 - loss: 0.8249 - val_accuracy: 0.5862 - val_loss: 0.8785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x18bed801b50>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련\n",
    "model.fit(train_X, train_Y, epochs = 1000, batch_size = 32,\n",
    "         validation_split = 0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "614dc869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6123 - loss: 0.8361 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8517798185348511, 0.5884615182876587]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_X, test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae537bbf",
   "metadata": {},
   "source": [
    "## 패션 이미지 분류 - keras 내장 데이터 세트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9896186a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 가져오기\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "35641b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_full.shape) # 28* 28 에 해당하는 이미지 6만개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "37ec1c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape) # 28*28 에 해당하는 이미지 1만개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f826844f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3329ccb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "          0,   0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,\n",
       "          1,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "          0,  36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,\n",
       "          0,   3],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,\n",
       "          0, 102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,\n",
       "         10,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0, 155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,\n",
       "         72,  15],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "         69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88,\n",
       "        172,  66],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0,\n",
       "        200, 232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196,\n",
       "        229,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        183, 225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245,\n",
       "        173,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        193, 228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243,\n",
       "        202,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12,\n",
       "        219, 220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197,\n",
       "        209,  52],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99,\n",
       "        244, 222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119,\n",
       "        167,  56],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55,\n",
       "        236, 228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,\n",
       "         92,   0],\n",
       "       [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237,\n",
       "        226, 217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,\n",
       "         77,   0],\n",
       "       [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228,\n",
       "        207, 213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244,\n",
       "        159,   0],\n",
       "       [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217,\n",
       "        226, 200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238,\n",
       "        215,   0],\n",
       "       [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200,\n",
       "        159, 245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232,\n",
       "        246,   0],\n",
       "       [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,\n",
       "         80, 150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228,\n",
       "        225,   0],\n",
       "       [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217,\n",
       "        241,  65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224,\n",
       "        229,  29],\n",
       "       [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198,\n",
       "        213, 240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221,\n",
       "        230,  67],\n",
       "       [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219,\n",
       "        221, 220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205,\n",
       "        206, 115],\n",
       "       [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211,\n",
       "        210, 200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177,\n",
       "        210,  92],\n",
       "       [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189,\n",
       "        188, 193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216,\n",
       "        170,   0],\n",
       "       [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244,\n",
       "        221, 220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full[0] # 0부터 255까지의 값으로 되어 있음\n",
    "# 딥러닝은 0~1 실수인 경우 학습을 더 잘 하는 것으로 알려져 있음\n",
    "# 값을 변경하지 않아도 학습은 가능하지만 되도록이면 0~1 사이의 숫자로 변환해주는 것이 좋음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "103fa015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화 과정\n",
    "X_valid, X_train = X_train_full[:5000] / 255. , X_train_full[5000:] / 255.\n",
    "y_valid, y_train = y_train_full[:5000] , y_train_full[5000 :]\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b6d1bf24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18bf0aa6890>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 이미지 1개 출력\n",
    "plt.imshow(X_valid[0], cmap = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b464eff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coat\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18bf0b346d0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 각 클래스의 실제 레이블을 배열로 생성\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "              'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "# print(y_train[0])\n",
    "print(class_names[y_train[0]])\n",
    "plt.imshow(X_train[0], cmap = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a8beecef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 활성화 함수\n",
    "# 입력을 비선형 출력으로 변환해주는 함수\n",
    "# 선형 관례를 나타내는 함수에 비선형을 추가하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d0b1bb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# 모델 만들기\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "# Dense는 데이터의 차원을 1차원으로 입력을 받아야 합니다.\n",
    "# 이미지 데이터의 경우는 가로 * 세로 또는 세로* 가로 *채널의 수로 입력\n",
    "# model.add(keras.layers.Dense(600, activation = 'rerlu', input_shape(784, )))# 28 * 28 이미지 라서 이렇게!\n",
    "# Flatten 은 원본 이미지의 차원을 주면 1차원으로 수정을 합니다.\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))  # input layer\n",
    "model.add(keras.layers.Dense(300, activation = 'relu'))# hidden layer\n",
    "model.add(keras.layers.Dense(200, activation = 'relu'))# hidden layer\n",
    "model.add(keras.layers.Dense(100, activation = 'relu'))# hidden layer\n",
    "\n",
    "# output layer 의 units 은 출력의 개수가 되어야 합니다.\n",
    "# 분류 문제는 활성화 함수로 softmax 가 잘 작동합니다.\n",
    "# 출력을 하나로 만들고자 하면 sigmoid를 사용하면 됩니다.\n",
    "\n",
    "model.add(keras.layers.Dense(10, activation = 'softmax'))# output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "04700df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">235,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">60,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │       \u001b[38;5;34m235,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │        \u001b[38;5;34m60,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m20,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">316,810</span> (1.21 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m316,810\u001b[0m (1.21 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">316,810</span> (1.21 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m316,810\u001b[0m (1.21 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델의 구조 확인\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "807c2b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수 \n",
    "# 출력층의 활성화 함수가  sigmoid : binary_crossentropy\n",
    "# 출력층의 활성화 함수가 softmax : (원핫 인코딩 한거) categorical_crossentropy\n",
    "                                  # (안한거) sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "29a0ee38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵티마이저\n",
    "# 손실을 낮추기 위해서 \n",
    "# # 종류\n",
    "# SGD\n",
    "# RMSprop\n",
    "# Adam\n",
    "# Adadelta\n",
    "# Adagrad\n",
    "# Nadam\n",
    "# Ftrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "839e52e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 지표\n",
    "# 분류 : auc, precision, recall, accuracy\n",
    "# 회귀 : mse, mae, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9d2c2e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일, 파라미터 조정\n",
    "# 틀림!!!\n",
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d038da84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일, 파라미터 조정\n",
    "# 분류를 할때 활성화 함수가 sigmoid 이면 loss가 binary_crossentropy\n",
    "# softmax 이고 원핫인코딩 하면, categorical_crossentropy\n",
    "# softmax 이고 원핫인코딩 안 하면, sparse_categorical_crossentropy\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c92702f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7839 - loss: 0.6125 - val_accuracy: 0.8706 - val_loss: 0.3561\n",
      "Epoch 2/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8591 - loss: 0.3823 - val_accuracy: 0.8680 - val_loss: 0.3736\n",
      "Epoch 3/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8781 - loss: 0.3290 - val_accuracy: 0.8832 - val_loss: 0.3229\n",
      "Epoch 4/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8870 - loss: 0.3040 - val_accuracy: 0.8814 - val_loss: 0.3235\n",
      "Epoch 5/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8895 - loss: 0.2906 - val_accuracy: 0.8826 - val_loss: 0.3327\n",
      "Epoch 6/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8955 - loss: 0.2768 - val_accuracy: 0.8866 - val_loss: 0.3090\n",
      "Epoch 7/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8994 - loss: 0.2647 - val_accuracy: 0.8936 - val_loss: 0.2890\n",
      "Epoch 8/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9058 - loss: 0.2464 - val_accuracy: 0.8912 - val_loss: 0.3069\n",
      "Epoch 9/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9110 - loss: 0.2327 - val_accuracy: 0.8920 - val_loss: 0.3068\n",
      "Epoch 10/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9142 - loss: 0.2273 - val_accuracy: 0.8978 - val_loss: 0.2963\n",
      "Epoch 11/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9164 - loss: 0.2154 - val_accuracy: 0.8944 - val_loss: 0.3169\n",
      "Epoch 12/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9189 - loss: 0.2112 - val_accuracy: 0.8952 - val_loss: 0.3102\n",
      "Epoch 13/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9236 - loss: 0.1971 - val_accuracy: 0.8896 - val_loss: 0.3138\n",
      "Epoch 14/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9241 - loss: 0.2003 - val_accuracy: 0.8952 - val_loss: 0.3303\n",
      "Epoch 15/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9252 - loss: 0.1925 - val_accuracy: 0.9024 - val_loss: 0.3227\n",
      "Epoch 16/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9286 - loss: 0.1869 - val_accuracy: 0.8962 - val_loss: 0.3216\n",
      "Epoch 17/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9316 - loss: 0.1777 - val_accuracy: 0.8912 - val_loss: 0.3302\n",
      "Epoch 18/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9356 - loss: 0.1708 - val_accuracy: 0.8946 - val_loss: 0.3599\n",
      "Epoch 19/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9324 - loss: 0.1757 - val_accuracy: 0.8946 - val_loss: 0.3596\n",
      "Epoch 20/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9371 - loss: 0.1640 - val_accuracy: 0.8918 - val_loss: 0.3703\n",
      "Epoch 21/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9402 - loss: 0.1549 - val_accuracy: 0.8946 - val_loss: 0.3869\n",
      "Epoch 22/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9405 - loss: 0.1557 - val_accuracy: 0.8934 - val_loss: 0.3721\n",
      "Epoch 23/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9389 - loss: 0.1553 - val_accuracy: 0.8966 - val_loss: 0.4136\n",
      "Epoch 24/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9445 - loss: 0.1441 - val_accuracy: 0.8986 - val_loss: 0.3837\n",
      "Epoch 25/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9439 - loss: 0.1447 - val_accuracy: 0.8920 - val_loss: 0.3856\n",
      "Epoch 26/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9471 - loss: 0.1347 - val_accuracy: 0.8988 - val_loss: 0.3988\n",
      "Epoch 27/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9481 - loss: 0.1383 - val_accuracy: 0.9022 - val_loss: 0.3814\n",
      "Epoch 28/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9488 - loss: 0.1331 - val_accuracy: 0.9014 - val_loss: 0.4009\n",
      "Epoch 29/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9498 - loss: 0.1290 - val_accuracy: 0.8986 - val_loss: 0.4312\n",
      "Epoch 30/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9513 - loss: 0.1271 - val_accuracy: 0.8950 - val_loss: 0.4376\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 30,\n",
    "                   validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f415ccc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8857 - loss: 0.5132\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5162312388420105, 0.8877999782562256]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2cadca37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "[[0.    0.    0.    0.    0.    0.    0.    0.    0.    1.   ]\n",
      " [0.    0.    0.985 0.    0.015 0.    0.    0.    0.    0.   ]\n",
      " [0.    1.    0.    0.    0.    0.    0.    0.    0.    0.   ]]\n"
     ]
    }
   ],
   "source": [
    "# 예측\n",
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "print(y_proba.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6adaa6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "[9 2 1]\n",
      "['Ankle boot' 'Pullover' 'Trouser']\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(model.predict(X_new), axis = -1)\n",
    "print(y_pred)\n",
    "print(np.array(class_names)[y_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "58943833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 4) subclassing\n",
    "# 개요\n",
    "# Sequential API 나 Functional API 는 선언적 방식인데 사용할 층과 연결 방식을 \n",
    "# 정의한 후 모델에 데이터를 주입해서 훈련이나 추론을 하는 방식\n",
    "# 선언적 방식은 장점이 많은데 모델을 저장하거나 복사 또는 공유하기 쉬우며\n",
    "# 모델의 구조를 출력하거나 분석하기도 좋고 프레임워크가 크기를 짐작하고 타입을\n",
    "# 확인해서 에러를 일찍 발견할 수도 있고, 디버깅도 쉽습니다.\n",
    "# 정적이라는 단점이 있음 - 수정하지 못한다는 뜻 \n",
    "# subclassing 은 기존의 클래스를 상속 받아서 수정해서 사용하는 것\n",
    "# Model 클래스를 상속받고 __init__ 메서드에서 필요한 층을 만들고 call메서드 안에\n",
    "# 수행하려는 연산을 기술하고 출력 층을 리턴하도록 작성 \n",
    "# subclassing 을 하고자 하면 원 클래스에 메서드들의 기능을 확인할 필요가 있습니다.\n",
    "# 필요한 메서드를 오버라이딩 해서 사용\n",
    "# 샘플\n",
    "# class WideAndDeepModel(keras.models.Model) :\n",
    "#     def __init__(self, 필요한 매개변수, **kwargs) :\n",
    "#                  super().__init__(**kwargs)\n",
    "#                  self.hidden1 = keras.layers.Dense(units, activation)\n",
    "#                  self.hidden2 = keras.layers.Dense(units, activation)\n",
    "#                  self.hidden3 = keras.layers.Dense(units, activation)\n",
    "#                  self.output = keras.layers.Dense(units)\n",
    "#    def call(self, inputs) :\n",
    "#                  hidden1 = self.hidden1(input_B)\n",
    "#                  ...\n",
    "#                  return self.output\n",
    "# model = WideAndDeepModel(매개변수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de6f18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) 모델 저장과 복원\n",
    "# 모델을 만들고 훈련한 후 모델.save 함수를 호출하면 모델을 훈련한 상태로\n",
    "# 저장할 수 있습니다.\n",
    "# load_model 함수를 이용해서 복원이 가능\n",
    "# 복원한 모델을 이용해서 예측을 할 수도 있고 훈련을 추가로 할 수 있습니다.\n",
    "# 복원한 모델을 가지고 추가 훈련을 해서 사용하는 것을 사전 훈련된 모델을 \n",
    "# 이용한다라고 합니다.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
